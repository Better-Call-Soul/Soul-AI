{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the location for the data set and Glove for embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder of the data set\n",
    "dataset_path = '../data/raw/detection/MELD/'\n",
    "# The folder for the models\n",
    "model_path = '../models'\n",
    "# The folder where Glove is installed\n",
    "TORCHNLP_CACHEDIR = f'{model_path}/Glove/pytorch-nlp_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Global Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isTrain = True\n",
    "seed = 2\n",
    "train_data_path = f\"{dataset_path}/train/train_sent_emo.csv\"\n",
    "dev_data_path = f\"{dataset_path}/validation/dev_sent_emo.csv\"\n",
    "test_data_path = f\"{dataset_path}/test/test_sent_emo.csv\"\n",
    "train_preprocess = f\"{dataset_path}/train/dialogues_train_preprocess.pkl\"\n",
    "dev_preprocess = f\"{dataset_path}/validation/dialogues_validation_preprocess.pkl\"\n",
    "test_preprocess = f\"{dataset_path}/test/dialogues_test_preprocess.pkl\"\n",
    "model_save_path = f\"{model_path}/MELD/model_test_new_code.pt\"\n",
    "batch_size = 16\n",
    "embedding_size = 300\n",
    "lstm_hidden_size = 500\n",
    "hidden_layer_size = 512\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sr No.          9932\n",
      "Utterance       8931\n",
      "Speaker          260\n",
      "Emotion            7\n",
      "Sentiment          3\n",
      "Dialogue_ID     1038\n",
      "Utterance_ID      24\n",
      "Season             9\n",
      "Episode           25\n",
      "StartTime       9008\n",
      "EndTime         8959\n",
      "dtype: int64\n",
      "['neutral' 'surprise' 'fear' 'sadness' 'joy' 'disgust' 'anger']\n",
      "Number of Dialogues:  1038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read CSV file into DataFrame\n",
    "df = pd.read_csv(train_data_path)\n",
    "# Count unique values in each column\n",
    "unique_counts = df.nunique()\n",
    "# Display the count of unique values\n",
    "print(unique_counts)\n",
    "# print the unique values of emotion\n",
    "print(df['Emotion'].unique())\n",
    "# get the number of dialogue\n",
    "num_Dialogues = len(df['Dialogue_ID'].unique())\n",
    "# print the number of dialogues\n",
    "print(\"Number of Dialogues: \", num_Dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the emotion map\n",
    "emotion_map_label = {\n",
    "    'neutral': 0,\n",
    "    'anger': 1,\n",
    "    'disgust': 2,\n",
    "    'fear': 3,\n",
    "    'joy': 4,\n",
    "    'sadness': 5,\n",
    "    'surprise': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-nlp --quiet\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install pyspellchecker --quiet\n",
    "!pip install contractions --quiet\n",
    "!pip install beautifulsoup4 --quiet\n",
    "!pip install emoji --quiet\n",
    "!pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable, Dict\n",
    "import argparse\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import torch.autograd\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score, classification_report, confusion_matrix)\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchnlp.word_to_vector import GloVe\n",
    "import contractions\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ahmed-\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ahmed-\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ahmed-\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ahmed-Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# define Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# define Glove\n",
    "pretrained_wv = GloVe(cache=TORCHNLP_CACHEDIR)\n",
    "# Stopword removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_tuple(filename: str, data: tuple) -> None:\n",
    "    '''\n",
    "    Dump the tuple to a file.\n",
    "    :param filename: The name of the file to dump the tuple to.\n",
    "    :type filename: str\n",
    "    :param data: The tuple to dump.\n",
    "    :type data: tuple\n",
    "    '''\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "\n",
    "def load_tuple(filename: str) -> tuple:\n",
    "    '''\n",
    "    Load the tuple from the file.\n",
    "    :param filename: The name of the file to load the tuple from.\n",
    "    :type filename: str\n",
    "    :return: The loaded tuple.\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_train(line: str) -> list[str]:\n",
    "    '''\n",
    "    Clean the line and return it as a list of tokens\n",
    "    :param line: the line to clean\n",
    "    :type line: str\n",
    "    :return: the cleaned line as a list of tokens\n",
    "    :rtype: list\n",
    "    '''\n",
    "    # translate emojis\n",
    "    line = translate_emojis_to_text(line)\n",
    "    # lower the line\n",
    "    line = lower_sentence(line)\n",
    "    # remove non ascii\n",
    "    line = remove_nonascii_diacritic(line)\n",
    "    # remove emails\n",
    "    line = remove_emails(line)\n",
    "    # remove html\n",
    "    line = clean_html(line)\n",
    "    # remove urls\n",
    "    line = remove_url(line)\n",
    "    # replace repeated chars\n",
    "    line = replace_repeated_chars(line)\n",
    "    # expand\n",
    "    line = expand_sentence(line)\n",
    "    # remove possessives\n",
    "    line = remove_possessives(line)\n",
    "    # remove extra spaces\n",
    "    line = remove_extra_space(line)\n",
    "    # tekonize\n",
    "    line = tokenize_sentence(line)\n",
    "    # remove stopwords\n",
    "    line = remove_stop_words(line)\n",
    "    # lemmetization\n",
    "    line = lemm_sentence(line)\n",
    "    if len(line) == 0:\n",
    "        return ['Normal']\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line: str) -> list[str]:\n",
    "    '''\n",
    "    Clean the line and return it as a list of tokens\n",
    "    :param line: the line to clean\n",
    "    :type line: str\n",
    "    :return: the cleaned line as a list of tokens\n",
    "    :rtype: list\n",
    "    '''\n",
    "    # translate emojis\n",
    "    line = translate_emojis_to_text(line)\n",
    "    # lower the line\n",
    "    line = lower_sentence(line)\n",
    "    # remove non ascii\n",
    "    line = remove_nonascii_diacritic(line)\n",
    "    # remove emails\n",
    "    line = remove_emails(line)\n",
    "    # remove html\n",
    "    line = clean_html(line)\n",
    "    # remove urls\n",
    "    line = remove_url(line)\n",
    "    # replace repeated chars\n",
    "    line = replace_repeated_chars(line)\n",
    "    # expand\n",
    "    line = expand_sentence(line)\n",
    "    # remove possessives\n",
    "    line = remove_possessives(line)\n",
    "    # remove extra spaces\n",
    "    line = remove_extra_space(line)\n",
    "    # tekonize\n",
    "    line = tokenize_sentence(line)\n",
    "    # check spelling\n",
    "    line = check_sentence_spelling(line)\n",
    "    # remove stopwords\n",
    "    line = remove_stop_words(line)\n",
    "    # lemmetization\n",
    "    line = lemm_sentence(line)\n",
    "    if len(line) == 0:\n",
    "        return ['Normal']\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_steps(line: str) -> list[str]:\n",
    "    '''\n",
    "    Clean the line and return it as a list of tokens\n",
    "    :param line: the line to clean\n",
    "    :type line: str\n",
    "    :return: the cleaned line as a list of tokens\n",
    "    :rtype: list\n",
    "    '''\n",
    "    print('-------------------------------')\n",
    "    # translate emojis\n",
    "    line = translate_emojis_to_text(line)\n",
    "    print(\"After translate --> \", line)\n",
    "    # lower the line\n",
    "    line = lower_sentence(line)\n",
    "    print(\"After lower --> \", line)\n",
    "    # remove non ascii\n",
    "    line = remove_nonascii_diacritic(line)\n",
    "    print(\"After remoeve non ascii --> \", line)\n",
    "    line = remove_emails(line)\n",
    "    print(\"After remove email --> \", line)\n",
    "    # remove html\n",
    "    line = clean_html(line)\n",
    "    print(\"After remove html --> \", line)\n",
    "    # remove urls\n",
    "    line = remove_url(line)\n",
    "    print(\"After remove url --> \", line)\n",
    "    # replace repeated chars\n",
    "    line = replace_repeated_chars(line)\n",
    "    print(\"replace repeated chars --> \", line)\n",
    "    # expand\n",
    "    line = expand_sentence(line)\n",
    "    print(\"After expand --> \", line)\n",
    "    # remove possessives\n",
    "    line = remove_possessives(line)\n",
    "    print(\"After remove possessives --> \", line)\n",
    "    # remove extra spaces\n",
    "    line = remove_extra_space(line)\n",
    "    print(\"After remove extra space --> \", line)\n",
    "    # tekonize\n",
    "    line = tokenize_sentence(line)\n",
    "    print(\"After tokenize --> \", line)\n",
    "    # check spelling\n",
    "    line = check_sentence_spelling(line)\n",
    "    print(\"After spelling check --> \", line)\n",
    "    # remove stopwords\n",
    "    line = remove_stop_words(line)\n",
    "    print(\"After remove stop words --> \", line)\n",
    "    # lemmetization\n",
    "    line = lemm_sentence(line)\n",
    "    print(\"After lemmatization --> \", line)\n",
    "    print('-------------------------------')\n",
    "    if len(line) == 0:\n",
    "        print(['Normal'])\n",
    "        return ['Normal']\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_sentence(sentence: str) -> str:\n",
    "    '''\n",
    "    Lowercase the sentence.\n",
    "    :param data: The sentence to lowercase.\n",
    "    :return: The lowercased sentence\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emails(sentence: str) -> str:\n",
    "    '''\n",
    "    Remove emails from the sentence.\n",
    "    :param sentence: The sentence to remove emails from.\n",
    "    :type sentence: str\n",
    "    :return: The sentence without emails.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return re.sub(r\"\\S*@\\S*\\s?\", \"\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonascii_diacritic(sentence: str) -> str:\n",
    "    '''\n",
    "\n",
    "    Remove diacritics from the sentence.\n",
    "\n",
    "    :param sentence: The sentence to remove diacritics from.\n",
    "\n",
    "    :type sentence: str\n",
    "\n",
    "    :return: The sentence without diacritics.\n",
    "\n",
    "    :rtype: str\n",
    "    '''\n",
    "\n",
    "    return unicodedata.normalize(\"NFKD\", sentence).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(sentence: str) -> str:\n",
    "    '''\n",
    "    Remove HTML tags from the sentence.\n",
    "    :param sentence: The sentence to remove HTML tags from.\n",
    "    :type sentence: str\n",
    "    :return: The sentence without HTML tags.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return BeautifulSoup(sentence, \"html.parser\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_repeated_chars(sentence: str) -> str:\n",
    "    '''\n",
    "    Replace repeated characters in the sentence.\n",
    "    :param sentence: The sentence to replace repeated characters in.\n",
    "    :type sentence: str\n",
    "    :return: The sentence with replaced repeated characters.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    # Replace consecutive occurrences of ',', '!', '.', and '?' with a single occurrence\n",
    "    return re.sub(r'([,!?.])\\1+', r'\\1', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_emojis_to_text(sentence: str) -> str:\n",
    "    '''\n",
    "    Translate emojis in the sentence to text.\n",
    "    :param sentence: The sentence to translate emojis to text.\n",
    "    :type sentence: str\n",
    "    :return: The sentence with translated emojis to text.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    # Translate emojis to text codes\n",
    "    translated_text = emoji.demojize(sentence)\n",
    "    # Remove colons from the translated text\n",
    "    translated_text = re.sub(r':', '', translated_text)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_sentence(sentence: str) -> str:\n",
    "    '''\n",
    "    Expand the contractions in the sentence.\n",
    "    :param sentence: The sentence to expand contractions in.\n",
    "    :type sentence: str\n",
    "    :return: The sentence with expanded contractions.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return contractions.fix(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(sentence: str) -> str:\n",
    "    '''\n",
    "    Remove URLs from the sentence.\n",
    "    :param sentence: The sentence to remove URLs from.\n",
    "    :type sentence: str\n",
    "    :return: The sentence without URLs.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return re.sub(\"((http\\://|https\\://|ftp\\://)|(www.))+(([a-zA-Z0-9\\.-]+\\.[a-zA-Z]{2,4})|([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(/[a-zA-Z0-9%:/-_\\?\\.'~]*)?\", '', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_possessives(sentence: str) -> str:\n",
    "    '''\n",
    "    Strip possessives from the sentence.\n",
    "    :param sentence: The sentence to strip possessives from.\n",
    "    :type sentence: str\n",
    "    :return: The sentence without possessives.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    # Stripping the possessives\n",
    "    sentence = sentence.replace(\"'s\", '')\n",
    "    sentence = sentence.replace('’s', '')\n",
    "    sentence = sentence.replace('s’', 's')\n",
    "    sentence = sentence.replace(\"s'\", 's')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(sentence: str) -> str:\n",
    "    '''\n",
    "    Remove extra spaces from the sentence.\n",
    "    :param sentence: The sentence to remove extra spaces from.\n",
    "    :type sentence: str\n",
    "    :return: The sentence without extra spaces.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return re.sub(r'\\s+', ' ', sentence).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentence_spelling(sentence: list[str]) -> list[str]:\n",
    "    '''\n",
    "    Check the spelling of the words in the sentence.\n",
    "    :param sentence: The sentence to check the spelling of.\n",
    "    :type sentence: list\n",
    "    :return: The sentence with corrected spelling.\n",
    "    :rtype: list\n",
    "    '''\n",
    "    spell = SpellChecker()\n",
    "    corrected_sentence = []\n",
    "    for word in sentence:\n",
    "        if word != '':\n",
    "            correction = spell.correction(word)\n",
    "            if correction is not None:\n",
    "                corrected_sentence.append(correction)\n",
    "            else:\n",
    "                corrected_sentence.append(word)\n",
    "        else:\n",
    "            corrected_sentence.append('')\n",
    "    return corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence: str) -> list[str]:\n",
    "    '''\n",
    "    Tokenize the sentence.\n",
    "    :param sentence: The sentence to tokenize.\n",
    "    :type sentence: str\n",
    "    :return: The tokenized sentence.\n",
    "    :rtype: str\n",
    "    '''\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence: list[str]) -> list[str]:\n",
    "    '''\n",
    "    Remove stop words from the sentence.\n",
    "    :param sentence: The sentence to remove stop words from.\n",
    "    :type sentence: list[str]\n",
    "    :return: The sentence without stop words.\n",
    "    :rtype: list[str]\n",
    "    '''\n",
    "    return [word for word in sentence if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_sentence(sentence: list[str]) -> list[str]:\n",
    "    '''\n",
    "    Lemmatize the sentence.\n",
    "    :param sentence: The sentence to lemmatize.\n",
    "    :type sentence: list[str]\n",
    "    :return: The lemmatized sentence.\n",
    "    :rtype: list[str]\n",
    "    '''\n",
    "    # Perform POS tagging\n",
    "    pos_tags = pos_tag(sentence)\n",
    "    # Lemmatize each word based on its POS tag\n",
    "    lemmatized_words = []\n",
    "    for word, pos in pos_tags:\n",
    "        # Map Penn Treebank POS tags to WordNet POS tags\n",
    "        if pos.startswith('N'):  # Nouns\n",
    "            pos = 'n'\n",
    "        elif pos.startswith('V'):  # Verbs\n",
    "            pos = 'v'\n",
    "        elif pos.startswith('J'):  # Adjectives\n",
    "            pos = 'a'\n",
    "        elif pos.startswith('R'):  # Adverbs\n",
    "            pos = 'r'\n",
    "        else:\n",
    "            pos = 'n'  # Default to noun if POS tag not found\n",
    "\n",
    "        # Lemmatize the word using the appropriate POS tag\n",
    "        lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemmatized_words.append(lemma)\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_MELD(data_path: str) -> Tuple[List[List[str]], List[List[int]]]:\n",
    "    '''\n",
    "    Read the MELD dataset from the specified path.\n",
    "    :param data_path: The path to the MELD dataset.\n",
    "    :type data_path: str\n",
    "    :return: The dialogues and their corresponding labels.\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    # Read the dataset\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Sort the data by Dialogue_ID and Utterance_ID\n",
    "    data.sort_values(['Dialogue_ID', 'Utterance_ID'], inplace=True)\n",
    "    \n",
    "    # Group the data by Dialogue_ID\n",
    "    grouped = data.groupby('Dialogue_ID')\n",
    "    \n",
    "    # Extract the dialogues and their corresponding labels\n",
    "    dialogues = []\n",
    "    labels = []\n",
    "    for _, group in grouped:\n",
    "        dialogues.append(group['Utterance'].apply(clean_train).tolist())\n",
    "        labels.append(group['Emotion'].apply(lambda x: emotion_map_label[x.lower()]).tolist())\n",
    "    \n",
    "    return dialogues, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for dataset reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed-Laptop\\AppData\\Local\\Temp\\ipykernel_26600\\964458276.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(sentence, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['also', 'point', 'person', 'companys', 'transition', 'kl-5', 'gr-6', 'system', '.'], ['must', 'hand', 'full', '.'], ['.', '.'], ['let', 'u', 'talk', 'little', 'bit', 'duty', '.'], ['duty', '?', 'right', '.'], ['head', 'whole', 'division', ',', 'lot', 'duty', '.'], ['see', '.'], ['perhaps', '30', 'people', 'dump', 'certain', 'amount', '.'], ['good', 'know', '.'], ['go', 'detail'], ['beg', '!'], ['right', ',', 'well', 'definite', 'answer', 'monday', ',', 'think', 'say', 'confidence', ',', 'fit', 'well', '.'], ['really', '?', '!'], ['absolutely', '.', 'relax']]\n",
      "[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 3, 0, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    inputs_old, targets_old = read_dataset_MELD(\n",
    "        train_data_path)\n",
    "    print(inputs_old[0])\n",
    "    print(targets_old[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert if number of inputs not equal to num_Dialogues\n",
    "assert len(inputs_old) == num_Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def clean_time(line: str) -> List[str]:\n",
    "    '''\n",
    "    Clean the line and return it as a list of tokens\n",
    "    :param line: the line to clean\n",
    "    :type line: str\n",
    "    :return: the cleaned line as a list of tokens\n",
    "    :rtype: list\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "\n",
    "    # translate emojis\n",
    "    line = translate_emojis_to_text(line)\n",
    "    print(\"Time taken for translating emojis:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # lower the line\n",
    "    line = lower_sentence(line)\n",
    "    print(\"Time taken for lowering sentence:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove non ascii\n",
    "    line = remove_nonascii_diacritic(line)\n",
    "    print(\"Time taken for removing non-ascii characters:\",\n",
    "          time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove emails\n",
    "    line = remove_emails(line)\n",
    "    print(\"Time taken for removing emails:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove html\n",
    "    line = clean_html(line)\n",
    "    print(\"Time taken for cleaning HTML:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove urls\n",
    "    line = remove_url(line)\n",
    "    print(\"Time taken for removing URLs:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # replace repeated chars\n",
    "    line = replace_repeated_chars(line)\n",
    "    print(\"Time taken for replacing repeated characters:\",\n",
    "          time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # expand\n",
    "    line = expand_sentence(line)\n",
    "    print(\"Time taken for expanding sentence:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove possessives\n",
    "    line = remove_possessives(line)\n",
    "    print(\"Time taken for removing possessives:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove extra spaces\n",
    "    line = remove_extra_space(line)\n",
    "    print(\"Time taken for removing extra spaces:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # tokenize\n",
    "    line = tokenize_sentence(line)\n",
    "    print(\"Time taken for tokenization:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # # check spelling\n",
    "    line = check_sentence_spelling(line)\n",
    "    print(\"Time taken for checking spelling:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # remove stopwords\n",
    "    line = remove_stop_words(line)\n",
    "    print(\"Time taken for removing stopwords:\", time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # lemmatization\n",
    "    line = lemm_sentence(line)\n",
    "    print(\"Time taken for lemmatization:\", time.time() - start_time)\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed train data already exists\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    if not os.path.exists(train_preprocess):\n",
    "        print(\"Preprocessing the training data\")\n",
    "        dump_tuple(train_preprocess, (inputs_old, targets_old))\n",
    "    else:\n",
    "        print(\"The preprocessed train data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess the data set (Train, Validation, Test) if not preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed train data already exists\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    if not os.path.exists(train_preprocess):\n",
    "        print(\"Preprocessing the training data\")\n",
    "        inputs, targets = read_dataset_MELD(train_data_path,)\n",
    "        dump_tuple(train_preprocess, (inputs, targets))\n",
    "    else:\n",
    "        print(\"The preprocessed train data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed dev data already exists\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    if not os.path.exists(dev_preprocess):\n",
    "        print(\"Preprocessing the validation data\")\n",
    "        inputs, targets = read_dataset_MELD(dev_data_path)\n",
    "        dump_tuple(dev_preprocess, (inputs, targets))\n",
    "    else:\n",
    "        print(\"The preprocessed dev data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed test data already exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(test_preprocess):\n",
    "    print(\"Preprocessing the testing data\")\n",
    "    inputs, targets = read_dataset_MELD(test_data_path)\n",
    "    dump_tuple(test_preprocess, (inputs, targets))\n",
    "else:\n",
    "    print(\"The preprocessed test data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data (train, val, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length:  1038 1038\n",
      "dev data length:  114 114\n",
      "test data length:  280 280\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # load data (train, dev, test)\n",
    "    train_data, train_label = load_tuple(train_preprocess)\n",
    "    dev_data, dev_label = load_tuple(dev_preprocess)\n",
    "test_data, test_label = load_tuple(test_preprocess)\n",
    "if isTrain:\n",
    "    # print length of each\n",
    "    print(\"train data length: \", len(train_data), len(train_label))\n",
    "    print(\"dev data length: \", len(dev_data), len(dev_label))\n",
    "print(\"test data length: \", len(test_data), len(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on the data (DailyDialoge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_class_distribution(targets: List[List[int]], dataset_name: str) -> None:\n",
    "    '''\n",
    "    Analyze the class distribution in the dataset.\n",
    "    :param targets: The list of targets in the dataset.\n",
    "    :type targets: List[List[int]]\n",
    "    :param dataset_name: The name of the dataset.\n",
    "    :type dataset_name: str\n",
    "    '''\n",
    "    class_counts = {}\n",
    "    for target_list in targets:\n",
    "        for label in target_list:\n",
    "            if label in class_counts:\n",
    "                class_counts[label] += 1\n",
    "            else:\n",
    "                class_counts[label] = 1\n",
    "\n",
    "    # Plot the class distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_counts.keys(), class_counts.values())\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of examples')\n",
    "    plt.title(f'Class distribution in {dataset_name}')\n",
    "\n",
    "    # Annotate each bar with its count\n",
    "    for label, count in class_counts.items():\n",
    "        plt.text(label, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_train_dev_test_distribution(train_targets: List[List[int]], dev_targets: List[List[int]], test_targets: List[List[int]], num_classes: int) -> None:\n",
    "    '''\n",
    "    Analyze the class distribution in the training, development, and test sets.\n",
    "    :param train_targets: The list of targets in the training set.\n",
    "    :type train_targets: List[List[int]]\n",
    "    :param dev_targets: The list of targets in the development set.\n",
    "    :type dev_targets: List[List[int]]\n",
    "    :param test_targets: The list of targets in the test set.\n",
    "    :type test_targets: List[List[int]]\n",
    "    :param num_classes: The number of classes in the dataset.\n",
    "    :type num_classes: int\n",
    "    '''\n",
    "    train_class_counts = {label: 0 for label in range(num_classes)}\n",
    "    dev_class_counts = {label: 0 for label in range(num_classes)}\n",
    "    test_class_counts = {label: 0 for label in range(num_classes)}\n",
    "\n",
    "    for target_list in train_targets:\n",
    "        for label in target_list:\n",
    "            train_class_counts[label] += 1\n",
    "\n",
    "    for target_list in dev_targets:\n",
    "        for label in target_list:\n",
    "            dev_class_counts[label] += 1\n",
    "\n",
    "    for target_list in test_targets:\n",
    "        for label in target_list:\n",
    "            test_class_counts[label] += 1\n",
    "\n",
    "    # Plot the distribution in training, development, and test sets\n",
    "    labels = np.arange(len(train_class_counts))\n",
    "    width = 0.25\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(labels - width, train_class_counts.values(),\n",
    "                    width, label='Train')\n",
    "    rects2 = ax.bar(labels, dev_class_counts.values(), width, label='Dev')\n",
    "    rects3 = ax.bar(labels + width, test_class_counts.values(),\n",
    "                    width, label='Test')\n",
    "\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Number of examples')\n",
    "    ax.set_title('Train, Dev, and Test class distribution')\n",
    "    ax.set_xticks(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # Annotate each bar with its count\n",
    "    for rect in rects1:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    # 3 points vertical offset\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    for rect in rects2:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    # 3 points vertical offset\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    for rect in rects3:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    # 3 points vertical offset\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if isTrain:\n",
    "    # Call the functions to analyze the data\n",
    "    analyze_class_distribution(train_label, 'Training set')\n",
    "    analyze_class_distribution(dev_label, 'Dev set')\n",
    "\n",
    "analyze_class_distribution(test_label, 'Test set')\n",
    "\n",
    "if isTrain:\n",
    "    # Call the function with training, development, and test targets\n",
    "    analyze_train_dev_test_distribution(train_label, dev_label, test_label, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove(word: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Retrieves the word embedding vector for a given word.\n",
    "\n",
    "    :param word: The word for which the embedding vector is retrieved.\n",
    "    :type word: str\n",
    "    :return: The word embedding vector for the given word.\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    return pretrained_wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2523,  0.1018, -0.6748,  0.2112,  0.4349,  0.1654,  0.4826, -0.8122,\n",
      "         0.0413,  0.7850, -0.0779, -0.6632,  0.1464, -0.2929, -0.2549,  0.0193,\n",
      "        -0.2026,  0.9823,  0.0283, -0.0813, -0.1214,  0.1313, -0.1765,  0.1356,\n",
      "        -0.1636, -0.2257,  0.0550, -0.2031,  0.2072,  0.0958,  0.2248,  0.2154,\n",
      "        -0.3298, -0.1224, -0.4003, -0.0794, -0.1996, -0.0151, -0.0791, -0.1813,\n",
      "         0.2068, -0.3620, -0.3074, -0.2442, -0.2311,  0.0980,  0.1463, -0.0627,\n",
      "         0.4293, -0.0780, -0.1963,  0.6509, -0.2281, -0.3031, -0.1248, -0.1757,\n",
      "        -0.1465,  0.1536, -0.2952,  0.1510, -0.5173, -0.0336, -0.2311, -0.7833,\n",
      "         0.0180, -0.1572,  0.0229,  0.4964,  0.0292,  0.0567,  0.1462, -0.1919,\n",
      "         0.1624,  0.2390,  0.3643,  0.4526,  0.2456,  0.2380,  0.3140,  0.3487,\n",
      "        -0.0358,  0.5611, -0.2535,  0.0520, -0.1062, -0.3096,  1.0585, -0.4202,\n",
      "         0.1822, -0.1126,  0.4058,  0.1178, -0.1971, -0.0753,  0.0807, -0.0278,\n",
      "        -0.1562, -0.4468, -0.1516,  0.1692,  0.0983, -0.0319,  0.0871,  0.2608,\n",
      "         0.0027,  0.1319,  0.3444, -0.3789, -0.4114,  0.0816, -0.1167, -0.4371,\n",
      "         0.0111,  0.0994,  0.2661,  0.4002,  0.1890, -0.1844, -0.3036, -0.2725,\n",
      "         0.2247, -0.4061,  0.1562, -0.1604,  0.4715,  0.0080,  0.5686,  0.2193,\n",
      "        -0.1118,  0.7993,  0.1071, -0.5015,  0.0636,  0.0695,  0.1529, -0.2747,\n",
      "        -0.2099,  0.2074, -0.1068,  0.4065, -2.6438, -0.3114, -0.3216, -0.2646,\n",
      "        -0.3562,  0.0700, -0.1884,  0.4877, -0.2617, -0.0208,  0.1782,  0.1576,\n",
      "        -0.1375,  0.0565,  0.3077, -0.0661,  0.4748, -0.2734,  0.0973, -0.2083,\n",
      "         0.0039,  0.3460, -0.0870, -0.5492, -0.1876, -0.1717,  0.0603, -0.1352,\n",
      "         0.1042,  0.3016,  0.0580,  0.2187, -0.0736, -0.2042, -0.2528, -0.1047,\n",
      "        -0.3216,  0.1252, -0.3128,  0.0097, -0.2678, -0.6112, -0.1109, -0.1365,\n",
      "         0.0351, -0.4939,  0.0849, -0.1549, -0.0635, -0.2394,  0.2827,  0.1085,\n",
      "        -0.3365, -0.6076,  0.3858, -0.0095,  0.1750, -0.5272,  0.6221,  0.1954,\n",
      "        -0.4898,  0.0366, -0.1280, -0.0168,  0.2565, -0.3170,  0.4826, -0.1418,\n",
      "         0.1105, -0.3098, -0.6314, -0.3727,  0.2318, -0.1427, -0.0234,  0.0223,\n",
      "        -0.0447, -0.1640, -0.2585,  0.1629,  0.0248,  0.2335,  0.2793,  0.3900,\n",
      "        -0.0590,  0.1135,  0.1567,  0.1858, -0.1981, -0.4812, -0.0351,  0.0785,\n",
      "        -0.4983,  0.1085, -0.2013,  0.0529, -0.1158, -0.1601,  0.1677,  0.4236,\n",
      "        -0.2311,  0.0825,  0.2430, -0.1679,  0.0080,  0.0859,  0.3803,  0.0730,\n",
      "         0.1633,  0.2470, -0.1109,  0.1512, -0.2207, -0.0619, -0.0371, -0.0879,\n",
      "        -0.2318,  0.1504, -0.1909, -0.1911, -0.1189,  0.0949, -0.0043,  0.1536,\n",
      "        -0.4120, -0.3073,  0.1838,  0.4021, -0.0035, -0.1092, -0.6952,  0.1016,\n",
      "        -0.0793,  0.4033,  0.2228, -0.1937, -0.1331,  0.0732,  0.0998,  0.1169,\n",
      "        -0.2164, -0.1108,  0.1034,  0.0973,  0.1120, -0.3894, -0.0089,  0.2881,\n",
      "        -0.1079,  0.0288,  0.3255,  0.2605, -0.0389,  0.0752,  0.4603, -0.0629,\n",
      "         0.2166,  0.1787, -0.5192,  0.3359])\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # test glove\n",
    "    embedding_test = glove('hello')\n",
    "    print(embedding_test)\n",
    "    print(len(embedding_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_embedding(inputs: List[List[List[str]]], word2vec: Callable[[str], torch.Tensor]) -> List[List[List[str]]]:\n",
    "    '''\n",
    "    Convert the dataset to embeddings.\n",
    "    :param inputs: The inputs of the dataset.\n",
    "    :type inputs: list\n",
    "    :return: A list containing the embeddings.\n",
    "    :rtype: list\n",
    "    '''\n",
    "    # define the embeddings list\n",
    "    embeddings = []\n",
    "    # for loop version\n",
    "    for dialogue in inputs:\n",
    "        # define the dialogue embeddings list\n",
    "        dialogue_embeddings = []\n",
    "        for sentence in dialogue:\n",
    "            # define the sentence embeddings list\n",
    "            sentence_embeddings = []\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    # get the word embedding\n",
    "                    word_embedding = word2vec(word)\n",
    "                    # append the word embedding to the sentence embeddings\n",
    "                    sentence_embeddings.append(word_embedding)\n",
    "                except KeyError:\n",
    "                    # if the word is not in the vocabulary, append a random vector\n",
    "                    sentence_embeddings.append(torch.rand(embedding_size))\n",
    "            # append the sentence embeddings to the dialogue embeddings\n",
    "            dialogue_embeddings.append(sentence_embeddings)\n",
    "        # append the dialogue embeddings to the embeddings list\n",
    "        embeddings.append(dialogue_embeddings)\n",
    "    # return the embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([ 2.0672e-03,  2.1145e-01, -1.8524e-01, -3.0905e-02,  2.4725e-01,\n",
      "         5.9446e-02,  1.3706e-02, -4.0758e-01, -4.7754e-02,  2.5806e+00,\n",
      "         7.0490e-02,  6.4292e-03,  1.8681e-01, -2.1989e-01, -9.1180e-02,\n",
      "        -1.7866e-01, -1.0238e-01,  9.9158e-01, -4.4060e-01, -2.2540e-03,\n",
      "        -4.5363e-01, -1.1468e-01, -5.0228e-02, -2.8581e-02,  6.9997e-02,\n",
      "         3.9979e-01, -6.9068e-02, -4.7958e-01, -2.0661e-01, -3.8850e-01,\n",
      "        -3.6105e-02, -2.2978e-03,  1.6734e-02,  9.6190e-02, -3.4225e-01,\n",
      "        -3.7471e-02, -4.9749e-02, -6.9791e-02, -2.1937e-01, -4.1352e-01,\n",
      "        -9.8468e-02,  6.5553e-02,  2.9838e-01, -3.2864e-01,  1.5924e-02,\n",
      "         1.7264e-02, -2.0529e-01, -2.2411e-01, -1.7274e-03,  2.1619e-01,\n",
      "        -1.3399e-01, -9.8754e-02,  2.7280e-01,  2.8525e-01,  1.8394e-01,\n",
      "        -2.0678e-01, -4.7490e-02, -2.7249e-02, -1.6912e-01, -1.9681e-01,\n",
      "        -1.2040e-01, -1.8441e-01, -1.6672e-02,  7.8169e-01, -1.3800e-01,\n",
      "        -1.8427e-01,  5.2241e-02,  2.2097e-01,  2.7181e-01,  1.1166e-01,\n",
      "         7.0292e-02,  3.5733e-01,  1.2349e-01, -2.0230e-01, -1.5105e-01,\n",
      "        -2.3412e-01,  3.8778e-02,  3.3363e-02, -4.9286e-02,  4.5542e-02,\n",
      "         4.5254e-02, -1.2481e-01, -4.4746e-01,  7.1069e-02,  2.5555e-01,\n",
      "        -5.9649e-01, -3.8173e-01,  4.4417e-02,  1.6431e-01, -2.6029e-01,\n",
      "         3.3224e-01,  7.3404e-02,  2.4068e-01,  7.4362e-03,  4.7972e-01,\n",
      "        -1.7850e-03, -4.7060e-02,  5.6476e-02, -2.4943e-01, -3.3277e-02,\n",
      "        -9.5038e-02,  8.2315e-03, -1.0937e-01,  7.2380e-02,  3.6326e-02,\n",
      "        -8.6065e-01,  1.4192e-01, -5.1392e-02, -9.4481e-02, -6.6388e-02,\n",
      "        -1.0182e-01,  1.9987e-01, -1.5867e-01, -1.8049e-02,  2.3223e-02,\n",
      "        -3.2358e-01,  1.5550e-01,  4.4619e-02, -1.5413e-01, -5.3259e-02,\n",
      "        -1.7410e-01, -1.4408e-01,  2.6262e-01, -1.6763e-01, -1.4044e-01,\n",
      "         3.4861e-02,  2.3380e-01, -4.1285e-01,  2.4563e-01,  1.1882e-01,\n",
      "        -2.9857e-02,  6.7154e-02,  9.4914e-02,  1.3767e-01,  4.2219e-01,\n",
      "         9.5418e-02,  2.1010e-01, -3.9006e-01,  4.4991e-02, -6.8347e-02,\n",
      "        -6.3816e-01,  2.2123e-01,  5.0841e-01,  3.5723e-02,  2.0266e-01,\n",
      "        -1.0329e-01,  5.8616e-02, -2.0011e-01, -1.0626e-01, -2.1551e-01,\n",
      "        -2.5187e-01,  2.2123e-01,  1.4712e-01,  3.8138e-02, -2.3799e-01,\n",
      "        -7.6580e-02, -1.5878e-01, -2.3523e-02, -1.4062e-01, -2.6651e-01,\n",
      "         2.8351e-01,  6.3906e-02, -3.8698e-01, -2.8565e-01,  1.8912e-02,\n",
      "        -4.7908e-01,  3.3664e-02, -7.3676e-02,  9.8917e-02, -2.1729e-01,\n",
      "        -3.9040e-01,  1.9976e-01,  2.4716e-01, -1.8064e-01, -5.1093e-01,\n",
      "         7.1950e-03,  2.5747e-01,  7.8263e-02,  1.5338e-02, -7.2376e-03,\n",
      "        -8.8996e-02,  2.8319e-01, -5.3720e-01,  8.0395e-02, -1.3071e-01,\n",
      "        -1.5342e-01, -1.0139e-01, -1.0472e-01, -1.4815e-01,  4.0233e-02,\n",
      "        -2.9872e-01, -1.3309e-01, -4.8087e-01,  1.3095e-01,  7.5826e-04,\n",
      "        -1.0264e-01, -1.8290e-01, -2.2466e-01, -4.9944e-02,  2.4116e-01,\n",
      "         2.1154e-02, -2.5101e-01, -6.7825e-02, -1.1802e-01,  4.3659e-01,\n",
      "         8.1956e-02,  7.1948e-02, -2.7477e-02, -9.0720e-02, -1.1074e-02,\n",
      "         9.2764e-02,  2.4070e-01, -1.0040e-01, -4.4220e-01, -1.0307e-01,\n",
      "         5.1464e-02, -6.4789e-02,  1.9987e-01, -3.0011e-01, -9.6113e-02,\n",
      "         3.0644e-02, -1.3270e-01,  3.0271e-01,  2.0800e-01, -1.6028e-02,\n",
      "         2.3996e-02,  2.2273e-01, -5.2439e-02, -1.2599e-01,  2.0196e-01,\n",
      "        -2.0911e-01, -7.8187e-02, -1.0225e-02, -1.0960e-02,  1.4785e-01,\n",
      "        -1.1225e-01,  1.9124e-01, -1.5983e-01, -2.1247e-01,  4.5341e-01,\n",
      "        -1.8367e-01,  7.2924e-02, -1.6042e-01,  1.3718e-01,  5.0401e-01,\n",
      "        -2.1494e-01, -4.4992e-01, -3.0015e-01, -1.3311e-01, -7.0944e-02,\n",
      "         2.2271e-01, -2.1885e-01, -1.3570e-02, -8.5168e-02,  1.1484e-01,\n",
      "        -1.4214e-01,  1.6436e-01,  7.9436e-02,  3.5556e-02, -1.4264e-02,\n",
      "         8.2947e-01, -9.7228e-03, -2.0411e-01,  2.1723e-01,  9.1097e-02,\n",
      "         3.1967e-01, -5.5709e-03, -1.1500e-01,  5.9580e-01,  6.9735e-02,\n",
      "         1.5148e-01, -1.1054e-01, -3.1078e-02, -7.1950e-03,  1.4530e-01,\n",
      "         2.3107e-02, -1.9097e-01,  3.6342e-01,  1.1363e-01,  2.6589e-01,\n",
      "         4.1716e-01,  3.2883e-01,  2.1658e-01,  4.3875e-02, -1.7120e-01,\n",
      "         3.5858e-02,  2.2337e-01,  4.1073e-03,  3.1401e-01, -1.9826e-01,\n",
      "        -4.8288e-01,  6.1790e-02, -2.0864e-01, -1.0915e-01,  2.0240e-01,\n",
      "         3.8696e-02,  8.3579e-02, -4.4664e-01,  4.3360e-01,  2.6717e-02]), tensor([-2.6161e-01,  4.1592e-01, -2.7887e-01,  1.9019e-01,  4.1254e-01,\n",
      "        -1.1941e-01, -1.0421e-01,  2.5440e-01,  2.6231e-02,  2.5043e+00,\n",
      "         6.9465e-02,  2.0187e-01,  2.7583e-01, -1.1832e-01, -6.3211e-02,\n",
      "        -1.4338e-01, -2.9870e-01,  1.3070e+00, -3.1519e-01, -1.8616e-01,\n",
      "         7.9471e-02, -1.5418e-01,  1.9360e-01, -8.5230e-02,  1.9259e-01,\n",
      "         5.2311e-02,  1.2986e-01, -1.7902e-01, -3.1106e-01,  2.0679e-02,\n",
      "        -8.3062e-02,  5.8480e-01,  3.3811e-02,  2.2940e-01, -2.4829e-02,\n",
      "        -2.8091e-02,  3.5322e-03,  5.9561e-02, -7.2350e-02, -3.2491e-01,\n",
      "        -2.5744e-01,  1.5044e-01, -3.5514e-01, -3.4522e-01,  2.6696e-01,\n",
      "        -1.6260e-01, -5.8277e-01, -1.3481e-01, -9.0599e-02,  1.4430e-02,\n",
      "         7.5714e-02,  1.6032e-01,  4.4923e-02,  1.4215e-01, -1.7324e-01,\n",
      "        -2.8896e-01, -1.1772e-01,  1.4887e-02,  2.3034e-01,  9.4912e-02,\n",
      "        -1.9258e-01, -7.6920e-02, -1.5796e-01,  4.6475e-03, -9.9648e-02,\n",
      "        -1.3244e-01,  7.9786e-02, -7.5191e-02,  3.7108e-01,  8.7885e-02,\n",
      "         1.5211e-02, -5.1574e-02,  2.3892e-01,  2.0362e-01, -2.4373e-01,\n",
      "         6.4078e-02, -1.0859e-01, -3.7272e-01, -5.2001e-02,  4.4802e-01,\n",
      "        -7.6019e-02,  3.5128e-02,  1.4726e-01,  2.6783e-01, -4.3305e-02,\n",
      "         1.4622e-01,  9.4794e-02, -5.1317e-01,  2.6840e-01, -1.2701e-01,\n",
      "        -4.2987e-01, -2.2568e-01, -1.6131e-01, -5.5821e-02,  6.5090e-02,\n",
      "         2.0412e-03, -4.9724e-02, -2.1830e-01,  1.3792e-01,  2.9662e-01,\n",
      "        -2.9487e-04, -4.0680e-01,  1.6342e-01, -4.8510e-02,  2.6671e-01,\n",
      "        -1.1808e+00,  6.0265e-04, -2.4216e-01, -4.7484e-01,  1.8331e-01,\n",
      "        -6.3958e-02,  1.3454e-02,  5.8838e-02, -1.2230e-02,  3.6778e-02,\n",
      "         3.8194e-02, -3.0617e-01, -1.8313e-01, -1.5147e-01,  2.0226e-01,\n",
      "         3.6076e-01, -1.1039e-01, -1.6646e-01,  2.1215e-02,  2.1955e-01,\n",
      "        -9.3325e-02, -4.4545e-01, -2.1181e-01, -1.1294e-01, -5.3717e-01,\n",
      "         7.8725e-02,  2.0547e-01,  1.1894e-01, -4.3916e-02, -7.8960e-02,\n",
      "         2.0511e-03,  1.2290e-01, -1.8315e-01,  5.8820e-02, -8.8993e-02,\n",
      "        -1.3847e+00,  3.5881e-01,  1.1744e-01,  5.2054e-02,  1.3280e-01,\n",
      "        -3.8596e-03, -2.5692e-01, -2.7796e-01,  1.5188e-01,  2.8552e-01,\n",
      "         1.0334e-01, -3.5377e-01, -2.2214e-01, -3.7217e-02, -2.1265e-01,\n",
      "         1.5994e-01,  1.8303e-01,  4.9813e-01,  1.9436e-01, -3.7553e-04,\n",
      "         2.1388e-02,  3.3331e-01, -3.1229e-02, -3.2784e-01, -2.5191e-01,\n",
      "         2.2750e-02, -2.5105e-01,  1.3570e-01, -8.6320e-03,  1.3230e-01,\n",
      "         2.9271e-01, -2.4111e-01, -3.4334e-01, -5.8101e-01, -7.7825e-02,\n",
      "         1.7446e-01,  7.8679e-02, -3.0183e-02, -8.1806e-02, -3.2712e-01,\n",
      "        -6.5981e-02, -1.2597e-02, -1.8930e-01, -1.2607e-01,  1.2502e-01,\n",
      "        -6.3008e-02,  2.9151e-02, -1.1116e-01, -2.3506e-04, -5.9351e-04,\n",
      "        -1.5591e-01,  8.1277e-02, -1.2990e-01,  1.6906e-01,  1.7245e-01,\n",
      "        -3.9307e-02, -2.3340e-01, -4.4002e-01, -1.7331e-01,  4.4754e-01,\n",
      "         2.4445e-01, -2.2059e-02, -6.1625e-01,  1.6627e-01,  1.8943e-01,\n",
      "         2.6485e-01, -9.1919e-02,  7.9451e-03, -9.7553e-02,  6.3925e-02,\n",
      "         8.7990e-02, -3.2723e-01, -1.3903e-01, -3.0260e-01, -1.5697e-02,\n",
      "        -5.5269e-02, -1.5103e-01,  7.2235e-01, -3.2432e-01,  1.2565e-01,\n",
      "         3.7397e-02, -6.2417e-02, -1.8368e-02,  2.3142e-01,  1.7695e-01,\n",
      "        -1.6762e-01,  6.3068e-02,  1.1899e-02, -2.7841e-01,  4.1403e-01,\n",
      "        -2.9195e-01,  1.6229e-01,  3.9387e-01,  2.2929e-01, -1.2171e-02,\n",
      "         7.3775e-02, -1.8159e-01,  1.9345e-01, -3.0110e-02,  4.5758e-01,\n",
      "         7.2491e-02, -1.5876e-01, -9.8345e-02,  2.9197e-01, -5.5464e-01,\n",
      "        -3.6151e-01, -8.5866e-02, -1.3474e-01, -2.8049e-01,  1.8014e-01,\n",
      "        -2.4524e-01,  2.5410e-01,  1.5933e-01, -1.4509e-01, -1.7656e-01,\n",
      "         2.5968e-01, -1.7740e-02, -1.9694e-01,  4.0761e-01,  1.0687e-01,\n",
      "         5.5641e-02,  1.5987e-01, -1.2064e-01,  4.3975e-02,  1.7243e-01,\n",
      "        -1.6047e-01,  1.6608e-01,  1.9268e-01,  5.7061e-01, -2.5755e-01,\n",
      "        -8.9411e-02,  3.8292e-01,  1.4612e-02, -5.6267e-01, -2.5354e-02,\n",
      "         4.2196e-02,  1.2539e-01, -3.6533e-01,  1.5905e-01, -5.4923e-02,\n",
      "        -1.8217e-01,  2.6025e-02, -4.4932e-01,  4.1651e-02, -5.2720e-01,\n",
      "         3.1158e-02,  1.1770e-02, -6.3587e-01,  2.9078e-01,  2.9615e-01,\n",
      "         1.7124e-01,  1.5856e-01, -2.4328e-01,  1.2553e-02,  3.1171e-01,\n",
      "         1.0023e-01, -5.6638e-01,  1.2226e-01,  6.1720e-02, -5.8289e-02]), tensor([-2.8545e-01,  1.8613e-01, -3.6656e-01, -2.8399e-02, -4.6600e-02,\n",
      "         7.1940e-02,  2.9929e-02, -9.1536e-01,  2.6457e-01,  3.1194e+00,\n",
      "        -3.6638e-01,  6.7558e-01, -5.3645e-01,  9.4788e-02,  2.5359e-01,\n",
      "         2.1967e-01, -5.3271e-01,  1.1469e+00,  1.4427e-01, -3.0327e-02,\n",
      "        -1.9001e-02, -4.7542e-02, -5.7979e-01, -6.6617e-02,  3.6411e-01,\n",
      "         1.8252e-01,  1.4270e-01, -1.1847e-01, -1.2525e-01, -2.7783e-01,\n",
      "         4.9227e-02,  5.8603e-02, -1.4217e-01,  3.7060e-01,  1.6469e-01,\n",
      "        -7.1414e-02, -2.4358e-01, -3.9535e-01, -3.6792e-01, -3.8580e-02,\n",
      "         1.7707e-01, -1.7135e-02, -1.4997e-02,  7.6096e-02, -1.2927e-01,\n",
      "         1.2746e-01, -1.7967e-01,  6.9770e-02,  2.1505e-01,  2.7568e-01,\n",
      "        -4.0566e-01, -7.1503e-01,  4.4739e-01,  1.6341e-01,  1.0850e-01,\n",
      "         1.9055e-02,  8.5015e-02,  3.5652e-02,  1.4133e-01, -2.8882e-01,\n",
      "         2.8899e-01, -4.1341e-01, -1.4936e-01,  1.4130e-01,  2.7201e-01,\n",
      "        -6.0803e-01, -2.0074e-01,  1.8194e-01, -3.7625e-01,  3.0936e-01,\n",
      "        -3.1392e-01, -2.1361e-01,  7.2878e-02, -3.2829e-01,  9.2763e-02,\n",
      "        -3.8384e-02, -1.2643e-01, -3.9655e-01,  1.0654e-01,  5.5379e-01,\n",
      "         2.1618e-01, -8.9621e-02, -1.3622e-01,  1.9074e-02,  5.1439e-01,\n",
      "        -1.2215e-01,  5.3386e-01, -6.0281e-01,  4.1781e-01, -8.1894e-01,\n",
      "        -1.2758e-01,  8.2661e-03, -3.4409e-01,  3.8340e-02, -2.3920e-01,\n",
      "        -5.3265e-01, -2.7096e-01, -2.3375e-01,  1.7762e-01,  7.2559e-02,\n",
      "         1.8009e-01,  2.1602e-01,  4.4480e-02, -2.2746e-01,  5.2720e-01,\n",
      "        -1.1949e+00, -1.7566e-01,  5.6218e-02, -2.1881e-01,  1.6880e-03,\n",
      "         4.4443e-01, -2.7613e-01, -1.8361e-01,  1.2183e-01, -1.0581e-01,\n",
      "         6.7063e-02, -6.1074e-02, -2.9320e-01,  2.3970e-01, -3.7792e-02,\n",
      "        -3.2675e-01, -4.3845e-01,  1.9067e-01, -4.4810e-02,  3.0299e-01,\n",
      "         4.7837e-02, -3.2462e-01, -1.7309e-01, -4.2140e-01, -1.4464e-01,\n",
      "         2.3669e-01, -4.5929e-02, -1.2923e-01, -1.6116e-01,  2.4681e-01,\n",
      "        -9.7846e-02,  1.2894e-01, -8.2661e-02,  1.5430e-01,  1.6279e-01,\n",
      "        -1.0104e+00,  1.8795e-01, -9.1862e-02,  5.2258e-01, -2.0191e-01,\n",
      "         6.7817e-02,  4.4474e-02, -2.4263e-01, -6.1477e-02, -5.7814e-01,\n",
      "         4.7357e-02,  4.3726e-02, -1.3786e-01,  1.3788e-01,  2.9092e-01,\n",
      "         4.7789e-01, -2.8608e-02, -3.8931e-02,  1.1675e-01, -2.6427e-01,\n",
      "         4.8919e-02, -3.6274e-01,  1.1859e-01,  1.1262e-01,  3.9282e-01,\n",
      "        -2.6175e-01, -7.0577e-02,  3.6360e-01, -1.0836e-01,  4.8829e-01,\n",
      "        -1.2166e-01, -2.0442e-01,  3.9812e-01, -2.2508e-02, -1.0683e-01,\n",
      "        -8.8209e-02, -2.8073e-01, -1.7601e-01, -5.0547e-01,  1.8879e-01,\n",
      "        -1.1320e-01,  3.8393e-01,  9.3451e-03, -3.3469e-01, -2.0428e-01,\n",
      "         7.8412e-01, -3.1775e-01, -2.9647e-02,  4.1582e-01,  1.3441e-03,\n",
      "        -4.1009e-01,  2.2361e-01, -9.4451e-02,  1.3014e-01,  5.0927e-01,\n",
      "         5.5883e-01, -4.6231e-01, -2.1260e-01,  2.5572e-01, -4.6041e-02,\n",
      "        -3.7454e-02,  2.5784e-01, -3.4846e-01,  1.5959e-01, -2.8146e-01,\n",
      "         3.6388e-01, -7.8552e-02,  8.8429e-03,  1.2487e-01,  1.9132e-01,\n",
      "        -7.8840e-02,  1.4637e-02, -1.2294e-01, -7.2034e-02,  3.2882e-01,\n",
      "         3.8889e-01, -1.9089e-01, -3.2443e-02, -5.9442e-01, -4.1312e-03,\n",
      "         3.3010e-01,  3.7451e-01,  3.0986e-01, -7.1407e-02, -8.5805e-02,\n",
      "        -5.6887e-01,  1.8607e-01,  2.0415e-01, -4.7275e-01, -5.1236e-01,\n",
      "        -5.3919e-01, -1.5432e-03, -3.0882e-02,  3.0391e-02, -8.7028e-02,\n",
      "        -1.6246e-01, -2.4024e-01, -5.0451e-02, -2.8717e-01,  2.8115e-01,\n",
      "        -1.0606e-01,  3.1304e-01,  4.5754e-01,  2.3915e-01,  3.8061e-01,\n",
      "        -2.4163e-01, -1.4491e-01, -8.0358e-02, -5.6473e-01, -7.4441e-02,\n",
      "         3.1097e-01,  2.3218e-01,  5.7540e-02,  4.2657e-01, -2.9657e-01,\n",
      "         8.2086e-01,  2.0658e-01, -8.6660e-01,  1.9116e-01,  3.0677e-01,\n",
      "        -3.7201e-01,  2.2199e-01, -4.3669e-02, -2.1748e-01, -1.0175e-01,\n",
      "         1.1434e-01, -1.7144e-01,  2.7899e-01,  3.9512e-01, -5.7092e-02,\n",
      "         2.7998e-01, -3.4140e-01, -3.7029e-01, -4.4937e-02, -1.3276e-01,\n",
      "         4.9246e-01, -3.2546e-01,  2.2689e-01, -4.9421e-02,  2.5456e-02,\n",
      "         1.0179e-01,  1.4277e-01,  1.6326e-01, -3.3239e-01,  5.1427e-02,\n",
      "         2.2603e-01, -2.5355e-02,  2.1068e-01,  1.9122e-01,  4.4498e-01,\n",
      "        -1.6963e-01,  1.7023e-01, -3.8504e-01, -4.4419e-01,  9.1514e-02,\n",
      "         3.0146e-01, -1.8267e-01, -1.3564e-01,  1.3998e-01,  1.1921e-01]), tensor([-2.4598e-01, -1.5669e-01, -4.2654e-01, -7.5829e-01, -1.2905e-02,\n",
      "         6.7642e-02,  1.5057e-01, -4.3067e-01,  3.3277e-01,  7.4442e-01,\n",
      "        -6.3664e-01, -1.5386e-01,  1.2344e-01,  1.9912e-01,  4.5872e-01,\n",
      "        -2.1189e-01,  1.4881e-01,  7.7509e-01, -6.1401e-02, -4.9231e-02,\n",
      "         3.9591e-01,  4.1580e-01,  1.5230e-01, -3.5009e-02, -4.0039e-02,\n",
      "        -9.0102e-02, -7.0542e-02,  4.4950e-02, -7.0272e-02,  1.8778e-01,\n",
      "         1.5355e-01, -2.0510e-01,  1.0861e-01,  4.7104e-01,  8.3338e-02,\n",
      "         5.4690e-01, -1.0356e-01,  1.4753e-01,  6.4421e-02,  3.0882e-01,\n",
      "        -1.3627e-01, -2.0919e-02, -1.6345e-01, -9.6651e-02, -4.6024e-02,\n",
      "        -1.1381e-01,  5.8343e-01, -2.8669e-01,  2.3102e-01,  4.5839e-01,\n",
      "        -1.3345e-01, -1.5666e-01,  5.1077e-01, -7.3233e-02, -3.2098e-01,\n",
      "        -1.6299e-01, -2.2177e-01, -5.7583e-01,  4.9386e-01, -1.8875e-01,\n",
      "         5.2732e-01, -5.1004e-01, -2.3562e-04,  3.7244e-01,  3.5606e-01,\n",
      "         2.1774e-01,  3.3031e-01,  4.4145e-02, -1.0743e-01, -3.4748e-01,\n",
      "        -2.6280e-01,  7.7561e-02,  4.6940e-01,  2.2898e-01,  1.6479e-03,\n",
      "         5.3001e-02,  2.5888e-01,  3.6989e-03, -3.4775e-01,  2.0902e-01,\n",
      "        -2.0171e-02,  2.4900e-01,  7.6762e-02, -2.0275e-01, -2.1917e-01,\n",
      "         2.3893e-01, -1.3819e-01,  4.9079e-01, -2.2651e-01, -2.9387e-01,\n",
      "        -3.4848e-01, -3.1990e-01, -8.5203e-02,  1.7946e-02,  4.2500e-01,\n",
      "         6.0903e-01, -5.3330e-02, -4.3234e-01,  3.8488e-02, -3.1359e-02,\n",
      "        -1.1634e-01, -1.4008e-01,  1.7215e-01,  3.6982e-01,  2.2865e-01,\n",
      "        -1.9575e+00,  7.2832e-01,  2.1919e-02, -1.7002e-01, -4.2805e-01,\n",
      "        -1.8999e-01,  1.7894e-01, -9.8052e-02,  8.3369e-02, -9.6326e-02,\n",
      "         5.0805e-01,  5.7757e-01, -2.8513e-01,  1.3360e-01,  5.0814e-01,\n",
      "         2.8021e-01,  4.5714e-02,  2.4653e-01,  1.0375e-02,  2.8148e-02,\n",
      "         9.3752e-02,  7.5400e-02, -1.9938e-02, -3.7947e-01, -4.6181e-01,\n",
      "         3.4976e-01, -9.1890e-02, -2.0586e-01,  9.0026e-02, -4.5987e-01,\n",
      "        -6.5634e-02, -3.4303e-01, -8.3470e-02, -1.0334e-01, -9.2081e-02,\n",
      "        -1.4476e-01, -2.9498e-01,  1.6822e-01, -3.0038e-01, -1.8262e-02,\n",
      "         2.1130e-02, -2.4068e-02,  2.2839e-01,  1.4773e-01,  2.1647e-01,\n",
      "         1.0440e-01, -1.4325e-01,  2.2184e-01, -3.1801e-01,  2.2582e-01,\n",
      "         4.1490e-01, -2.6233e-01,  3.3700e-01, -4.2061e-03,  1.5252e-01,\n",
      "         9.6519e-02,  3.3179e-01,  1.1061e-01,  4.2468e-01, -6.8266e-02,\n",
      "         4.3585e-02,  1.6031e-01,  5.1765e-01,  2.4897e-01,  4.3785e-02,\n",
      "        -3.6550e-01, -2.6242e-01, -3.8495e-01, -1.5596e-01,  5.4148e-02,\n",
      "        -2.9717e-01, -3.7309e-01,  7.1846e-01, -2.3401e-01,  8.0896e-01,\n",
      "         4.1556e-01,  5.0733e-01, -1.2439e-01, -3.1588e-02, -2.5931e-01,\n",
      "         3.2135e-01,  3.6193e-02, -3.3590e-01, -4.8108e-01,  4.4310e-01,\n",
      "         4.2707e-01, -1.1124e-01,  6.8985e-01, -1.4445e-01, -1.0422e-01,\n",
      "        -1.4528e-01,  3.8356e-01,  1.1229e-01,  1.5149e-01, -1.2602e-01,\n",
      "         5.1905e-01, -1.7672e-01, -5.2170e-02, -2.4668e-01, -2.7854e-01,\n",
      "         3.3405e-01, -4.8304e-02,  3.4410e-01,  1.2894e-01,  7.7099e-02,\n",
      "        -1.8969e-01,  4.8181e-01,  1.4012e-01,  5.3140e-01, -3.9721e-02,\n",
      "        -3.1366e-02,  3.0372e-01, -1.7630e-01, -1.4823e-01, -2.1404e-01,\n",
      "        -3.9079e-03, -3.0791e-01,  2.3253e-01, -7.6326e-02, -3.7038e-02,\n",
      "        -5.5235e-01, -2.5442e-01, -4.7377e-02, -4.8005e-01, -3.5716e-01,\n",
      "         8.7237e-02, -4.4210e-02, -3.7310e-01,  7.4941e-02, -1.9636e-01,\n",
      "        -1.1306e-01,  1.6822e-01, -1.5913e-01, -7.8707e-02,  6.0369e-02,\n",
      "        -9.3834e-02,  8.4785e-02,  3.5268e-01, -1.8542e-01,  1.4523e-01,\n",
      "        -5.2161e-01,  6.0610e-01,  1.1331e-01,  2.6428e-01, -1.9178e-01,\n",
      "         2.7958e-03, -7.1457e-01,  2.5137e-01, -3.5745e-01, -2.0108e-01,\n",
      "        -3.3942e-01, -3.1476e-01,  2.6371e-01, -2.9021e-01, -1.3961e-01,\n",
      "         3.3683e-01,  1.1686e-01,  2.3513e-02, -6.5750e-03, -3.3373e-01,\n",
      "        -7.2388e-01, -7.7388e-02, -5.8374e-02,  1.4553e-01,  4.1637e-01,\n",
      "        -1.5007e-01, -5.0773e-02,  2.1516e-02,  2.6370e-01,  1.3017e-01,\n",
      "         6.1903e-02,  1.7644e-01,  1.8963e-01,  4.0307e-01, -1.8406e-01,\n",
      "        -8.2917e-01, -8.8490e-02, -1.3499e-01,  6.6532e-01,  1.8298e-01,\n",
      "         3.8788e-01,  1.7039e-01,  1.2922e-01, -1.2117e-01,  2.9874e-01,\n",
      "        -6.4738e-01, -1.5999e-01, -7.8233e-02,  8.1818e-02,  2.5074e-01,\n",
      "        -5.5207e-02,  5.1010e-01, -6.1067e-03,  5.6276e-02,  2.6062e-01]), tensor([ 4.7185e-01,  1.3181e-01,  3.4655e-02,  4.5220e-01,  4.1645e-03,\n",
      "         1.0897e-01,  3.2726e-01,  3.2638e-01, -1.7167e-02,  2.0030e+00,\n",
      "         2.4314e-01, -3.5829e-02,  3.7208e-01,  7.4727e-01,  7.1051e-02,\n",
      "         4.2817e-01,  5.2239e-01,  1.9849e+00, -1.4816e-01,  8.4684e-02,\n",
      "        -2.9637e-01, -2.6454e-01, -5.8700e-01, -6.7730e-02, -3.6744e-01,\n",
      "        -8.6433e-03, -2.5120e-01,  1.9594e-01,  1.6325e-01, -1.4951e-01,\n",
      "        -1.8342e-01, -3.9295e-01,  2.9651e-01, -4.0906e-01,  1.1847e-01,\n",
      "         2.8688e-02,  7.7393e-01, -5.3021e-02, -4.6469e-02, -5.1279e-01,\n",
      "         7.0682e-03,  3.1162e-01, -1.3601e-01, -1.1299e-01, -3.6225e-01,\n",
      "        -1.6489e-02, -1.6698e-01, -1.0784e-01, -3.7915e-01,  1.4149e-01,\n",
      "         2.0106e-01, -1.4490e-01,  1.3802e-02, -1.4094e-01, -2.4860e-02,\n",
      "         1.7755e-01, -1.1173e-01, -3.1679e-02, -1.2278e-01, -2.2517e-01,\n",
      "        -1.8132e-01, -9.5175e-03, -1.4700e-01, -3.1052e-01, -7.0177e-02,\n",
      "         3.7114e-02,  5.6382e-02,  3.6236e-01,  2.8942e-01, -8.2027e-02,\n",
      "         9.0821e-02, -3.1094e-01, -4.7153e-01,  3.9534e-01,  3.9423e-02,\n",
      "         2.2868e-01, -2.8290e-01,  6.3384e-02,  4.2222e-01, -1.0037e-01,\n",
      "         4.3595e-01,  2.1176e-01, -4.3806e-01,  5.8811e-01,  7.1516e-02,\n",
      "         2.5082e-01, -5.5615e-01,  6.9455e-02,  8.0369e-02,  1.6859e-01,\n",
      "         1.1164e-01,  1.2946e-02, -1.3509e-01, -6.2734e-02, -3.3087e-01,\n",
      "         2.5941e-01,  5.1721e-01, -5.9604e-01,  2.8175e-01,  2.5258e-02,\n",
      "         5.1004e-01, -1.9594e-01,  4.5313e-02, -2.7211e-01, -2.1715e-01,\n",
      "        -1.6680e+00, -2.4527e-01, -5.1800e-01, -1.5989e-01,  1.8881e-01,\n",
      "        -4.8440e-01,  2.4228e-01, -7.0801e-01, -1.3849e-02, -4.7256e-04,\n",
      "        -3.9758e-01, -2.6135e-01,  2.3229e-01, -1.2775e-01,  8.6775e-02,\n",
      "        -2.9666e-01, -2.5884e-01, -4.9953e-01,  5.2057e-01,  4.5284e-01,\n",
      "         3.0983e-01,  6.2549e-02, -1.2135e-01,  1.9635e-01, -2.6871e-01,\n",
      "        -1.3750e-01,  9.2256e-02,  4.4099e-01,  1.9059e-01, -1.4607e-02,\n",
      "         4.9773e-01, -5.6078e-01,  4.8437e-01, -2.9842e-01,  2.8460e-01,\n",
      "        -4.5176e-01, -4.2182e-01,  2.0017e-01,  1.9964e-01, -2.2198e-02,\n",
      "        -9.6067e-02,  2.4021e-01,  5.0578e-01, -2.5207e-01,  1.8961e-01,\n",
      "        -3.5058e-01, -3.7388e-01, -2.8290e-01,  8.2545e-02, -2.4453e-01,\n",
      "        -1.8384e-01,  5.4987e-01,  2.3146e-01,  9.2601e-03, -1.0881e-01,\n",
      "        -2.5547e-01,  1.5704e-01,  2.2774e-02, -1.6002e-01, -5.3953e-01,\n",
      "        -1.4882e-01,  1.4642e-01, -3.5878e-01, -1.2874e-01, -5.2657e-01,\n",
      "         1.8358e-01,  2.7237e-02, -1.4684e-01, -1.5912e-02,  2.8535e-01,\n",
      "        -3.3421e-01,  1.8545e-01,  1.3881e-01, -5.3458e-02, -4.4557e-01,\n",
      "        -1.0767e-01, -3.9370e-01, -6.3385e-03, -2.3123e-03,  1.8893e-01,\n",
      "         1.7755e-03, -1.5822e-01,  2.2559e-01, -4.3598e-02, -3.5898e-01,\n",
      "        -1.6991e-02, -4.5827e-02,  4.6834e-01, -9.0168e-02,  3.1595e-01,\n",
      "         1.8223e-01, -1.6489e-01,  9.2910e-02, -4.4256e-01,  2.5926e-01,\n",
      "        -2.0058e-02,  1.7609e-01,  2.7298e-01, -3.2089e-01,  5.6530e-02,\n",
      "         3.9166e-02, -3.1475e-01, -3.6399e-01,  2.0129e-01,  8.3377e-02,\n",
      "         6.0657e-02, -2.6071e-01,  9.8211e-02, -2.5432e-01, -9.3868e-02,\n",
      "         2.0503e-01,  2.6065e-01,  2.4848e-01,  1.9055e-02,  2.5624e-01,\n",
      "         4.1069e-01, -2.1757e-01, -2.6086e-01, -1.5772e-02, -1.0663e-01,\n",
      "         2.7659e-01,  3.5153e-01, -4.5959e-02,  1.5214e-01,  7.4685e-01,\n",
      "        -3.5827e-01, -1.5159e-01,  4.7245e-01,  3.8225e-01,  2.5564e-01,\n",
      "        -1.1820e-01, -8.0388e-02,  8.1245e-02,  4.6375e-01,  1.0655e-01,\n",
      "         4.3045e-01, -2.8118e-01, -3.6054e-02,  4.4787e-01, -3.7109e-01,\n",
      "        -2.1916e-02,  3.0832e-02,  1.1899e-01,  3.5207e-01, -7.4672e-02,\n",
      "        -1.8886e-01,  1.5640e-01, -4.6999e-02,  1.7870e-01, -6.6923e-02,\n",
      "        -2.9439e-01,  7.4522e-02,  4.9537e-02, -1.7832e-01,  6.5140e-02,\n",
      "        -2.0469e-01,  1.0167e-01,  3.8212e-01,  6.6444e-02,  1.0342e-01,\n",
      "        -5.8168e-01, -7.2496e-02, -1.1233e-01,  5.7219e-01,  3.2774e-01,\n",
      "         1.3156e-01,  1.5807e-01,  1.0145e-01, -4.3104e-01, -7.2034e-01,\n",
      "        -4.1769e-01, -3.7382e-02, -2.7511e-01,  5.3479e-01,  1.7185e-01,\n",
      "         7.5556e-02,  1.4546e-01, -6.0626e-01,  1.3535e-01,  1.2949e-01,\n",
      "        -3.6160e-01, -3.7236e-01,  1.4056e-01,  3.3079e-01,  1.5411e-01,\n",
      "         1.3217e-01,  3.9335e-01,  2.6216e-01, -3.3588e-02,  4.1446e-02,\n",
      "         1.8237e-01, -1.1769e-01,  6.4075e-01, -2.0903e-02,  1.0956e-01]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([-5.6907e-01,  2.9066e-01,  4.0035e-01, -4.4450e-01, -2.8553e-01,\n",
      "        -5.9144e-02, -3.3809e-01, -3.3167e-01,  8.6699e-02,  1.6829e+00,\n",
      "         1.1289e-02, -2.5938e-01,  2.0536e-02, -3.5916e-02, -5.4331e-01,\n",
      "         2.7632e-02, -2.9068e-01,  2.7970e+00,  1.5754e-01,  1.9236e-01,\n",
      "         3.8849e-02, -9.2648e-02,  2.6970e-01,  6.3421e-02,  8.7162e-02,\n",
      "        -6.8522e-02, -2.5759e-01, -4.2842e-02,  1.7374e-01, -1.6159e-01,\n",
      "        -3.8265e-01,  1.9907e-02,  5.2915e-01, -3.7525e-01, -1.1763e-01,\n",
      "        -1.8277e-01, -1.3794e-01, -3.2496e-01, -6.2085e-02,  7.4453e-02,\n",
      "         6.1303e-01,  3.4287e-01, -1.9400e-02,  1.6951e-01, -1.2925e-01,\n",
      "         5.6516e-02, -6.3975e-01,  4.2620e-02, -6.4113e-01,  1.5335e-02,\n",
      "         1.5444e-01, -9.3647e-02, -1.8030e-02,  3.7656e-01, -3.7855e-01,\n",
      "        -1.1722e-02,  5.7375e-01, -1.7112e-01, -4.0487e-01,  2.6405e-01,\n",
      "         5.4668e-01,  2.8413e-01, -6.1513e-02,  8.4251e-02,  3.2516e-01,\n",
      "         1.1862e-01, -3.6169e-01, -1.0730e-01, -1.7502e-01, -2.6521e-01,\n",
      "         9.9426e-02, -4.2918e-01,  1.0151e-01, -5.9240e-01, -2.7139e-01,\n",
      "        -2.4081e-01, -1.2208e-01, -1.7127e-01, -1.0305e-01,  7.4111e-01,\n",
      "        -2.5473e-01,  6.8445e-02,  1.8286e-01, -4.4889e-01, -2.1102e-01,\n",
      "        -6.2081e-02, -4.4053e-01,  1.8458e-01,  6.0987e-02, -4.0375e-02,\n",
      "        -3.0728e-01,  3.1701e-01, -3.3589e-01,  1.3164e-02,  1.3372e-01,\n",
      "        -2.8193e-01,  6.3492e-02,  3.9298e-01,  2.2753e-03,  3.1307e-01,\n",
      "        -2.5287e-02, -3.7129e-01, -2.0983e-02, -3.4167e-01,  2.5929e-01,\n",
      "        -1.8672e+00,  1.8214e-01,  2.8298e-01, -1.9620e-01,  2.7491e-02,\n",
      "        -1.3602e-01, -1.2503e-01, -7.4227e-02,  1.4444e-01, -3.0379e-02,\n",
      "         1.1434e-01, -1.2851e-01,  8.8875e-02, -6.1470e-01,  8.6785e-01,\n",
      "        -2.0709e-01,  6.0318e-02,  1.6888e-01, -6.8668e-02, -2.8535e-01,\n",
      "        -4.8222e-01,  3.0006e-01,  2.0502e-01,  2.8487e-01, -2.9896e-01,\n",
      "        -1.6445e-01,  1.2480e-01, -3.7248e-01, -2.2848e-01,  3.0487e-01,\n",
      "        -5.1499e-02, -2.7455e-02,  6.2353e-03, -2.8441e-01, -5.6056e-01,\n",
      "        -5.5342e-02, -6.3336e-02,  3.1680e-01, -1.7166e-01,  9.3447e-02,\n",
      "         3.6541e-01, -1.7514e-01,  2.8285e-02, -1.2220e-01,  2.7517e-01,\n",
      "        -6.4777e-01,  1.8380e-01, -9.8472e-02,  4.7904e-01, -1.2713e-01,\n",
      "         2.9703e-01, -2.3583e-02,  1.0631e-01,  4.3598e-01,  2.0335e-02,\n",
      "         9.2299e-02, -3.3961e-02, -1.1249e-02, -3.2232e-01, -1.9003e-02,\n",
      "        -1.7197e-01,  4.1493e-01, -5.0542e-01,  2.4467e-01, -3.3611e-02,\n",
      "        -8.1732e-03,  2.9774e-02, -3.8562e-01, -1.4696e-01,  2.6607e-01,\n",
      "         2.6008e-01,  5.5223e-02,  2.0261e-01,  4.2110e-02,  5.8264e-01,\n",
      "         1.9543e-01, -2.5569e-01, -5.1367e-01, -1.5327e-01, -1.5017e-01,\n",
      "        -2.4015e-01, -4.6099e-01, -1.8602e-02, -4.2868e-01, -2.8143e-02,\n",
      "        -4.1277e-01, -8.0461e-01, -2.4189e-01,  4.2781e-01,  8.5538e-02,\n",
      "         6.6899e-02, -5.1920e-01, -1.1523e-01, -4.7241e-01,  8.9654e-02,\n",
      "        -4.0628e-02,  3.5514e-01,  3.6100e-01,  3.4398e-01, -1.8331e-01,\n",
      "        -9.4212e-02,  3.5846e-01,  2.4346e-01, -2.8680e-01,  8.8898e-02,\n",
      "        -6.5100e-01, -5.3909e-01, -2.3148e-01, -3.8451e-02,  2.0105e-02,\n",
      "        -1.5624e-01, -1.2215e-01,  2.6890e-01, -5.9694e-01, -2.0173e-01,\n",
      "         3.3340e-02,  4.8821e-01, -3.3052e-01,  1.1350e-01,  6.3528e-02,\n",
      "        -1.5925e-01,  2.5533e-01,  4.2077e-01,  1.9065e-01,  5.2994e-01,\n",
      "        -1.7359e-01, -3.8066e-01,  1.7924e-01,  2.3980e-01,  7.0585e-02,\n",
      "         1.3679e-01,  3.6429e-01, -2.7332e-01, -2.2591e-01,  5.3410e-03,\n",
      "        -1.4973e-01, -1.8923e-02,  4.9471e-01,  5.0752e-02, -2.4328e-01,\n",
      "        -3.7651e-01, -2.7192e-01, -8.2514e-02, -5.3332e-01,  3.7344e-01,\n",
      "         1.1733e-01, -1.4270e-01,  2.6394e-01,  6.2645e-02, -1.8137e-01,\n",
      "        -1.4318e-01, -2.0382e-01, -3.9510e-01, -1.5289e-01, -1.3636e-01,\n",
      "         3.4512e-01, -5.5440e-02, -7.0061e-02, -9.0203e-02, -3.9557e-01,\n",
      "        -4.5589e-01, -5.3997e-01, -7.0141e-02,  1.1282e+00,  2.9571e-01,\n",
      "         7.5009e-01,  3.0855e-02, -4.4588e-01, -1.1280e-01, -2.2151e-01,\n",
      "         2.1640e-01,  1.4339e-01,  2.1526e-01,  3.3070e-01, -6.3638e-01,\n",
      "        -2.4728e-01, -3.4312e-01,  1.5658e-01,  1.2074e-01, -6.5889e-01,\n",
      "        -2.5902e-01,  4.4484e-02, -1.1002e-01,  5.3079e-01, -5.9341e-01,\n",
      "        -6.6280e-01, -1.5885e-01,  3.3118e-01,  4.0762e-01,  9.5726e-02,\n",
      "        -1.5343e-02, -1.7072e-01,  4.9422e-01,  3.2091e-01, -4.1983e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 2.5343e-01, -2.4652e-01, -7.2461e-02, -1.7379e-01, -2.7067e-01,\n",
      "        -1.8529e-01,  2.1169e-02,  3.2397e-02, -1.5941e-01,  2.8452e+00,\n",
      "        -1.7716e-01,  2.0639e-01, -1.8112e-01,  2.6911e-01, -1.1389e-01,\n",
      "        -5.6499e-03,  2.3101e-02,  1.4712e+00, -4.9120e-01,  4.4886e-01,\n",
      "        -4.1793e-03, -4.7862e-01, -2.8190e-02, -2.6351e-01,  1.5126e-02,\n",
      "         2.1643e-01, -2.6271e-01, -4.7853e-01, -6.9289e-03,  4.6185e-02,\n",
      "        -5.2709e-01, -1.0517e-01,  1.0817e-01,  3.1032e-01, -2.1356e-01,\n",
      "        -1.3438e-01,  1.6756e-01,  2.5412e-01, -1.0225e-01, -2.0960e-01,\n",
      "        -1.9543e-01,  9.6065e-02,  1.4940e-02, -1.2389e-01, -3.8768e-02,\n",
      "        -7.3113e-02, -3.0991e-02, -3.2326e-02,  2.0335e-03,  3.8908e-01,\n",
      "        -1.2595e-02, -3.8986e-02,  1.5883e-01, -2.6229e-02,  3.9497e-01,\n",
      "         1.9390e-01,  3.0324e-02,  3.9831e-02,  1.4375e-01, -1.1458e-01,\n",
      "        -1.1852e-01,  1.4618e-01,  7.1360e-02,  2.3896e-01,  1.0165e-01,\n",
      "         5.4111e-01, -1.2925e-01,  3.2116e-01,  4.0596e-01,  2.0214e-01,\n",
      "        -9.3252e-02, -2.2834e-01,  4.7798e-01, -7.6000e-02,  8.4543e-02,\n",
      "         4.4619e-02, -6.9022e-02, -1.8192e-01,  1.2019e-01,  1.0853e-01,\n",
      "        -5.1074e-02,  1.4228e-01, -6.3109e-01, -7.9613e-02,  4.0649e-01,\n",
      "        -1.8000e-01,  2.7669e-01, -4.6770e-01,  5.7455e-01, -1.4994e-01,\n",
      "        -3.6719e-01,  8.1354e-02,  2.2154e-01, -5.4530e-02,  1.7011e-01,\n",
      "        -1.2494e-01, -6.3763e-02, -1.7323e-01, -7.2790e-02,  9.0460e-02,\n",
      "         1.8992e-01, -5.7479e-02,  1.1253e-01, -2.9021e-02,  8.0494e-02,\n",
      "        -1.1587e+00, -3.2920e-01, -1.4851e-01, -6.9593e-02,  1.5133e-01,\n",
      "         4.3163e-02,  4.3096e-02,  1.9214e-01, -2.5655e-01,  2.5101e-01,\n",
      "        -3.6275e-02,  4.2217e-01, -1.7398e-01, -2.8423e-01, -9.1980e-04,\n",
      "        -6.2936e-02, -1.8913e-01,  6.3183e-03, -1.2222e-01,  1.7220e-01,\n",
      "         2.3749e-02,  4.0021e-02, -2.1012e-01, -2.8792e-01,  2.3272e-01,\n",
      "         4.3026e-01,  1.1763e-01, -2.2246e-01,  2.9593e-01,  2.3851e-01,\n",
      "         7.0854e-02,  8.0145e-02, -3.4225e-01,  7.4686e-02,  1.8821e-01,\n",
      "        -7.6513e-01,  5.5689e-02,  1.5370e-01, -1.5351e-01,  2.9261e-01,\n",
      "        -3.8346e-01,  1.0322e-01, -1.1351e-01, -1.9821e-01, -3.8368e-01,\n",
      "         2.2824e-01,  1.6572e-01, -6.7278e-02,  2.6137e-01,  3.6073e-01,\n",
      "        -3.4953e-01, -2.8402e-01, -1.3673e-01,  7.5469e-02,  1.5061e-01,\n",
      "         3.1309e-01, -1.8264e-01, -4.1087e-01,  3.1916e-01,  1.2493e-01,\n",
      "        -1.9151e-01,  3.1982e-01, -3.6266e-01, -1.3255e-01,  9.2557e-02,\n",
      "         1.1676e-02, -1.1098e-01,  4.7360e-01, -3.5118e-01,  8.4228e-02,\n",
      "         3.0879e-01,  1.7055e-01,  2.1563e-01, -1.8073e-01, -8.1094e-02,\n",
      "         4.4005e-02,  2.4916e-01, -3.1350e-02, -1.9529e-01, -3.3600e-01,\n",
      "        -1.3784e-01, -4.6441e-01,  4.1018e-02, -8.7880e-03,  2.9457e-01,\n",
      "        -2.2578e-01,  5.1271e-01, -4.1839e-01,  2.7395e-02,  2.5097e-01,\n",
      "         2.3135e-01, -2.8276e-01, -5.5018e-02,  4.1319e-01,  4.2208e-01,\n",
      "         1.6035e-01,  1.1777e-01, -1.8323e-01,  7.6956e-05,  7.0349e-02,\n",
      "         2.4577e-02, -8.5470e-02,  2.6032e-01,  4.8492e-01, -2.0149e-02,\n",
      "         4.3426e-01, -7.1811e-02, -4.3024e-01, -3.7080e-01,  6.1242e-02,\n",
      "         3.9589e-01, -2.0658e-01,  8.7543e-02, -7.8592e-01,  8.0815e-02,\n",
      "        -6.3782e-02, -8.5938e-03,  3.4632e-01, -7.3251e-02,  1.5859e-01,\n",
      "         1.1503e-01, -5.1353e-02,  2.2192e-01, -1.0214e-01, -2.4954e-01,\n",
      "        -2.5309e-01,  1.3838e-01, -3.8246e-02,  3.0277e-01, -2.7883e-01,\n",
      "         2.3689e-02, -3.6825e-01, -8.4595e-01, -2.2146e-01, -6.4646e-02,\n",
      "        -8.5734e-03, -9.3305e-02,  1.2756e-01, -6.6558e-02,  1.0116e-01,\n",
      "        -3.5406e-01, -3.6482e-01,  5.5788e-03, -2.1870e-01,  3.2219e-01,\n",
      "        -2.2985e-01, -2.5712e-02, -3.0786e-01,  2.8554e-03, -9.4401e-02,\n",
      "         2.8364e-01,  1.4432e-01, -3.5734e-01, -3.4036e-02,  3.1602e-01,\n",
      "         3.2120e-01,  2.1176e-01, -3.6731e-01,  1.5428e-01,  3.7463e-02,\n",
      "         3.1655e-01,  2.9004e-01,  1.5187e-01,  8.6156e-01,  5.1438e-04,\n",
      "         5.3745e-01,  1.4355e-01, -1.5789e-01,  4.0415e-03, -5.1850e-02,\n",
      "         8.4828e-02, -2.6571e-01,  4.3575e-01,  2.8316e-02,  2.3171e-01,\n",
      "         2.5665e-01,  8.6280e-02,  1.7733e-01,  3.1108e-02,  2.7406e-02,\n",
      "        -1.7796e-01, -1.1448e-01,  1.3098e-01,  3.2621e-01,  1.0691e-01,\n",
      "        -2.0104e-01,  3.7747e-01, -2.1283e-01, -4.0675e-01,  3.6953e-01,\n",
      "         3.7894e-02, -2.3780e-01, -2.0161e-01,  5.1248e-01, -3.0237e-01]), tensor([-5.3293e-01, -2.0122e-01, -3.7079e-02, -6.0405e-02,  2.6306e-01,\n",
      "        -3.2949e-01, -1.6358e-01,  2.0531e-01, -3.1003e-03,  2.0820e+00,\n",
      "         1.9750e-02,  6.0231e-01,  1.1953e-01, -6.1272e-01, -5.5293e-02,\n",
      "         3.9245e-02, -6.0776e-01,  1.2901e+00, -3.1257e-02, -7.4918e-02,\n",
      "        -5.9154e-03,  2.4484e-01,  8.7067e-02, -1.0938e-02,  3.4489e-01,\n",
      "         7.9009e-02,  1.4180e-01,  1.8054e-04, -2.5091e-01, -5.6329e-01,\n",
      "         2.2463e-02, -4.5154e-02, -4.0973e-01, -1.9361e-01,  3.0947e-01,\n",
      "        -6.5443e-02, -2.5943e-01,  2.5298e-04,  3.6062e-02, -4.5192e-01,\n",
      "        -1.6892e-02,  7.0818e-02, -1.6618e-01, -5.6682e-01,  3.1435e-01,\n",
      "         1.4138e-01,  1.7986e-02, -2.6620e-01,  1.5349e-01,  2.3628e-01,\n",
      "         3.0675e-01,  7.7422e-02, -1.9565e-01,  6.8128e-02,  2.8277e-03,\n",
      "        -1.7669e-01, -5.9773e-02,  1.1834e-01, -4.9139e-02, -1.6938e-01,\n",
      "        -4.5880e-01,  8.0050e-02,  7.7822e-02,  1.2191e-01,  3.9593e-01,\n",
      "         1.0655e-01,  1.5780e-01,  3.3180e-01,  1.7720e-01,  2.7050e-01,\n",
      "        -4.3262e-01,  3.3808e-02,  2.1755e-01,  1.1438e-01,  5.0119e-02,\n",
      "        -1.0563e-01,  3.9360e-01, -4.9969e-01, -2.6356e-01,  5.2516e-03,\n",
      "        -2.6783e-01,  3.6215e-01, -2.1302e-01, -1.4962e-01, -1.8772e-01,\n",
      "        -1.7988e-01,  3.6843e-01,  4.8090e-01,  1.7775e-01,  9.5701e-02,\n",
      "         1.3073e-01, -1.2425e-01, -1.3510e-01,  9.8081e-02,  8.7784e-02,\n",
      "        -4.0343e-01,  2.9363e-01, -2.4880e-01, -4.3696e-01, -1.8775e-02,\n",
      "        -3.1994e-01, -6.5736e-02, -3.3870e-01,  9.8746e-02, -3.0548e-01,\n",
      "        -1.0144e+00, -3.4336e-01,  2.7681e-02,  2.2082e-01,  2.5450e-01,\n",
      "         8.1117e-02, -1.0189e-01,  3.3425e-01, -1.3620e-02,  2.7760e-01,\n",
      "        -2.6337e-02,  1.8756e-01,  4.7597e-02,  4.5873e-01,  4.6451e-02,\n",
      "         1.2129e-01, -2.8047e-01,  4.9621e-01,  6.0904e-01, -3.6900e-01,\n",
      "        -1.6113e-01, -5.2909e-01, -2.8279e-01,  1.1733e-01, -2.7546e-02,\n",
      "         9.2341e-02, -1.9805e-01, -2.7002e-01, -1.0523e-01, -1.9449e-01,\n",
      "         1.2349e-01,  4.2287e-01,  7.5313e-03,  3.2437e-01, -4.4093e-02,\n",
      "        -2.1088e+00, -5.8795e-02,  2.8711e-02, -5.3457e-02, -3.6996e-02,\n",
      "        -3.0232e-01, -2.1497e-01, -1.6659e-01, -1.4155e-01,  3.1190e-03,\n",
      "        -5.0739e-02,  3.2495e-02,  4.1739e-02,  1.5256e-01, -1.8844e-01,\n",
      "        -7.4672e-02, -7.1749e-02,  1.3247e-01,  7.4028e-03,  9.8931e-02,\n",
      "         1.5200e-01,  1.2318e-01, -1.7985e-01,  1.7695e-01,  1.3711e-01,\n",
      "        -4.7225e-01, -1.5112e-01, -2.7014e-01, -1.6837e-01,  1.3258e-01,\n",
      "        -6.4798e-01, -1.9737e-01,  3.1975e-02,  4.7299e-02, -4.0879e-01,\n",
      "         3.4881e-02,  1.1856e-01,  1.5380e-01,  2.8314e-01, -2.0526e-01,\n",
      "        -2.7293e-01,  5.3061e-02,  5.1982e-02, -3.2393e-01, -8.6257e-02,\n",
      "         2.3465e-01,  1.4332e-01,  9.2332e-03, -2.0516e-01,  1.5237e-01,\n",
      "        -5.8024e-01, -1.8108e-01, -1.3531e-01, -2.4897e-01,  5.6767e-02,\n",
      "        -1.2639e-02, -8.3788e-03, -1.6598e-01, -2.1002e-01,  5.5800e-02,\n",
      "        -2.5542e-01,  1.8441e-01, -8.0377e-02, -8.0548e-02,  4.6646e-02,\n",
      "         1.7759e-01,  7.7426e-02, -3.1260e-01, -2.6799e-01, -5.7985e-04,\n",
      "         1.1032e-01, -3.3414e-01,  4.9344e-03, -2.4910e-01,  2.0653e-01,\n",
      "         4.0363e-01, -3.0419e-01,  2.6219e-02, -7.0211e-01,  7.3718e-02,\n",
      "         2.8563e-01, -1.0249e-01, -4.6012e-03, -1.7482e-02, -2.5161e-01,\n",
      "         1.3222e-01, -7.8733e-02,  3.7271e-01,  2.7448e-01,  8.1104e-02,\n",
      "        -4.0645e-03,  1.2424e-01, -1.5974e-02, -2.5975e-01, -3.5274e-01,\n",
      "        -3.6050e-01,  1.1549e-01, -1.0422e-01,  3.5226e-02, -1.6570e-01,\n",
      "         5.5704e-02,  5.2908e-01,  2.6023e-01,  5.7477e-02, -5.1114e-02,\n",
      "        -2.8414e-01, -4.7576e-01, -4.7511e-01, -1.7445e-01,  3.9160e-01,\n",
      "        -2.0532e-01, -2.0391e-01, -1.4781e-01, -2.3542e-01, -7.6283e-02,\n",
      "         4.8842e-01,  1.7784e-01,  2.7270e-01,  1.4794e-01,  6.3812e-01,\n",
      "         6.0846e-02,  1.4001e-01, -2.0098e-02, -1.1952e-01,  2.5059e-01,\n",
      "         5.6902e-01, -1.8612e-01, -1.9185e-01,  1.2861e-02, -5.3315e-02,\n",
      "         1.9632e-01, -3.5608e-01, -2.3408e-01, -2.0114e-01, -2.4746e-01,\n",
      "         1.0847e-01,  2.7484e-01,  3.3304e-01,  1.5028e-01, -6.3581e-02,\n",
      "        -8.9621e-02,  1.2966e-01, -1.3484e-01,  1.0251e-01,  3.9167e-01,\n",
      "        -2.6146e-01, -1.7979e-01,  2.3925e-01, -1.3766e-02, -1.2448e-01,\n",
      "        -9.9528e-02,  3.1082e-01,  2.0247e-01,  1.5621e-03, -1.5218e-02,\n",
      "         2.7733e-01,  2.5773e-01, -6.9567e-02,  8.1057e-02,  2.7045e-01]), tensor([ 1.8252e-01, -3.4848e-01, -8.1394e-02,  3.2983e-01, -1.0957e-01,\n",
      "        -3.2872e-02,  2.2969e-01,  2.1271e-01,  2.2881e-01,  1.6532e+00,\n",
      "         4.8123e-02,  1.8061e-01, -1.5656e-01, -2.1404e-01, -4.6549e-01,\n",
      "         9.8081e-02, -6.4880e-02,  1.8911e+00, -1.3090e-01, -6.0966e-03,\n",
      "        -2.5184e-01, -3.8788e-01,  4.5986e-01, -2.3023e-01, -7.1719e-02,\n",
      "        -1.5006e-01,  2.1965e-01,  4.5706e-02,  5.0188e-01,  2.3885e-01,\n",
      "         7.5335e-02, -1.5852e-01, -2.5764e-01,  2.8332e-01,  5.2596e-02,\n",
      "        -7.4115e-02, -1.5297e-01,  3.6716e-01, -3.9539e-01,  7.8275e-02,\n",
      "         1.7038e-01, -5.5695e-02,  4.6137e-01, -3.3406e-01,  4.4755e-02,\n",
      "         4.9690e-01,  2.2878e-01,  4.3005e-01,  3.0389e-01,  8.7826e-02,\n",
      "        -2.7169e-01, -1.4552e-02,  3.6486e-01, -2.8561e-01, -1.0439e-01,\n",
      "         3.1896e-01, -1.5564e-01,  2.9492e-01, -4.1102e-01, -2.5033e-01,\n",
      "         2.3907e-01, -4.0789e-02,  3.0650e-01,  2.9751e-01,  2.4354e-02,\n",
      "         1.4490e-02, -1.2524e-01, -3.7754e-02,  1.3245e-01,  2.3590e-01,\n",
      "        -9.5467e-02, -2.4890e-01,  3.9515e-01, -2.5907e-01,  3.3903e-01,\n",
      "        -6.7480e-02,  1.9717e-01,  1.5276e-01,  9.0141e-02,  5.2029e-01,\n",
      "         5.0401e-03,  9.9142e-03,  1.3429e-01, -1.0588e-01, -4.2797e-01,\n",
      "        -1.3044e-01, -2.1962e-01,  3.0581e-01,  7.6195e-01, -1.4760e-01,\n",
      "        -3.8570e-01,  9.9921e-02,  5.2698e-02, -1.0698e-02, -9.7693e-04,\n",
      "         5.0827e-02, -6.3602e-02,  2.0995e-01,  6.5345e-02,  4.3269e-02,\n",
      "        -1.9534e-01, -7.7083e-02, -5.1436e-02, -1.7913e-01, -5.9892e-02,\n",
      "        -6.6358e-01,  1.6949e-02,  1.5984e-01,  3.2662e-01, -3.8560e-01,\n",
      "        -2.6223e-01, -6.7125e-02,  4.9430e-02,  4.5073e-01,  3.0439e-01,\n",
      "        -9.3092e-02, -5.7045e-02,  6.1006e-01,  3.9630e-01, -2.2215e-01,\n",
      "         2.1492e-01, -3.3421e-03, -2.7135e-01,  9.4058e-02, -4.3959e-01,\n",
      "         3.1533e-02, -2.9879e-01, -3.1848e-01, -4.0600e-01, -1.0014e-01,\n",
      "         6.4007e-02,  1.4852e-01,  1.5302e-01, -1.6145e-01,  4.0689e-01,\n",
      "         6.1270e-01,  2.8011e-01,  2.3945e-01, -2.4056e-01, -2.2579e-01,\n",
      "        -1.4389e+00, -3.0557e-01,  1.6749e-01, -1.3920e-01,  1.7638e-01,\n",
      "        -4.4747e-01,  3.6680e-02,  4.7205e-02, -1.3274e-01, -3.8673e-01,\n",
      "         3.8712e-02,  2.3625e-02,  3.6556e-01,  1.1784e-01, -1.6116e-01,\n",
      "         2.1269e-01, -1.5904e-02, -2.8975e-01, -7.0097e-02, -1.6100e-01,\n",
      "         2.0201e-01,  1.2674e-01, -1.1416e-01,  5.5049e-02, -9.4113e-02,\n",
      "        -2.0329e-01,  3.3488e-01, -3.1298e-01,  1.2535e-01, -5.3556e-01,\n",
      "         3.4709e-02, -2.6004e-01, -1.1077e-01, -2.0798e-01, -2.0348e-01,\n",
      "         6.6521e-02, -2.9617e-01,  2.4920e-01,  5.7716e-02,  1.7242e-01,\n",
      "         1.3525e-01, -3.7243e-01,  2.6116e-01,  1.6006e-02, -4.5264e-02,\n",
      "        -2.5819e-01, -1.9585e-01, -1.4364e-02,  1.1797e-01,  2.6061e-01,\n",
      "        -3.9869e-01, -1.0433e-01,  4.3832e-01,  2.7169e-01, -7.1498e-02,\n",
      "         3.0512e-01,  3.7008e-04,  3.7223e-01,  1.9207e-01,  2.1822e-01,\n",
      "         7.7054e-02,  7.4431e-02, -3.3861e-01, -3.4034e-01,  3.1355e-01,\n",
      "         2.1343e-01,  2.6615e-01, -1.3265e-01, -4.1216e-01,  9.9386e-02,\n",
      "        -1.5017e-01,  1.0639e-01,  4.4689e-01, -3.2935e-01,  1.8373e-01,\n",
      "         4.4705e-01, -9.1370e-02, -4.3454e-01, -5.9109e-02,  3.1006e-01,\n",
      "        -3.1088e-01, -4.9045e-01,  1.8107e-02,  2.4880e-01,  5.8535e-02,\n",
      "        -7.5070e-02, -5.4814e-02, -3.0170e-02,  2.8256e-01,  3.6763e-01,\n",
      "         3.4005e-01, -1.5984e-01,  1.7892e-02,  3.0413e-01,  9.7968e-02,\n",
      "         1.0208e-01,  4.2719e-03, -4.4455e-01,  1.7867e-02,  6.5163e-02,\n",
      "         4.2296e-02,  6.8716e-02,  5.4789e-03, -7.1077e-02,  4.6813e-02,\n",
      "         8.4418e-02, -2.5417e-01,  2.4714e-01, -2.8247e-01,  3.5769e-02,\n",
      "         1.6859e-02, -1.3057e-01, -7.1032e-02,  1.0410e-01, -8.8062e-04,\n",
      "         4.9245e-01,  2.1687e-01, -1.7922e-01, -5.5372e-01, -7.0894e-02,\n",
      "         1.2917e-01,  2.3226e-01,  1.4457e-01,  3.6461e-02,  3.0557e-01,\n",
      "        -1.9577e-01,  1.5655e-01,  2.2041e-01,  2.5967e-01, -2.0937e-01,\n",
      "         2.6074e-02, -3.8494e-02,  8.3234e-02, -4.2227e-01,  2.1268e-02,\n",
      "         5.0715e-01, -1.9498e-01, -1.1524e-02,  2.8803e-01,  2.0244e-01,\n",
      "         6.1209e-01,  2.6682e-01, -7.8592e-02, -1.4993e-01,  1.3777e-02,\n",
      "        -2.6847e-03, -3.5428e-01, -1.4536e-01,  1.8849e-01, -2.6361e-01,\n",
      "        -4.3855e-01, -2.6583e-01,  4.2716e-01, -3.9450e-01, -1.2715e-01,\n",
      "        -5.0797e-02, -5.0617e-01, -1.6726e-01,  1.6558e-01, -2.2563e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 9.3250e-02,  5.0599e-02, -4.8968e-01,  2.7851e-01,  1.5286e-01,\n",
      "        -1.3690e-01, -1.5794e-01,  6.7914e-03,  7.5847e-02,  2.5251e+00,\n",
      "        -2.3616e-01, -1.4799e-01,  2.2294e-01, -2.0697e-01, -1.8580e-01,\n",
      "        -1.6819e-01, -9.7591e-02,  6.9474e-01, -3.5729e-01, -5.5215e-03,\n",
      "         3.7689e-01,  1.1240e-01, -7.9097e-02, -5.4534e-02, -2.5686e-01,\n",
      "        -7.3549e-02, -1.7079e-01,  2.3360e-02,  2.2242e-01, -4.6184e-01,\n",
      "        -1.0292e-02,  3.7507e-01, -8.4341e-02,  1.9003e-01,  3.2980e-01,\n",
      "        -1.4508e-02,  3.7284e-01,  8.1165e-02, -1.3183e-01,  9.1393e-03,\n",
      "        -6.2218e-02, -3.7141e-01, -3.0504e-01, -4.2962e-01, -1.6529e-01,\n",
      "         1.2322e-01,  1.4059e-01,  1.1754e-02,  8.9681e-02, -1.2562e-03,\n",
      "        -4.9571e-02,  2.4349e-02,  8.6289e-03,  1.8357e-01,  2.7346e-01,\n",
      "        -5.1557e-02, -1.3188e-01,  3.7446e-02, -1.9667e-01,  2.0547e-01,\n",
      "        -2.4978e-02,  6.5271e-02, -2.5471e-01,  8.1128e-02,  4.3281e-01,\n",
      "         1.2339e-01, -2.4362e-01,  1.6110e-01,  5.1125e-01,  2.6967e-01,\n",
      "         7.6260e-02,  2.4962e-01,  1.7834e-01, -1.4423e-01,  2.0893e-01,\n",
      "        -1.6603e-03,  2.6246e-01, -2.4152e-01,  2.2789e-01,  6.2363e-02,\n",
      "        -3.5768e-01,  2.9228e-01, -7.0747e-01, -1.8364e-01, -1.5781e-01,\n",
      "        -7.6690e-02,  3.0888e-01, -5.3459e-01,  7.5535e-01,  9.8625e-02,\n",
      "        -3.2246e-01, -2.3448e-01,  1.6892e-01,  7.6448e-02, -1.7069e-02,\n",
      "        -1.8979e-02, -7.5453e-02, -5.5355e-02, -3.3932e-01,  2.4331e-01,\n",
      "         1.2271e-01,  1.1807e-01, -6.2957e-02,  1.5674e-02,  2.3544e-01,\n",
      "        -7.1471e-01,  2.9429e-01, -3.0277e-02, -2.9467e-01,  4.0571e-01,\n",
      "         2.8614e-01, -3.2952e-01,  4.3575e-01,  4.4389e-02,  2.5957e-01,\n",
      "         3.5200e-02,  1.2841e-01, -3.9553e-01, -1.0527e-02,  3.3108e-01,\n",
      "         2.3590e-01, -3.9255e-01,  3.7457e-02,  2.6974e-01,  3.5529e-01,\n",
      "        -8.4561e-02, -1.2525e-01, -3.6472e-01,  2.0246e-02,  9.2442e-02,\n",
      "        -1.2632e-01,  1.0549e-01,  2.3703e-01,  8.2976e-02,  1.6961e-02,\n",
      "         8.4727e-02,  1.6508e-02, -1.0803e-01, -2.6151e-02, -8.7635e-02,\n",
      "        -2.3881e+00,  3.6853e-01, -1.2159e-01, -6.7435e-02,  9.7362e-02,\n",
      "        -2.4413e-01, -4.8389e-02,  3.6878e-01, -1.9612e-01, -2.5491e-01,\n",
      "         2.6297e-01,  5.5155e-02,  1.4781e-01, -1.2052e-01,  6.0062e-02,\n",
      "         4.8958e-02,  6.5330e-02, -1.8637e-01,  2.8439e-02,  4.7032e-02,\n",
      "        -1.9826e-01,  2.7120e-01, -1.1266e-01,  4.4066e-02,  1.6468e-01,\n",
      "        -1.4856e-01,  3.9789e-01, -2.0421e-01, -7.7205e-02,  6.7335e-02,\n",
      "        -2.6958e-01, -1.7960e-02,  1.5594e-01, -4.9385e-01,  1.8608e-01,\n",
      "         2.7105e-01, -1.8901e-01, -1.4330e-01, -2.0968e-01,  1.3511e-01,\n",
      "         1.4514e-01, -9.8491e-02,  6.9470e-02, -1.0507e-01,  1.2563e-01,\n",
      "        -1.9256e-02, -1.4006e-01, -1.9053e-01,  1.3467e-03,  2.4733e-01,\n",
      "         5.0063e-03, -3.3518e-01, -1.3722e-01, -1.9545e-01,  2.3433e-01,\n",
      "         5.7972e-02, -1.0095e-01, -3.0243e-01,  1.8301e-01,  3.9504e-01,\n",
      "        -3.9710e-01,  1.0242e-01, -1.8768e-01, -6.1669e-01,  2.7327e-01,\n",
      "         1.9000e-01,  1.3508e-01,  1.1648e-01,  1.8209e-01,  7.5766e-02,\n",
      "        -3.2721e-01, -4.0137e-01,  1.8970e-02,  1.4664e-01,  3.2520e-01,\n",
      "         2.2775e-01,  1.5433e-02,  8.4019e-02, -5.6540e-01,  2.7435e-01,\n",
      "         2.7024e-01,  3.1692e-02,  1.1857e-01,  1.1159e-02,  4.9781e-02,\n",
      "         7.6929e-02, -1.7923e-01, -1.1379e-02, -3.4320e-01, -2.0649e-01,\n",
      "        -5.3315e-02,  2.2427e-01,  6.2022e-02,  3.0683e-01, -4.4969e-02,\n",
      "        -1.1339e-01,  2.0668e-01, -1.6750e-01, -1.1935e-01,  8.5310e-02,\n",
      "         3.6134e-01, -2.0427e-01,  2.0829e-01, -1.3841e-02,  5.6120e-02,\n",
      "        -2.4944e-01, -2.6533e-01, -1.4500e-01, -4.1489e-01,  7.0148e-01,\n",
      "         3.0077e-02, -1.4346e-01, -5.1720e-01, -2.4647e-01, -1.5729e-01,\n",
      "         2.7561e-01, -8.8460e-02, -1.0739e-01, -1.3019e-01, -1.7792e-01,\n",
      "        -5.7172e-04,  2.3123e-02,  2.9201e-02, -3.1450e-02,  1.7755e-01,\n",
      "        -2.7998e-01, -1.6394e-01,  2.0925e-01,  2.9958e-01,  3.5392e-01,\n",
      "         4.8260e-01, -1.0322e-01,  4.1762e-01, -8.6013e-02, -2.4109e-02,\n",
      "         1.6622e-01,  1.2710e-02,  1.0194e-01, -3.6362e-02, -2.4443e-02,\n",
      "         6.3773e-02, -2.2706e-01, -2.1225e-02,  1.4000e-01, -1.2766e-01,\n",
      "        -2.7162e-01,  2.7590e-01, -3.6209e-01,  2.4078e-01, -5.4157e-02,\n",
      "        -1.6255e-01,  3.4351e-02, -1.7346e-01,  1.6418e-01,  4.9555e-02,\n",
      "        -2.8204e-01, -1.5857e-01,  1.5514e-01,  8.1325e-02, -4.4961e-02]), tensor([-3.2642e-01, -4.7426e-02, -3.0887e-01, -4.7085e-01, -5.7324e-03,\n",
      "        -6.2423e-02,  3.7831e-01, -9.2603e-01,  1.3958e-01,  1.0340e+00,\n",
      "        -8.3525e-01, -8.9945e-02, -2.9842e-01, -3.4916e-01,  2.4004e-01,\n",
      "        -1.8173e-02, -3.8187e-01,  1.4761e+00, -5.1992e-01,  9.6903e-02,\n",
      "         3.8877e-01,  1.2884e-01, -3.5934e-02, -2.8532e-01,  1.6981e-01,\n",
      "        -3.4918e-01, -2.2212e-01, -5.4581e-01,  2.0627e-01,  4.2015e-01,\n",
      "        -5.2647e-02,  1.2857e-02,  1.0361e-01, -1.4081e-01,  3.6681e-03,\n",
      "         3.2023e-01,  9.3910e-02,  2.8421e-01, -2.7203e-01,  1.6457e-02,\n",
      "        -1.6287e-01, -5.9962e-01, -2.8153e-01, -2.9685e-01, -1.1271e-01,\n",
      "         9.7819e-03, -3.0332e-01,  2.8798e-02, -1.6485e-01, -7.2207e-04,\n",
      "        -2.9727e-01,  3.1393e-01,  5.3346e-02,  3.2972e-02, -6.7956e-02,\n",
      "         2.9795e-01, -1.4520e-01, -2.8234e-01,  9.9344e-02,  8.5714e-02,\n",
      "        -2.4147e-01, -2.5415e-01, -5.7550e-01,  1.5814e-01,  1.4834e-01,\n",
      "        -7.5197e-02,  1.5494e-01,  4.0976e-01,  2.5090e-01, -4.6960e-02,\n",
      "        -5.4264e-02,  5.8257e-01,  3.2062e-01, -4.2955e-01, -1.6566e-01,\n",
      "         1.9951e-01,  1.2034e-01, -1.4203e-02,  7.7139e-02,  2.3071e-01,\n",
      "         4.4025e-01,  5.7548e-01, -3.4726e-01,  6.0105e-01,  1.4616e-02,\n",
      "        -1.7761e-01,  1.3863e+00, -1.2178e+00,  6.5553e-02, -3.2466e-01,\n",
      "        -2.8627e-01, -2.9252e-01, -2.8491e-01, -6.6172e-02,  9.6919e-02,\n",
      "         8.4024e-02,  2.1685e-01,  2.3803e-02, -5.3823e-01,  2.2481e-01,\n",
      "         7.7096e-02, -1.9243e-02,  2.6451e-01, -3.2871e-02,  3.4045e-01,\n",
      "        -4.4296e-01,  4.0434e-01, -3.2901e-01, -2.6264e-01, -2.3052e-01,\n",
      "        -4.6119e-01, -5.8897e-01, -8.1216e-02, -2.6994e-01, -7.7693e-02,\n",
      "         1.1365e-01,  1.0028e-01, -2.1312e-01, -6.2362e-01, -1.5725e-01,\n",
      "         1.3781e-01, -1.1344e-01,  3.3040e-01, -1.8711e-01,  3.7849e-01,\n",
      "         2.2697e-01, -8.8057e-02, -3.4655e-01,  4.1241e-02,  1.5009e-01,\n",
      "         1.1526e-01,  3.1357e-01, -2.5415e-01, -1.8176e-02,  5.1489e-01,\n",
      "        -1.1170e-01,  1.5990e-01, -3.0815e-01, -1.1861e-01, -3.5318e-02,\n",
      "        -3.2394e+00,  1.7876e-02, -1.2945e-01, -1.3941e-01, -8.7627e-02,\n",
      "        -3.1757e-01, -2.1367e-01,  5.8958e-01, -5.0743e-01, -2.5978e-01,\n",
      "        -2.2548e-01,  3.5612e-01,  4.0548e-01, -4.1881e-01, -1.1643e-01,\n",
      "         1.8025e-01, -2.6350e-01,  2.3454e-02,  3.1150e-01, -1.2510e-01,\n",
      "         5.3416e-01, -9.7323e-04, -2.0881e-01,  3.7086e-01, -9.5422e-02,\n",
      "        -1.6967e-01, -1.6009e-01, -2.7913e-01, -5.7553e-01,  1.7004e-01,\n",
      "        -1.8499e-01, -1.6680e-01, -3.6655e-01, -5.6427e-01,  4.5473e-01,\n",
      "        -1.7707e-01, -4.6329e-01,  8.3183e-01, -3.5481e-01, -2.7577e-02,\n",
      "         2.4849e-01,  5.9409e-01, -3.8787e-01,  2.1746e-01, -2.5420e-01,\n",
      "         2.4853e-01, -5.3261e-01, -7.0012e-01,  6.8208e-01,  3.3834e-01,\n",
      "         4.0766e-01, -1.0734e-01, -5.0547e-01, -3.5712e-01,  4.4888e-01,\n",
      "         2.9147e-01,  9.5560e-02, -7.7588e-01,  3.5788e-02, -1.2742e-01,\n",
      "        -2.5511e-02, -1.8934e-01,  2.8752e-01, -2.0100e-01,  2.9583e-01,\n",
      "        -2.4856e-01,  1.1630e-01,  2.1262e-01,  2.2434e-01,  1.4747e-02,\n",
      "        -7.5889e-02,  3.1717e-01, -1.0849e-01,  2.2646e-01,  3.4181e-01,\n",
      "         9.1407e-02, -3.2760e-01, -4.5941e-01, -2.7483e-01,  7.1180e-02,\n",
      "         3.2483e-01,  4.8875e-02, -3.8906e-02, -2.4754e-01, -1.5285e-01,\n",
      "         3.4754e-01, -1.9161e-01,  3.2465e-01,  2.3279e-01, -1.7261e-01,\n",
      "        -5.2112e-01,  1.1521e-01,  2.6706e-01, -5.1825e-02, -2.1568e-01,\n",
      "        -3.9073e-01, -2.1969e-01,  2.2487e-01, -5.1606e-01,  3.5975e-01,\n",
      "         1.5073e-01,  6.4941e-01, -1.3052e-01,  3.1779e-01,  3.5433e-01,\n",
      "        -3.0344e-01,  3.4776e-01,  2.1879e-01, -9.4251e-02,  3.7130e-01,\n",
      "         7.2679e-01, -4.0563e-02, -2.0056e-01, -5.1911e-02,  1.6124e-01,\n",
      "         1.6198e-01,  1.0871e-01, -8.5487e-02, -6.7718e-01, -4.4081e-01,\n",
      "        -1.4766e-01, -1.9064e-01,  5.8050e-01, -1.4979e-02, -2.3617e-01,\n",
      "        -4.7242e-01,  4.4973e-02,  8.1533e-01,  6.5308e-01,  4.8133e-01,\n",
      "        -3.6846e-02,  2.7763e-02, -5.4884e-01,  7.5539e-01, -9.9792e-04,\n",
      "         2.7066e-01, -1.3480e-01,  4.1621e-02, -1.2019e-01,  1.9275e-01,\n",
      "        -1.3659e-01, -7.9267e-04, -5.2881e-02,  2.6122e-01,  2.0510e-02,\n",
      "        -1.1351e-01,  6.3746e-01,  3.8394e-01,  2.5729e-01,  2.8406e-01,\n",
      "         4.7218e-01, -4.1976e-01, -8.9370e-01, -8.1083e-01,  6.6108e-01,\n",
      "        -2.3324e-01, -2.8758e-01,  3.2141e-01,  1.6011e-01,  5.8877e-01]), tensor([-3.0319e-01,  2.1902e-01, -4.5800e-01,  5.1577e-01,  8.6683e-02,\n",
      "         2.5579e-04,  1.9374e-01, -5.6432e-01, -1.7592e-01,  2.5823e+00,\n",
      "        -1.2005e-01, -2.5813e-01,  1.5654e-01, -3.4848e-01, -4.1250e-01,\n",
      "         1.5398e-01, -1.7747e-01,  1.5287e-01, -4.5402e-01, -2.0266e-01,\n",
      "         4.6875e-01,  4.3809e-01,  8.3990e-02,  3.5616e-02,  1.1588e-01,\n",
      "         7.1903e-02,  4.6117e-02, -1.1594e-01,  9.6070e-02, -3.4981e-01,\n",
      "        -2.1293e-01,  3.3321e-01, -1.8935e-01, -1.0120e-01,  3.9855e-01,\n",
      "         4.1026e-01,  4.4898e-01,  2.3541e-01, -3.2057e-01,  1.3466e-01,\n",
      "        -1.0398e-01, -2.5291e-01, -2.4896e-01,  1.4438e-01, -3.9389e-01,\n",
      "         3.6933e-01, -5.0282e-02, -2.5900e-01, -4.1628e-03, -3.6256e-01,\n",
      "         1.5577e-02,  2.0341e-01, -1.3123e-01, -2.6659e-01,  8.3407e-02,\n",
      "         2.5968e-01, -8.6972e-02, -2.3136e-01, -9.8011e-03, -2.2740e-01,\n",
      "        -7.9407e-02,  1.6818e-01, -3.9108e-01,  3.5097e-01,  3.9469e-01,\n",
      "        -2.4262e-01,  7.8167e-02,  1.9718e-01, -1.7883e-01,  2.4754e-01,\n",
      "         6.6524e-02, -1.6903e-01,  1.6034e-01, -3.0271e-01, -8.6855e-02,\n",
      "         4.5322e-01,  1.0011e-02,  2.0875e-01,  2.8741e-01,  5.2132e-01,\n",
      "         1.8917e-01, -2.3793e-01, -4.6856e-01,  6.3453e-02, -3.4637e-01,\n",
      "        -1.5191e-01, -4.7310e-01, -4.8562e-01,  1.3443e-01, -4.1873e-02,\n",
      "        -2.6770e-01, -3.2591e-01, -2.8787e-01, -2.1782e-01, -4.5690e-02,\n",
      "        -4.0971e-02, -3.0318e-01, -3.8872e-01, -2.3176e-01, -2.6395e-01,\n",
      "         4.9751e-02,  6.0636e-02, -1.4275e-01, -4.1655e-01, -1.2143e-01,\n",
      "        -4.1880e-01,  5.9150e-01,  1.2645e-01,  7.3115e-02,  7.6298e-02,\n",
      "        -1.4850e-02, -4.4024e-01,  1.9434e-01,  2.7278e-01, -1.4363e-02,\n",
      "        -1.2287e-01, -3.1227e-01, -4.1705e-01,  1.5505e-01,  1.7692e-01,\n",
      "         3.0797e-02, -4.1315e-01, -8.5779e-02,  3.6627e-02,  4.1889e-01,\n",
      "         1.6855e-01,  2.5042e-01, -1.1308e-02, -1.7253e-02,  6.4692e-03,\n",
      "        -2.1691e-01,  8.2378e-02,  2.3169e-01,  1.6640e-01,  3.8430e-03,\n",
      "        -1.8129e-02,  1.7362e-01,  9.5835e-02,  4.2918e-01, -2.3075e-02,\n",
      "        -1.9422e+00, -2.2437e-01, -3.2092e-01,  9.0280e-02,  1.9094e-01,\n",
      "         1.6547e-01, -1.9369e-01,  1.8493e-01, -4.9989e-01, -1.6261e-01,\n",
      "         2.3860e-02,  5.4787e-02, -1.0397e-01, -1.9717e-01, -1.7457e-01,\n",
      "        -5.6867e-02,  4.9641e-01, -4.0065e-01, -1.6387e-01, -3.0760e-02,\n",
      "        -3.6098e-01, -1.8999e-01, -1.2438e-04, -3.9945e-01,  1.9272e-01,\n",
      "        -3.5556e-02,  4.9652e-02,  2.5498e-02, -1.0048e-01, -1.3512e-01,\n",
      "        -2.0860e-01,  2.6990e-01, -4.1118e-02,  3.3952e-01,  7.7034e-02,\n",
      "         1.3781e-01,  7.2991e-03,  5.3623e-01,  7.2618e-02, -9.9259e-02,\n",
      "         2.2464e-02, -2.6065e-01, -6.6404e-02, -1.6267e-02,  1.6445e-01,\n",
      "         1.3525e-01, -2.4582e-01, -1.3828e-01,  4.2669e-01,  1.4040e-01,\n",
      "         3.3842e-01,  2.7421e-02, -2.2566e-01, -5.2125e-02, -1.6722e-01,\n",
      "         2.6434e-01,  5.9454e-02, -4.4734e-01,  2.4247e-01,  5.2400e-01,\n",
      "        -1.5717e-01,  1.8585e-01, -2.5000e-02, -3.0737e-01, -4.9635e-03,\n",
      "        -1.0537e-01,  2.0706e-01,  5.9320e-02,  8.3574e-02,  7.9867e-02,\n",
      "        -4.8456e-01, -3.8394e-01,  1.2754e-01, -7.6456e-02,  1.0479e-01,\n",
      "         1.5600e-01, -3.1441e-01,  1.2325e-01, -3.8845e-01,  6.3269e-02,\n",
      "         1.9338e-01, -1.5374e-01, -4.8458e-01,  2.0409e-01, -1.9656e-02,\n",
      "         4.7531e-02, -1.7501e-02, -2.8964e-01,  8.3876e-02, -2.2475e-03,\n",
      "        -1.6018e-01,  2.6411e-01,  2.2727e-01,  1.3327e-01, -1.3321e-01,\n",
      "         1.7105e-01, -1.3990e-01,  1.1624e-01, -1.9978e-02,  1.8483e-01,\n",
      "         8.3772e-03, -5.8897e-02, -1.6318e-01, -6.0849e-01,  2.2859e-01,\n",
      "         1.2826e-01, -4.0066e-01,  8.2104e-02, -4.8592e-01,  6.3817e-02,\n",
      "         1.1167e-01, -2.5046e-01, -1.6322e-01, -1.1218e-01, -2.0562e-01,\n",
      "        -1.3316e-01,  4.0402e-02, -5.1411e-01, -5.1358e-01, -4.9576e-02,\n",
      "        -3.6712e-02,  4.0644e-01,  1.5245e-01,  5.9780e-01,  1.5697e-01,\n",
      "        -2.3237e-01, -7.2927e-02,  4.1242e-01,  8.2105e-01,  4.6808e-01,\n",
      "        -8.2240e-02,  1.9755e-01, -4.1705e-02, -2.6576e-01, -2.0142e-03,\n",
      "        -2.1784e-01,  1.8232e-01, -5.9293e-03,  8.8559e-02,  4.2219e-02,\n",
      "         1.7725e-01, -1.1704e-01, -2.8630e-01, -1.3221e-01, -3.2103e-01,\n",
      "        -8.2773e-02,  3.2907e-01, -6.3386e-02, -2.7042e-01,  7.0827e-01,\n",
      "         1.7514e-01, -1.1990e-01, -6.0634e-01,  1.7498e-01,  2.1540e-01,\n",
      "         1.4201e-01,  2.7836e-02,  1.6294e-01, -1.5864e-01,  3.5319e-01]), tensor([-4.7160e-01,  2.5148e-01, -3.6664e-01,  3.2902e-01,  7.3740e-02,\n",
      "        -9.6121e-02, -1.8007e-01, -2.3354e-01, -7.4560e-02,  2.2082e+00,\n",
      "        -3.6398e-01, -3.2352e-01,  2.3042e-01, -4.4910e-01, -3.0911e-01,\n",
      "         1.9049e-01, -2.2380e-01,  9.0952e-01,  8.0537e-02, -8.9746e-02,\n",
      "         8.8693e-03, -2.8151e-01,  8.0135e-02, -2.4125e-01, -1.8379e-01,\n",
      "        -1.1029e-01,  6.1420e-02, -4.0083e-02,  5.6011e-01, -1.3346e-01,\n",
      "        -3.7101e-01,  2.0927e-01,  7.9195e-02, -4.9383e-02,  3.8617e-01,\n",
      "        -6.5020e-02,  1.4549e-01,  6.5818e-02, -1.1027e-01, -2.2099e-01,\n",
      "         4.5376e-02,  4.7334e-01, -4.8147e-02, -2.8479e-01,  3.6882e-01,\n",
      "         2.2204e-02,  1.3056e-01, -2.7169e-01,  1.3194e-01, -3.5920e-01,\n",
      "        -3.0049e-01,  2.1180e-01, -9.4843e-02,  2.3170e-01, -7.1235e-02,\n",
      "        -1.0839e-01,  1.9551e-01,  2.0764e-02,  4.2276e-01, -6.8073e-02,\n",
      "         1.8874e-02,  1.3202e-01,  7.0006e-02,  1.5092e-01, -2.4150e-02,\n",
      "        -1.3937e-01, -1.3145e-01,  3.0620e-01, -1.7726e-01, -2.1308e-02,\n",
      "         1.9108e-01,  1.5225e-01, -9.1785e-02,  9.1788e-03,  4.2094e-01,\n",
      "         1.1479e-01,  8.0170e-02,  2.0512e-02, -3.2275e-01, -1.4844e-01,\n",
      "         2.3631e-01,  2.5127e-01, -1.2095e-02, -1.4879e-03, -4.0834e-01,\n",
      "        -2.0145e-01,  4.8312e-01,  4.7926e-02,  1.8975e-01,  2.9310e-01,\n",
      "        -6.1473e-02,  2.8624e-01, -2.7121e-01, -3.5265e-01,  1.4051e-01,\n",
      "         2.4380e-01, -1.1134e-01, -3.2222e-02,  4.2659e-01,  1.4438e-02,\n",
      "        -3.0976e-02,  1.0508e-01, -4.5325e-01, -1.0982e-01,  2.0467e-01,\n",
      "        -1.0275e+00,  8.1726e-02, -2.2724e-01,  2.6090e-01,  1.6788e-01,\n",
      "         2.3348e-01, -3.5231e-01, -2.2257e-01, -2.1278e-01,  1.0332e-01,\n",
      "        -4.4424e-01, -5.1831e-02, -8.7659e-02,  1.2331e-02, -5.7722e-02,\n",
      "         3.8823e-01, -4.5677e-01, -2.1501e-01, -9.4050e-03,  1.5517e-02,\n",
      "         8.6521e-02, -1.7669e-01, -1.3824e-01, -1.0453e-01,  8.0319e-03,\n",
      "        -1.1916e-01, -7.9443e-02, -3.8929e-02,  3.9810e-01,  1.7108e-02,\n",
      "        -2.0162e-01, -1.6402e-01,  1.2624e-01,  1.7106e-01, -2.1234e-01,\n",
      "        -2.7705e+00,  4.3177e-01,  1.6633e-02, -1.4489e-01, -3.5487e-02,\n",
      "        -3.8970e-01, -2.5352e-01,  1.8899e-01,  2.3492e-01, -5.2947e-02,\n",
      "         2.7257e-01,  2.4231e-02,  3.8832e-01, -7.0190e-02, -2.9610e-01,\n",
      "        -2.2560e-01, -8.7515e-02,  1.4212e-02, -1.4225e-01, -9.4078e-01,\n",
      "        -1.3987e-01,  8.6993e-02, -1.5125e-01, -1.9995e-01, -4.4605e-01,\n",
      "        -2.9341e-01,  2.2256e-01, -2.5694e-01,  4.3100e-01, -1.8594e-01,\n",
      "         2.3942e-01,  6.6344e-02,  2.7788e-01, -3.3886e-01,  6.8305e-02,\n",
      "        -1.3576e-01, -1.9935e-01,  1.0531e-01,  8.8211e-03,  7.1634e-02,\n",
      "         5.1641e-02, -2.8577e-01,  7.6244e-02, -8.8258e-02, -1.3150e-01,\n",
      "        -1.1785e-02, -6.9207e-02,  2.7700e-01,  2.3090e-03, -2.4661e-02,\n",
      "        -1.6959e-01,  1.1412e-01, -3.0347e-01, -7.6442e-02, -2.0251e-01,\n",
      "         1.3009e-01,  1.7785e-01,  1.6866e-02, -2.5317e-02,  1.2317e-01,\n",
      "        -1.4767e-01,  1.1442e-01, -5.4935e-01, -9.7924e-02, -3.7773e-04,\n",
      "         3.9139e-01,  1.8029e-01, -2.0671e-01, -8.6047e-02,  3.0330e-01,\n",
      "        -4.4119e-01, -2.3451e-01,  1.0756e-02, -2.1121e-01,  1.8049e-01,\n",
      "         6.3201e-01,  4.8743e-02,  2.1003e-01,  5.5365e-02, -1.1366e-01,\n",
      "         3.9356e-01, -6.7832e-04,  1.8620e-01,  1.1305e-01,  1.1053e-01,\n",
      "        -1.6804e-01,  1.6056e-01,  6.5637e-02, -1.3524e-01, -1.0095e-01,\n",
      "         5.0520e-02,  3.6234e-01,  5.9795e-02,  9.3383e-02,  3.7651e-01,\n",
      "         1.6531e-01,  2.2402e-01,  1.3437e-01,  2.9139e-01,  1.6708e-01,\n",
      "         9.2993e-03,  2.8496e-02, -2.6132e-01,  1.7716e-01,  1.9709e-01,\n",
      "        -1.2635e-01, -6.2846e-01, -2.4718e-01, -9.6553e-03,  2.7603e-01,\n",
      "        -7.3658e-02, -2.7563e-01, -6.5822e-02, -5.1642e-02,  7.4998e-02,\n",
      "         4.5143e-01, -7.1648e-02, -2.5490e-01, -7.3358e-02,  4.7640e-01,\n",
      "        -1.8510e-01, -7.2407e-02, -1.3286e-01,  5.9593e-02,  2.7843e-01,\n",
      "         8.5518e-02, -2.4348e-02, -6.7146e-02, -8.0348e-02, -3.5643e-02,\n",
      "        -2.8455e-01,  2.4969e-01, -2.3524e-01, -9.6517e-01, -3.9526e-01,\n",
      "        -5.1582e-02,  1.0336e-01, -8.2765e-02, -1.8408e-02,  3.7244e-01,\n",
      "         2.5689e-01,  2.2391e-01,  2.5904e-02, -4.2903e-02, -1.8179e-01,\n",
      "         4.0099e-02,  3.4833e-02, -2.5257e-01, -9.4783e-02, -1.9604e-01,\n",
      "        -6.3201e-01,  1.9382e-01,  3.1973e-01,  1.0819e-01,  9.4606e-02,\n",
      "         3.0916e-01,  2.7914e-01, -2.1312e-01, -2.0518e-01,  6.0325e-02]), tensor([-9.8027e-02,  1.8014e-01,  9.9034e-02,  1.6379e-01,  1.7841e-01,\n",
      "         3.1874e-01,  1.9240e-01, -3.4775e-01, -1.8178e-01,  1.7812e+00,\n",
      "         3.3183e-02, -2.9260e-01, -7.7725e-02, -3.4576e-01, -2.9026e-01,\n",
      "        -9.8951e-02, -2.6494e-01,  1.1084e+00, -1.9631e-01, -3.0716e-01,\n",
      "        -3.0154e-01, -9.8845e-02,  3.1699e-02, -3.0885e-01, -3.9976e-02,\n",
      "        -4.7606e-01,  2.2504e-01, -1.6491e-01,  3.0337e-01, -3.6870e-01,\n",
      "        -4.5543e-01, -7.2509e-02,  1.7399e-01, -2.6120e-01,  4.1011e-01,\n",
      "         2.5278e-01,  1.8498e-01,  2.0441e-01, -4.1355e-01, -2.4399e-01,\n",
      "         1.3191e-01,  4.2414e-01,  1.3264e-01, -8.6374e-02,  2.3816e-01,\n",
      "         1.6511e-01,  2.8583e-02, -4.5655e-01, -2.6728e-01,  1.2335e-02,\n",
      "        -1.2386e-01,  1.2313e-01,  2.4926e-01,  3.1789e-01,  3.0894e-02,\n",
      "         1.1270e-01, -7.2673e-02, -1.9435e-01,  5.1191e-01, -6.1791e-02,\n",
      "        -1.3715e-01,  8.2289e-02, -1.2324e-01, -6.2251e-02, -3.4331e-01,\n",
      "        -2.1021e-01, -9.7057e-02,  1.5611e-01,  5.1127e-03,  1.4852e-01,\n",
      "         4.9867e-01,  5.4087e-03,  2.7458e-01, -3.3637e-01,  1.3029e-01,\n",
      "         3.7874e-01,  3.8682e-01,  1.8863e-01, -5.5367e-01,  2.0505e-01,\n",
      "         3.3467e-01,  6.1149e-02,  3.9492e-02, -3.5181e-01, -2.3950e-01,\n",
      "        -1.7457e-01,  4.8938e-01, -9.7245e-02,  5.3357e-01,  2.3065e-01,\n",
      "        -2.8472e-01,  2.7255e-02, -1.5315e-01,  1.0664e-01, -7.6195e-02,\n",
      "         2.8156e-01, -2.8743e-03,  1.1059e-01,  3.2513e-01,  2.2456e-01,\n",
      "        -2.5552e-01, -2.4825e-01, -2.1810e-01, -3.1640e-02,  5.5943e-01,\n",
      "        -9.5684e-01,  1.8800e-01, -1.5871e-01,  3.9123e-01,  1.9804e-01,\n",
      "        -1.9325e-02, -4.2540e-01, -1.8543e-01, -1.7514e-02, -1.5663e-01,\n",
      "        -1.6508e-01, -3.0980e-01, -9.3178e-02,  1.2130e-01, -5.5970e-02,\n",
      "         5.5559e-01,  1.2123e-01, -2.7352e-01,  5.7035e-02,  1.8896e-01,\n",
      "         3.8765e-01, -2.6500e-01, -2.0842e-01, -2.9607e-01, -6.6415e-02,\n",
      "        -4.6842e-01,  3.3548e-01, -4.2743e-01,  4.7911e-01,  2.4903e-01,\n",
      "        -2.9769e-01, -1.4958e-01,  2.9182e-01, -2.0850e-01, -2.2341e-01,\n",
      "        -2.4123e+00,  5.8902e-01,  6.6027e-02, -2.1638e-01, -2.7317e-02,\n",
      "        -2.1444e-01, -4.5459e-01, -5.3311e-02,  6.5294e-02, -3.4772e-02,\n",
      "        -4.4160e-02, -1.7967e-01,  4.4897e-01,  3.0571e-01, -2.7539e-01,\n",
      "        -6.3290e-01, -2.0726e-02,  4.3446e-03,  1.7020e-01, -7.5427e-01,\n",
      "        -1.6865e-01, -1.5714e-01, -1.0261e-01, -1.7919e-02, -4.3971e-01,\n",
      "        -3.0971e-01,  5.1314e-02, -2.6701e-01, -7.4724e-02, -4.5924e-01,\n",
      "         2.6558e-01, -1.0393e-02, -1.2716e-01, -4.7316e-01,  1.4537e-03,\n",
      "        -1.5574e-01, -1.6398e-01, -2.5790e-01,  9.2685e-02, -1.5374e-01,\n",
      "         2.2899e-01, -7.7159e-01,  6.1067e-02, -6.5541e-02,  1.6441e-01,\n",
      "         1.7086e-01, -8.4660e-02,  4.7587e-01, -9.9615e-02, -3.6406e-02,\n",
      "         1.3210e-01,  3.1464e-01, -1.8071e-01,  2.7975e-01, -3.2537e-01,\n",
      "        -1.8664e-01,  2.7660e-01, -2.9938e-01, -3.6844e-01,  2.4066e-01,\n",
      "         9.8078e-02, -1.4962e-01, -5.2242e-01, -1.4500e-01, -2.5443e-01,\n",
      "         4.5361e-01,  1.0181e-01, -2.0196e-01, -1.3428e-01,  3.6976e-01,\n",
      "        -1.0376e-01, -2.4868e-01,  2.0927e-01, -8.3951e-01,  7.3323e-03,\n",
      "         6.4711e-01, -7.5909e-02,  2.8747e-01, -1.8472e-01,  3.3179e-01,\n",
      "         4.3942e-01,  2.0320e-01,  6.1921e-02, -1.3871e-01,  1.4272e-01,\n",
      "        -4.1570e-01,  1.3421e-01, -1.9249e-01, -4.3288e-02, -9.5841e-02,\n",
      "        -7.4666e-02, -1.0981e-01,  3.0961e-01,  4.4995e-01,  8.0730e-02,\n",
      "        -6.4188e-02, -2.8159e-02,  1.0232e-01,  1.2899e-01,  5.0306e-01,\n",
      "         3.0673e-01,  1.4114e-01, -1.4655e-01, -2.1830e-01, -4.4068e-02,\n",
      "        -2.4659e-01, -1.3801e-01, -2.2681e-01,  3.2479e-01,  7.2536e-02,\n",
      "         1.8476e-01, -3.1588e-01, -1.4015e-01, -8.9151e-02, -2.4307e-03,\n",
      "         9.8180e-03,  4.8298e-01, -1.7826e-01, -6.4221e-02,  6.5529e-01,\n",
      "        -1.5871e-01,  3.9674e-01, -1.1279e-01,  1.3558e-01,  4.0359e-01,\n",
      "        -1.0618e-01, -1.4749e-01, -1.8194e-01,  4.3114e-01,  8.3355e-02,\n",
      "         8.6052e-02,  5.5673e-01, -1.8242e-02, -9.8434e-01, -1.4162e-01,\n",
      "         3.7464e-01,  3.2357e-01, -3.9734e-01, -1.7230e-01,  7.4385e-01,\n",
      "         4.2892e-01,  3.4880e-02,  3.1457e-01, -8.9296e-02, -2.4381e-01,\n",
      "        -3.1748e-01, -2.6875e-01, -5.7344e-01,  1.6101e-01, -2.2029e-01,\n",
      "        -3.6543e-01,  6.8398e-02, -3.7930e-02, -5.5896e-02,  1.9791e-01,\n",
      "         3.5958e-01,  2.1465e-02, -2.4725e-01, -1.6960e-01,  3.4731e-02]), tensor([-8.6931e-02,  2.5377e-01,  1.6810e-01,  7.5704e-02,  1.8061e-02,\n",
      "        -6.4389e-01,  1.7444e-01, -1.6433e-01, -2.4357e-01,  2.0393e+00,\n",
      "        -1.8395e-01, -3.2359e-01,  3.9382e-01,  1.1465e-01, -5.8393e-01,\n",
      "        -2.8376e-01, -7.9123e-03,  1.5639e+00,  5.6717e-02,  8.9370e-01,\n",
      "         2.6189e-01, -2.7468e-01,  9.5437e-02, -8.2834e-02,  3.3205e-01,\n",
      "         2.5640e-01,  7.9347e-02, -4.0802e-01, -4.5415e-02, -1.2211e-01,\n",
      "         7.7319e-02,  3.0104e-01, -6.9792e-01,  3.7858e-01, -3.2511e-01,\n",
      "        -3.4816e-01, -1.4897e-01, -1.2082e-01, -3.6768e-01, -4.6140e-01,\n",
      "         3.6606e-01, -1.7980e-01,  5.5668e-01,  1.5601e-01,  3.5077e-01,\n",
      "        -2.1335e-01,  3.0609e-02,  2.9482e-02,  1.7253e-01,  1.1802e-01,\n",
      "         5.6768e-01, -7.5744e-02,  2.2792e-01,  3.7455e-01,  1.0764e-01,\n",
      "         2.3349e-01, -4.8613e-02,  1.4903e-02, -1.8861e-02,  7.2076e-02,\n",
      "        -1.2824e-01, -5.6068e-02,  3.4755e-01, -2.2559e-01,  2.7096e-01,\n",
      "        -1.4799e-01,  2.8941e-01, -1.9283e-01, -1.3008e-01, -2.8928e-01,\n",
      "        -4.0841e-01, -1.1667e-01, -1.8544e-01,  1.0841e-02,  3.3931e-01,\n",
      "         3.0211e-01,  7.9449e-02,  4.9943e-01,  2.9937e-01,  4.1393e-01,\n",
      "        -7.4495e-02,  1.2421e-01, -3.3169e-01, -1.6158e-01,  5.2858e-01,\n",
      "         6.5366e-01,  2.9973e-01,  1.5875e-01,  6.7577e-01,  7.7287e-02,\n",
      "         1.1412e-01,  1.2254e-02, -2.9015e-01, -1.7928e-01, -4.9186e-01,\n",
      "        -1.2598e-01,  1.6042e-01, -2.2954e-01,  5.0506e-02, -6.6345e-02,\n",
      "         1.9868e-01,  3.5123e-01, -1.7286e-01,  4.6147e-01, -4.6016e-01,\n",
      "        -1.4044e+00, -1.4856e-01,  4.7593e-01,  2.2862e-01, -6.8214e-01,\n",
      "        -1.9437e-01, -2.6027e-01,  3.2618e-04,  5.4230e-02,  3.6361e-01,\n",
      "         2.0118e-01,  1.9304e-01, -1.8354e-01,  5.7294e-02, -2.1890e-01,\n",
      "        -1.8793e-01, -8.5771e-02, -1.8986e-01,  1.8665e-01, -1.9236e-01,\n",
      "        -3.2537e-01, -2.1477e-01, -2.4442e-01,  5.9846e-01,  1.7391e-01,\n",
      "         7.1084e-01,  3.0003e-01, -4.2107e-01, -3.0604e-01, -2.8967e-02,\n",
      "         1.7653e-01,  5.4666e-01, -4.3913e-01, -5.1071e-02,  2.0685e-01,\n",
      "        -7.2354e-01, -3.6712e-01,  8.8936e-01,  3.4360e-01, -3.3631e-01,\n",
      "         3.8445e-01, -1.4627e-01,  1.8470e-01,  2.3577e-01, -6.6380e-01,\n",
      "        -4.7945e-01, -1.9683e-01,  5.3875e-02,  3.1728e-02,  1.5154e-01,\n",
      "         2.1521e-01, -2.7518e-01, -2.7524e-01,  1.6966e-01,  3.4476e-01,\n",
      "         3.6126e-01, -7.2814e-02,  6.3696e-03, -6.8936e-02,  1.1748e-01,\n",
      "        -3.3441e-01,  9.4751e-02, -2.6346e-01, -1.7579e-01, -6.5886e-02,\n",
      "         9.8776e-02, -3.8819e-02, -3.0414e-02, -4.4638e-02,  2.5021e-01,\n",
      "         3.0640e-01, -6.1699e-01,  2.2005e-01,  3.7970e-01,  1.3509e-01,\n",
      "        -4.9354e-01, -1.8982e-01,  1.1159e-01, -2.2430e-02, -2.6495e-02,\n",
      "         8.8934e-02,  5.1640e-02, -1.0745e-01,  3.3793e-01,  3.2827e-01,\n",
      "        -7.8899e-01,  3.4429e-01,  4.9727e-01, -4.2502e-01,  1.4580e-01,\n",
      "         7.2040e-02,  6.3826e-01,  1.1769e-02, -3.5771e-01,  2.4299e-02,\n",
      "         7.5025e-02,  5.5158e-01,  2.5258e-01,  2.7976e-01,  1.7559e-01,\n",
      "        -6.4084e-02,  3.5076e-01, -3.6487e-01,  1.7129e-01,  1.1715e-01,\n",
      "         7.5078e-01,  5.3097e-01, -3.5169e-01,  1.1246e-01,  1.2781e-01,\n",
      "         8.0519e-01, -2.4990e-01, -1.7553e-01, -4.3607e-01,  6.0099e-01,\n",
      "        -1.9220e-01, -1.3045e-01,  2.3349e-02,  1.9654e-01, -7.5144e-02,\n",
      "        -3.4489e-04, -3.9902e-01, -6.9974e-02, -2.1452e-01, -2.7759e-01,\n",
      "        -7.5542e-01, -4.4597e-03,  3.7904e-01,  1.5843e-02,  2.5780e-01,\n",
      "        -2.1381e-01, -1.3249e-01,  3.1974e-01, -2.6245e-03,  2.6878e-01,\n",
      "         4.3700e-01, -8.5989e-02,  5.2564e-01,  8.4453e-02, -2.3008e-02,\n",
      "         2.7029e-01, -1.2239e-01,  1.0191e-01,  4.5072e-01, -2.9237e-01,\n",
      "         2.4293e-01,  2.4587e-01, -3.0860e-01, -2.7456e-01, -2.6117e-01,\n",
      "         7.3651e-01,  7.0003e-02,  5.1902e-02,  9.8995e-02,  3.2050e-01,\n",
      "        -5.5318e-02,  4.1742e-01, -5.1779e-01, -1.5360e-01, -7.4256e-01,\n",
      "         6.7100e-01,  1.3189e-01,  5.2296e-01,  1.6764e-01, -1.3867e-01,\n",
      "         1.3756e+00, -5.2925e-02,  3.9862e-01,  7.2141e-02,  2.6560e-01,\n",
      "         4.6330e-01,  5.7191e-02,  6.7450e-01,  4.9835e-01, -1.5570e-01,\n",
      "         4.4757e-02,  5.0085e-01,  2.8037e-01,  3.3379e-02, -2.8748e-01,\n",
      "        -4.2730e-02, -1.3433e-01, -2.7426e-01, -1.6603e-01,  6.1011e-01,\n",
      "        -2.6176e-02, -2.3683e-01, -1.1369e-01, -1.4368e-01,  1.0938e-01,\n",
      "         6.4238e-02,  6.0057e-01,  4.1425e-01, -2.3232e-01, -5.2258e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([-8.6931e-02,  2.5377e-01,  1.6810e-01,  7.5704e-02,  1.8061e-02,\n",
      "        -6.4389e-01,  1.7444e-01, -1.6433e-01, -2.4357e-01,  2.0393e+00,\n",
      "        -1.8395e-01, -3.2359e-01,  3.9382e-01,  1.1465e-01, -5.8393e-01,\n",
      "        -2.8376e-01, -7.9123e-03,  1.5639e+00,  5.6717e-02,  8.9370e-01,\n",
      "         2.6189e-01, -2.7468e-01,  9.5437e-02, -8.2834e-02,  3.3205e-01,\n",
      "         2.5640e-01,  7.9347e-02, -4.0802e-01, -4.5415e-02, -1.2211e-01,\n",
      "         7.7319e-02,  3.0104e-01, -6.9792e-01,  3.7858e-01, -3.2511e-01,\n",
      "        -3.4816e-01, -1.4897e-01, -1.2082e-01, -3.6768e-01, -4.6140e-01,\n",
      "         3.6606e-01, -1.7980e-01,  5.5668e-01,  1.5601e-01,  3.5077e-01,\n",
      "        -2.1335e-01,  3.0609e-02,  2.9482e-02,  1.7253e-01,  1.1802e-01,\n",
      "         5.6768e-01, -7.5744e-02,  2.2792e-01,  3.7455e-01,  1.0764e-01,\n",
      "         2.3349e-01, -4.8613e-02,  1.4903e-02, -1.8861e-02,  7.2076e-02,\n",
      "        -1.2824e-01, -5.6068e-02,  3.4755e-01, -2.2559e-01,  2.7096e-01,\n",
      "        -1.4799e-01,  2.8941e-01, -1.9283e-01, -1.3008e-01, -2.8928e-01,\n",
      "        -4.0841e-01, -1.1667e-01, -1.8544e-01,  1.0841e-02,  3.3931e-01,\n",
      "         3.0211e-01,  7.9449e-02,  4.9943e-01,  2.9937e-01,  4.1393e-01,\n",
      "        -7.4495e-02,  1.2421e-01, -3.3169e-01, -1.6158e-01,  5.2858e-01,\n",
      "         6.5366e-01,  2.9973e-01,  1.5875e-01,  6.7577e-01,  7.7287e-02,\n",
      "         1.1412e-01,  1.2254e-02, -2.9015e-01, -1.7928e-01, -4.9186e-01,\n",
      "        -1.2598e-01,  1.6042e-01, -2.2954e-01,  5.0506e-02, -6.6345e-02,\n",
      "         1.9868e-01,  3.5123e-01, -1.7286e-01,  4.6147e-01, -4.6016e-01,\n",
      "        -1.4044e+00, -1.4856e-01,  4.7593e-01,  2.2862e-01, -6.8214e-01,\n",
      "        -1.9437e-01, -2.6027e-01,  3.2618e-04,  5.4230e-02,  3.6361e-01,\n",
      "         2.0118e-01,  1.9304e-01, -1.8354e-01,  5.7294e-02, -2.1890e-01,\n",
      "        -1.8793e-01, -8.5771e-02, -1.8986e-01,  1.8665e-01, -1.9236e-01,\n",
      "        -3.2537e-01, -2.1477e-01, -2.4442e-01,  5.9846e-01,  1.7391e-01,\n",
      "         7.1084e-01,  3.0003e-01, -4.2107e-01, -3.0604e-01, -2.8967e-02,\n",
      "         1.7653e-01,  5.4666e-01, -4.3913e-01, -5.1071e-02,  2.0685e-01,\n",
      "        -7.2354e-01, -3.6712e-01,  8.8936e-01,  3.4360e-01, -3.3631e-01,\n",
      "         3.8445e-01, -1.4627e-01,  1.8470e-01,  2.3577e-01, -6.6380e-01,\n",
      "        -4.7945e-01, -1.9683e-01,  5.3875e-02,  3.1728e-02,  1.5154e-01,\n",
      "         2.1521e-01, -2.7518e-01, -2.7524e-01,  1.6966e-01,  3.4476e-01,\n",
      "         3.6126e-01, -7.2814e-02,  6.3696e-03, -6.8936e-02,  1.1748e-01,\n",
      "        -3.3441e-01,  9.4751e-02, -2.6346e-01, -1.7579e-01, -6.5886e-02,\n",
      "         9.8776e-02, -3.8819e-02, -3.0414e-02, -4.4638e-02,  2.5021e-01,\n",
      "         3.0640e-01, -6.1699e-01,  2.2005e-01,  3.7970e-01,  1.3509e-01,\n",
      "        -4.9354e-01, -1.8982e-01,  1.1159e-01, -2.2430e-02, -2.6495e-02,\n",
      "         8.8934e-02,  5.1640e-02, -1.0745e-01,  3.3793e-01,  3.2827e-01,\n",
      "        -7.8899e-01,  3.4429e-01,  4.9727e-01, -4.2502e-01,  1.4580e-01,\n",
      "         7.2040e-02,  6.3826e-01,  1.1769e-02, -3.5771e-01,  2.4299e-02,\n",
      "         7.5025e-02,  5.5158e-01,  2.5258e-01,  2.7976e-01,  1.7559e-01,\n",
      "        -6.4084e-02,  3.5076e-01, -3.6487e-01,  1.7129e-01,  1.1715e-01,\n",
      "         7.5078e-01,  5.3097e-01, -3.5169e-01,  1.1246e-01,  1.2781e-01,\n",
      "         8.0519e-01, -2.4990e-01, -1.7553e-01, -4.3607e-01,  6.0099e-01,\n",
      "        -1.9220e-01, -1.3045e-01,  2.3349e-02,  1.9654e-01, -7.5144e-02,\n",
      "        -3.4489e-04, -3.9902e-01, -6.9974e-02, -2.1452e-01, -2.7759e-01,\n",
      "        -7.5542e-01, -4.4597e-03,  3.7904e-01,  1.5843e-02,  2.5780e-01,\n",
      "        -2.1381e-01, -1.3249e-01,  3.1974e-01, -2.6245e-03,  2.6878e-01,\n",
      "         4.3700e-01, -8.5989e-02,  5.2564e-01,  8.4453e-02, -2.3008e-02,\n",
      "         2.7029e-01, -1.2239e-01,  1.0191e-01,  4.5072e-01, -2.9237e-01,\n",
      "         2.4293e-01,  2.4587e-01, -3.0860e-01, -2.7456e-01, -2.6117e-01,\n",
      "         7.3651e-01,  7.0003e-02,  5.1902e-02,  9.8995e-02,  3.2050e-01,\n",
      "        -5.5318e-02,  4.1742e-01, -5.1779e-01, -1.5360e-01, -7.4256e-01,\n",
      "         6.7100e-01,  1.3189e-01,  5.2296e-01,  1.6764e-01, -1.3867e-01,\n",
      "         1.3756e+00, -5.2925e-02,  3.9862e-01,  7.2141e-02,  2.6560e-01,\n",
      "         4.6330e-01,  5.7191e-02,  6.7450e-01,  4.9835e-01, -1.5570e-01,\n",
      "         4.4757e-02,  5.0085e-01,  2.8037e-01,  3.3379e-02, -2.8748e-01,\n",
      "        -4.2730e-02, -1.3433e-01, -2.7426e-01, -1.6603e-01,  6.1011e-01,\n",
      "        -2.6176e-02, -2.3683e-01, -1.1369e-01, -1.4368e-01,  1.0938e-01,\n",
      "         6.4238e-02,  6.0057e-01,  4.1425e-01, -2.3232e-01, -5.2258e-01]), tensor([-8.6864e-02,  1.9161e-01,  1.0915e-01, -3.4321e-01,  2.0368e-01,\n",
      "        -2.4777e-01,  4.6046e-01, -3.6570e-01, -1.9804e-01,  1.7379e+00,\n",
      "        -4.3507e-01,  9.6135e-02,  1.5601e-01,  2.3903e-01, -4.1931e-01,\n",
      "        -9.5131e-02,  4.4342e-02,  1.2392e+00,  1.1157e-02, -2.2522e-01,\n",
      "         3.8411e-01, -1.1606e-01, -3.9036e-02,  3.6106e-02, -5.2676e-04,\n",
      "        -1.2154e-01, -5.6884e-02,  4.1425e-01,  3.8248e-01,  2.3590e-01,\n",
      "        -8.5550e-02,  8.5120e-02, -3.7976e-02, -1.6109e-01,  4.6274e-01,\n",
      "         4.5681e-01,  1.5099e-01,  1.1551e-01, -5.9356e-03, -1.4960e-01,\n",
      "         1.1590e-01, -1.1414e-01, -1.9262e-01, -2.5766e-02,  1.6849e-01,\n",
      "         4.7380e-02, -4.7483e-01, -1.6071e-01, -9.6243e-02,  1.8192e-01,\n",
      "         1.4954e-01,  1.2130e-01,  9.3597e-04, -5.7363e-01, -1.7880e-01,\n",
      "        -1.4485e-01,  1.1158e-01, -1.8386e-01,  3.4030e-01,  2.1795e-01,\n",
      "        -2.6490e-01, -1.1665e-01,  6.4359e-01,  9.5316e-03,  5.4370e-02,\n",
      "        -2.7008e-01, -4.2555e-01,  1.8764e-02, -3.0406e-01, -3.5391e-02,\n",
      "         1.6890e-01, -9.6122e-02,  4.8576e-01,  2.2636e-01,  8.6754e-02,\n",
      "         3.2521e-01,  1.0200e-01, -2.1386e-01,  1.6353e-01,  5.7040e-01,\n",
      "        -4.8834e-01, -2.9669e-02, -1.2532e-01,  1.5784e-01, -1.6349e-01,\n",
      "         1.0762e-01,  6.4525e-01, -8.3646e-01,  1.3500e-01,  2.1632e-01,\n",
      "        -3.0822e-01, -1.5673e-01,  2.7079e-02, -4.6443e-02, -4.0391e-02,\n",
      "        -3.1256e-01, -4.4964e-01, -4.7512e-01,  4.7597e-02, -1.2785e-01,\n",
      "        -1.2521e-01,  5.1054e-01, -8.2481e-02, -2.9605e-01,  6.6536e-02,\n",
      "         3.9705e-01, -1.6395e-02,  1.8592e-01, -1.1063e-02,  1.3644e-01,\n",
      "         1.4628e-01, -7.0372e-01,  4.9209e-01,  3.8754e-03,  6.8155e-02,\n",
      "         4.2250e-01,  1.2923e-01, -3.2346e-01, -2.0351e-01, -1.1109e-01,\n",
      "         1.0363e-01,  4.8225e-02,  1.2263e-01, -2.7850e-02, -1.6093e-01,\n",
      "         1.3469e-01, -7.8230e-02, -1.1730e-01,  3.5181e-01, -2.8887e-01,\n",
      "         3.4357e-01, -2.6096e-01,  1.2608e-01,  2.7807e-01,  1.5766e-01,\n",
      "         1.8333e-02,  1.5407e-01,  7.3841e-02, -5.7197e-01,  1.7403e-01,\n",
      "        -1.4982e+00,  2.2341e-01,  2.7361e-01,  9.2857e-03,  6.7072e-02,\n",
      "         2.4006e-02, -1.1183e-01,  3.8380e-01, -4.3853e-01,  1.5147e-01,\n",
      "         2.1548e-01,  4.5302e-01, -1.8521e-01, -2.0169e-02,  2.4229e-01,\n",
      "        -2.9120e-01, -3.4095e-02, -2.3276e-01,  2.1502e-01, -2.2064e-02,\n",
      "        -4.5589e-02, -1.2733e-01, -9.7544e-02, -9.7579e-02, -7.0610e-02,\n",
      "         1.7009e-01, -3.5061e-01, -2.4645e-01,  3.0984e-01,  7.3659e-01,\n",
      "        -8.6049e-02, -2.4189e-01, -1.6846e-01,  2.2105e-01, -6.1358e-02,\n",
      "         1.6661e-01,  2.2734e-01,  1.1214e-01,  1.3455e-01, -3.4864e-01,\n",
      "        -8.4708e-02, -1.0605e-01, -1.1327e-01, -4.7898e-01, -2.2993e-01,\n",
      "        -7.0329e-02, -3.3025e-01, -5.4552e-02,  1.7280e-01, -7.2809e-02,\n",
      "         1.4718e-01,  3.1015e-01, -1.7731e-01, -2.6494e-01,  8.8670e-02,\n",
      "         9.0799e-02, -2.7828e-01, -1.7866e-02,  6.5535e-01,  4.6306e-01,\n",
      "        -9.4648e-02,  2.4050e-01,  2.2981e-01, -1.0659e-01, -1.3292e-01,\n",
      "        -1.5076e-01,  3.0420e-01, -8.7631e-02, -4.9375e-02, -2.0011e-01,\n",
      "        -2.3972e-01, -1.8101e-01, -1.2819e-01, -1.0902e-01,  1.3651e-01,\n",
      "        -2.7016e-01, -2.5798e-02,  3.1209e-01, -5.6491e-01, -1.2271e-01,\n",
      "         1.5309e-01,  1.0768e-01, -4.9543e-01, -9.4164e-03,  2.3867e-01,\n",
      "         3.7198e-02, -6.6242e-02,  1.4924e-01, -1.6148e-01, -2.5135e-01,\n",
      "        -4.1731e-01, -5.2517e-01,  5.8631e-01,  1.9534e-02, -1.2889e-01,\n",
      "        -1.4278e-01,  2.5435e-01, -1.2348e-01, -1.6830e-01, -7.7178e-02,\n",
      "        -4.5393e-02, -1.6850e-01, -1.1748e-01, -2.0589e-01,  1.0368e-01,\n",
      "        -5.2111e-01,  6.4614e-01,  7.2337e-02, -2.3209e-01,  2.9604e-01,\n",
      "         4.1656e-01, -6.7341e-02, -2.6587e-01,  4.0931e-02, -3.2838e-01,\n",
      "         1.7573e-01, -1.1610e-01,  4.5733e-02,  4.3051e-02, -3.7436e-02,\n",
      "        -2.8593e-01, -4.9150e-01,  1.6184e-01, -1.5258e-02, -1.7994e-01,\n",
      "        -6.8346e-02, -6.7421e-02,  6.4331e-02,  6.7300e-01,  3.1727e-01,\n",
      "        -9.0806e-02,  7.1224e-02,  2.6468e-02, -1.1935e-01, -5.9743e-01,\n",
      "         1.5141e-01,  1.9130e-01, -3.9930e-01,  1.7107e-01,  5.4200e-01,\n",
      "         3.8492e-01,  1.9350e-01, -3.4072e-02, -3.0936e-01,  9.9719e-02,\n",
      "         3.7634e-03,  1.6417e-01, -1.2316e-02,  2.2114e-02,  9.3504e-03,\n",
      "        -1.6615e-01, -2.6295e-01, -4.4568e-02, -1.3297e-01,  4.2561e-01,\n",
      "         7.1100e-02, -1.2816e-01, -1.5160e-02,  1.1108e-01,  2.0650e-01]), tensor([ 2.4498e-01,  1.7973e-01, -4.9191e-01,  1.2429e-01,  5.4470e-01,\n",
      "        -1.1258e-01, -2.2837e-01, -4.2478e-02,  1.3143e-01,  2.6448e+00,\n",
      "        -2.5930e-01,  3.0903e-01, -4.6845e-02,  5.8319e-02, -1.9684e-01,\n",
      "        -2.2155e-02, -2.2821e-01,  1.1278e+00, -2.5243e-01,  1.1636e-01,\n",
      "         7.5598e-02,  4.8716e-02,  1.8727e-01, -3.2490e-01,  2.8231e-02,\n",
      "        -3.0675e-01,  5.8118e-03, -2.4703e-01,  3.4676e-02, -1.4749e-01,\n",
      "         9.1599e-02,  2.9625e-01,  7.5177e-02,  2.5304e-01,  8.6464e-02,\n",
      "         3.9885e-03, -1.5262e-01,  9.2531e-02, -2.7002e-01, -1.5531e-01,\n",
      "        -2.3120e-01,  2.3151e-01, -4.7052e-01, -2.0252e-01,  1.5311e-01,\n",
      "         2.8793e-01, -3.8947e-01, -2.2848e-01, -2.8524e-01, -7.7195e-02,\n",
      "         1.2883e-01,  3.6220e-01, -1.5384e-01,  1.4605e-01,  2.1578e-01,\n",
      "        -9.9416e-02,  1.2956e-01, -1.5691e-01, -8.9919e-02, -3.8154e-01,\n",
      "        -2.6094e-01, -5.6228e-02,  1.5524e-01,  3.6326e-01,  3.9776e-01,\n",
      "        -1.5396e-01, -2.1966e-01, -3.2676e-03,  1.9904e-01,  1.7114e-01,\n",
      "         2.9464e-02,  9.9572e-02,  5.3585e-01,  6.4559e-02, -8.0625e-02,\n",
      "        -1.2405e-01,  3.2002e-01, -2.9716e-01, -2.0656e-01, -5.6908e-02,\n",
      "        -1.7928e-01,  3.0715e-01,  9.1507e-02,  2.8014e-01, -7.8898e-02,\n",
      "         2.4502e-01,  3.7296e-01, -1.9800e-01,  4.6024e-01,  1.6299e-02,\n",
      "        -3.1077e-02,  8.8482e-02,  1.1320e-01,  2.8058e-01,  1.8246e-01,\n",
      "        -2.0707e-01, -5.1813e-01, -3.5000e-01,  1.5409e-01, -2.3215e-01,\n",
      "        -2.1623e-01, -1.7890e-01,  2.6002e-01,  6.2191e-02,  4.0326e-01,\n",
      "        -5.8886e-01,  1.3819e-02,  3.4795e-02, -2.1756e-01,  3.8578e-01,\n",
      "        -1.5722e-01, -1.2098e-01,  4.8606e-02,  1.3307e-01,  4.1042e-01,\n",
      "         2.6994e-01,  5.8005e-02, -7.7229e-02, -2.8127e-01, -2.9094e-02,\n",
      "         1.7076e-01, -2.3250e-02,  3.2220e-01,  3.2751e-01,  6.7714e-02,\n",
      "         1.4124e-01, -2.7823e-01, -1.7043e-01, -1.5698e-01, -6.3559e-02,\n",
      "        -1.3311e-01, -2.6129e-01, -9.6243e-02, -1.1270e-01,  7.5621e-02,\n",
      "        -4.2429e-02,  1.8267e-02,  2.6391e-02, -1.2504e-01,  6.7258e-02,\n",
      "        -1.7528e+00,  1.6933e-01, -3.1463e-01,  6.4982e-02,  1.8901e-01,\n",
      "        -1.8856e-01, -1.5670e-01, -1.2425e-01, -4.1318e-02,  3.4542e-02,\n",
      "        -3.8035e-01, -9.9705e-02,  1.4546e-01, -2.3221e-01, -1.7633e-01,\n",
      "         1.1423e-01, -6.1160e-02, -7.3944e-02, -1.4333e-01,  1.6908e-01,\n",
      "        -2.2675e-02,  9.6898e-02, -1.3966e-01,  1.1116e-01,  5.3619e-02,\n",
      "        -3.7228e-01,  1.0494e-01,  9.0221e-02,  3.6803e-01,  1.4964e-01,\n",
      "        -9.8395e-02, -3.1496e-01, -1.7175e-01, -4.3477e-01,  9.1846e-02,\n",
      "         8.3158e-02, -3.7460e-01, -1.1624e-01,  6.7491e-02, -1.0670e-01,\n",
      "         2.3328e-01, -2.1242e-01, -1.7353e-01, -2.2342e-01,  7.1008e-02,\n",
      "         1.6430e-01, -1.6975e-01, -5.2061e-01,  1.9495e-01,  5.8516e-02,\n",
      "        -8.0125e-02, -2.0989e-01,  2.1990e-01, -7.0059e-02,  2.7256e-01,\n",
      "         2.7535e-01,  1.5762e-01, -1.5093e-01,  4.5139e-02,  7.3498e-01,\n",
      "        -3.3560e-01,  2.8694e-01, -6.3161e-02, -7.8611e-02,  1.3628e-01,\n",
      "         3.8350e-01,  1.2466e-01, -2.4877e-01, -1.0306e-01, -1.5148e-01,\n",
      "        -5.8404e-02, -2.4681e-01,  1.3591e-01, -1.3578e-01,  1.5568e-01,\n",
      "         2.0310e-01, -1.9195e-01,  2.1136e-01, -3.1806e-01,  1.1897e-01,\n",
      "        -1.1872e-01, -1.9652e-01, -1.9575e-01, -2.3096e-02,  4.6078e-01,\n",
      "        -4.1096e-01, -2.8599e-01,  1.2833e-01,  2.0667e-01, -2.0054e-01,\n",
      "        -4.2896e-01, -1.1261e-02,  4.4412e-01,  2.4096e-01,  3.8138e-02,\n",
      "        -2.3037e-01,  3.0130e-01, -2.0100e-01,  8.2807e-03, -6.2039e-02,\n",
      "         4.8129e-01,  1.6556e-01,  8.4501e-02,  4.6395e-01, -1.0592e-01,\n",
      "        -2.5434e-01, -2.4599e-01, -6.6526e-02, -6.6260e-01,  2.7794e-01,\n",
      "        -2.2119e-01, -1.4337e-01,  1.2034e-01, -1.0214e-01, -2.0465e-01,\n",
      "         5.1383e-01,  3.2635e-01,  7.7044e-02,  1.1295e-01, -1.1206e-03,\n",
      "        -1.9568e-01,  8.8547e-03,  4.6611e-01, -4.1398e-01,  3.6870e-01,\n",
      "         2.0834e-02, -9.7065e-02, -1.7683e-01,  6.9659e-01,  8.6765e-02,\n",
      "         2.7708e-02, -1.4932e-01, -1.3559e-01, -3.8356e-01,  3.0686e-02,\n",
      "        -1.2247e-01,  4.5502e-02, -6.3452e-02,  2.4374e-02,  1.1859e-01,\n",
      "         1.4230e-01, -5.8382e-02, -2.9158e-01,  9.9985e-02, -1.3216e-01,\n",
      "         6.5382e-02, -1.4264e-01, -1.3792e-01,  4.1462e-01, -1.5035e-01,\n",
      "         4.9602e-03,  4.8956e-02,  3.8412e-03, -3.2283e-01,  2.7687e-01,\n",
      "        -2.6963e-01, -1.1004e-01, -1.5867e-01,  1.7981e-01,  1.9019e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 1.0618e-01, -1.5243e-01, -6.2126e-02,  9.4499e-02,  4.1116e-01,\n",
      "        -1.8721e-01, -1.6263e-01, -1.7088e-03,  3.8844e-01,  2.4993e+00,\n",
      "         5.9315e-02,  3.7034e-02,  3.5450e-01, -4.8101e-01,  2.3037e-01,\n",
      "        -5.2577e-01, -3.9569e-01,  8.8071e-01,  7.6004e-02,  1.7396e-01,\n",
      "         3.8861e-01,  6.0014e-01, -3.3831e-01, -3.1118e-01, -2.4859e-01,\n",
      "         1.8057e-01, -2.4039e-01,  5.2105e-02, -5.6059e-02,  1.3235e-02,\n",
      "        -3.5413e-01, -4.8330e-02, -1.7775e-01,  1.4367e-01,  3.4010e-01,\n",
      "         1.3782e-02, -1.0325e-01,  1.3748e-01,  2.5917e-01, -3.2197e-01,\n",
      "         3.1810e-01, -1.0755e-01, -3.1917e-01, -6.1684e-02,  4.8625e-01,\n",
      "         2.4602e-01, -3.9416e-02, -1.1421e-01, -3.5104e-01, -7.2778e-02,\n",
      "         2.7352e-01, -2.1596e-02, -4.6802e-02,  2.5156e-01, -1.9392e-02,\n",
      "         4.2503e-02, -3.3746e-01,  3.4077e-01,  2.8695e-01, -2.0506e-01,\n",
      "        -2.0327e-01,  2.2446e-01,  2.3778e-01,  2.0096e-01,  7.5477e-02,\n",
      "        -2.8725e-01, -1.4457e-01,  1.6358e-01,  5.6577e-02,  8.5565e-01,\n",
      "        -1.5092e-01, -1.6139e-01, -2.2404e-01,  7.0616e-01, -5.0074e-01,\n",
      "         5.6715e-02, -2.5611e-01, -2.3357e-01, -1.2682e-01, -4.8076e-01,\n",
      "        -6.0287e-01,  5.3624e-01, -2.8682e-01, -5.4010e-03, -1.6342e-01,\n",
      "        -1.1488e-01,  5.6652e-01,  1.6973e-01,  3.7347e-01, -1.7455e-01,\n",
      "         3.9466e-01, -4.7293e-01,  9.1782e-02, -7.9003e-02,  1.5903e-01,\n",
      "        -7.5274e-01, -4.9228e-01, -2.0391e-01,  3.6798e-01, -3.2692e-01,\n",
      "        -1.5068e-01,  2.0213e-01, -2.6766e-01, -5.8092e-02,  1.1304e-01,\n",
      "        -5.0597e-01,  1.0907e-01, -1.9702e-01,  1.1426e-01,  3.5837e-01,\n",
      "        -5.0204e-02, -1.4627e-01, -1.6928e-01,  4.8561e-02,  1.0756e-01,\n",
      "        -2.6395e-01,  2.4174e-02, -1.2779e-01, -1.5442e-01,  6.4580e-01,\n",
      "         5.7893e-02,  1.0517e-01,  1.2539e-01,  1.0355e-01, -5.6904e-01,\n",
      "        -1.9816e-02,  6.8360e-02, -1.4468e-01, -4.2643e-01,  7.3314e-02,\n",
      "        -2.6496e-01, -4.8445e-02, -1.2275e-01,  3.8691e-01,  2.9685e-01,\n",
      "        -1.5251e-01,  1.4966e-01,  6.0380e-02, -1.4357e-01, -4.7216e-02,\n",
      "        -1.8219e+00,  1.8755e-01, -2.2802e-01, -3.3161e-01,  1.8082e-01,\n",
      "        -3.1718e-01, -2.4789e-01, -4.0793e-01, -1.0863e-01, -1.9101e-02,\n",
      "        -7.3696e-01, -2.5828e-01, -3.7829e-01,  4.6461e-02, -5.6323e-02,\n",
      "         1.3211e-01,  4.8712e-02,  1.2835e-01, -1.0296e-02, -4.9942e-01,\n",
      "         1.2080e-01, -9.5265e-02, -2.0801e-01,  8.5368e-02,  3.3766e-01,\n",
      "        -3.8235e-01, -9.6507e-02,  8.5062e-02,  2.6877e-01, -6.5446e-03,\n",
      "        -3.2521e-01, -3.4163e-01, -2.4974e-01, -6.8904e-01, -2.4496e-01,\n",
      "        -2.8664e-03,  3.0834e-01,  5.9978e-01, -8.0389e-02, -4.1924e-01,\n",
      "        -4.1174e-01, -1.8848e-01, -1.1325e-02, -2.5597e-01, -1.4408e-01,\n",
      "         1.0138e-01, -1.3955e-01,  3.4002e-01, -2.7847e-02,  2.5247e-01,\n",
      "        -3.3159e-01,  3.3714e-02, -3.3531e-03,  3.5987e-01, -4.2088e-01,\n",
      "         4.0708e-01,  4.0118e-01, -4.1302e-01, -4.3735e-01,  1.6187e-02,\n",
      "        -4.3081e-01,  2.4044e-01, -2.1664e-01, -6.5414e-02,  3.5477e-01,\n",
      "         8.4734e-02,  3.1257e-01,  1.1688e-01, -3.6184e-01, -1.0484e-02,\n",
      "        -2.3138e-01, -2.2612e-01,  1.4276e-01, -3.5441e-03,  2.5343e-01,\n",
      "         2.6083e-01, -3.0570e-01, -2.9950e-01, -1.0386e-01, -1.0073e-01,\n",
      "        -3.0273e-01, -5.4184e-02, -4.3250e-01,  1.9233e-04,  7.4002e-02,\n",
      "        -1.3238e-01,  1.0091e-03,  2.9990e-01,  5.1446e-01,  2.4811e-01,\n",
      "        -3.1364e-01, -1.3692e-01, -6.9617e-02, -1.0973e-01, -2.5384e-01,\n",
      "        -3.9927e-01, -3.7628e-01,  1.8322e-01,  3.9642e-01,  2.2108e-01,\n",
      "        -2.5693e-02,  2.7510e-01,  3.3457e-01, -2.1377e-01, -2.5945e-01,\n",
      "        -1.1236e-01, -1.1706e-01, -2.4085e-01, -1.4702e-01,  4.5058e-01,\n",
      "         1.2177e-01, -2.7612e-01,  6.1680e-01,  2.3487e-01,  5.9399e-02,\n",
      "         1.6169e-01,  2.5882e-01, -1.4620e-01, -9.5626e-02,  1.8351e-01,\n",
      "        -6.9270e-02,  2.2539e-01,  4.6179e-02, -2.0428e-01,  3.2836e-01,\n",
      "        -2.3054e-02, -7.9511e-01, -4.9857e-01, -2.8789e-01,  3.1397e-02,\n",
      "         6.4125e-01, -6.0171e-02,  2.4961e-02, -2.2604e-01, -1.3664e-01,\n",
      "         2.2395e-01,  1.7334e-01,  1.4544e-01, -4.9798e-02, -2.8190e-01,\n",
      "         5.1398e-02,  2.5113e-01, -4.1185e-01, -9.7907e-03, -5.5128e-01,\n",
      "        -2.6816e-01, -2.1186e-01, -3.1193e-01,  1.4969e-01, -3.1633e-01,\n",
      "        -1.2642e-01, -4.1437e-01,  3.2047e-01, -6.7030e-01, -2.4566e-01,\n",
      "         1.6989e-01, -1.7454e-01,  2.6481e-01,  1.0389e-01, -1.2794e-01]), tensor([-2.7483e-01,  1.2249e-01,  1.3033e-01,  2.0637e-01, -3.1709e-02,\n",
      "         3.4632e-01, -2.3252e-01, -1.5254e-02,  2.8030e-01,  2.2904e+00,\n",
      "        -4.1915e-01,  2.7619e-01,  1.2825e-01, -7.4462e-02,  1.3589e-01,\n",
      "         7.3838e-02, -2.2377e-01,  1.2075e+00, -2.7073e-01,  7.2912e-02,\n",
      "         1.3378e-01, -6.3544e-02, -3.0955e-02,  2.9335e-01,  1.1667e-01,\n",
      "        -1.7785e-01, -3.1805e-02,  4.2490e-02, -2.6658e-01,  2.7283e-02,\n",
      "        -3.4750e-01,  5.3246e-01,  1.0854e-01,  2.0026e-02,  2.9807e-01,\n",
      "        -2.1760e-01, -3.6432e-02, -1.6830e-02, -3.1890e-01,  3.5611e-01,\n",
      "        -1.2362e-01,  3.4960e-01, -2.7771e-01,  1.2422e-01, -1.7454e-01,\n",
      "         3.8983e-01,  2.6953e-02,  3.6095e-01,  1.4894e-01,  1.1218e-02,\n",
      "        -1.0717e-01, -2.3021e-01,  1.8816e-01,  1.6307e-02,  1.7303e-01,\n",
      "        -2.6454e-01,  1.8761e-01,  2.3263e-02,  4.5820e-01, -1.8164e-01,\n",
      "         2.7718e-01,  4.0620e-02, -1.2565e-01, -1.8392e-01,  2.4845e-01,\n",
      "        -2.9541e-01, -2.2753e-01,  8.3055e-03,  1.7642e-01,  2.6886e-01,\n",
      "        -1.9765e-02,  2.8409e-02,  3.5120e-01,  2.3305e-01, -3.0041e-02,\n",
      "        -2.3275e-01, -5.8456e-02,  1.8419e-01, -1.8737e-01,  5.7082e-02,\n",
      "         2.0862e-01,  5.0261e-02, -1.9403e-01, -3.4227e-01,  1.5546e-01,\n",
      "        -9.0878e-02, -2.3614e-01, -1.2965e-01,  1.0873e-01,  1.0695e-01,\n",
      "        -3.3232e-01,  1.1788e-01, -4.8256e-01,  4.0456e-01,  2.2543e-01,\n",
      "         3.6913e-01, -6.1486e-02,  1.6887e-01,  3.0784e-01,  4.2433e-01,\n",
      "         1.5938e-01, -5.9806e-01, -1.0171e-02, -4.0228e-01,  5.8709e-02,\n",
      "        -1.3360e+00,  3.6881e-01, -4.1036e-01,  3.0043e-01,  1.5679e-01,\n",
      "        -7.6981e-02, -1.4550e-01, -1.3762e-01, -1.6091e-01,  1.7273e-03,\n",
      "         2.2671e-01,  1.1926e-01,  2.0692e-01,  1.5165e-02,  8.9123e-03,\n",
      "         7.8096e-02, -1.7920e-01, -1.1388e-02,  6.2830e-02, -2.5935e-01,\n",
      "         1.1116e-02, -3.2517e-01, -4.4919e-01,  2.4225e-01, -5.4012e-02,\n",
      "        -1.6165e-01, -4.8195e-02, -8.2311e-02, -1.7298e-01,  1.1357e-01,\n",
      "         1.3761e-01, -2.1684e-01, -1.4794e-02,  3.0397e-02, -2.0290e-01,\n",
      "        -2.0423e+00, -1.8754e-01, -1.3149e-01,  4.1857e-01,  3.2331e-01,\n",
      "        -3.9745e-01, -4.8975e-01,  1.1253e-01, -4.2415e-02, -2.1286e-01,\n",
      "         2.2564e-02,  3.4329e-01,  4.1795e-01, -2.5504e-02, -8.4796e-02,\n",
      "         4.4614e-04, -1.2343e-01, -1.9541e-01, -2.9208e-02,  1.6260e-01,\n",
      "        -3.2527e-01,  4.1088e-01, -8.5093e-02,  2.1184e-01, -1.7173e-01,\n",
      "        -1.1284e-01,  2.3846e-01,  1.2531e-01,  1.9986e-01, -1.4444e-01,\n",
      "         3.5793e-01, -8.9630e-02, -1.4423e-01, -3.6620e-01, -1.5390e-01,\n",
      "        -4.5811e-01, -3.9319e-01, -1.3929e-02,  1.0750e-01, -1.3528e-01,\n",
      "         1.1005e-01, -4.4399e-01, -1.5502e-01, -9.8434e-02,  9.2489e-02,\n",
      "        -1.1604e-01, -3.6174e-01, -3.2645e-01,  8.9676e-02,  5.6836e-02,\n",
      "        -1.1546e-01,  4.2248e-02, -1.5059e-01,  4.5798e-01,  2.2015e-01,\n",
      "         1.4900e-01, -9.6128e-02,  2.7555e-02, -1.9483e-01,  1.6366e-01,\n",
      "        -1.6545e-01,  1.4592e-02, -1.4149e-01,  1.1413e-01,  1.0939e-01,\n",
      "         1.6341e-01,  4.1780e-01,  5.3562e-03,  1.3834e-01,  2.6541e-01,\n",
      "        -6.0542e-02,  2.0385e-01,  2.2659e-01, -3.7253e-01,  6.1144e-02,\n",
      "         5.2167e-02, -1.4911e-01, -2.9522e-01, -4.4038e-02,  3.0952e-01,\n",
      "        -9.9955e-02, -1.6346e-01, -1.7438e-01, -2.3150e-02,  2.0444e-02,\n",
      "         4.8692e-02, -2.4333e-02,  1.2530e-01, -1.2783e-01,  1.1443e-01,\n",
      "        -1.3660e-02,  9.4194e-02, -2.3950e-01,  2.8656e-01,  4.5242e-03,\n",
      "         3.1018e-02,  9.9030e-02, -1.9887e-01, -2.1852e-01, -7.0122e-02,\n",
      "        -3.9911e-01,  9.8339e-02,  3.6082e-02, -2.6370e-01, -1.1249e-01,\n",
      "        -1.9461e-02,  2.5686e-01, -3.3593e-01, -1.2732e-01, -3.0851e-01,\n",
      "         1.3341e-01, -4.0051e-01,  4.0224e-01, -2.7651e-01, -9.0978e-02,\n",
      "         2.2513e-01,  8.6455e-02,  2.1865e-01, -7.2983e-03,  3.8181e-02,\n",
      "         1.5673e-01, -2.0952e-02,  1.6842e-01, -1.1667e-01,  2.0150e-01,\n",
      "        -1.9092e-01, -1.4036e-01,  7.2043e-03,  3.2245e-01, -8.0468e-02,\n",
      "         2.4607e-01, -5.6418e-02, -1.8961e-01, -6.3904e-01, -4.6314e-01,\n",
      "         2.5020e-01,  1.2790e-02,  1.7174e-01,  2.6794e-01,  2.4945e-01,\n",
      "         1.5735e-01, -2.3188e-01, -2.6601e-02, -4.9325e-02, -2.9577e-01,\n",
      "         2.4555e-01,  9.7819e-02, -2.8276e-01, -4.7564e-02, -1.4132e-01,\n",
      "        -2.8123e-01, -1.5105e-01,  2.5029e-02, -1.1685e-01, -4.6642e-01,\n",
      "         3.5981e-01, -4.3792e-01, -3.3248e-01, -1.5461e-01,  2.3797e-01]), tensor([-3.3572e-01,  1.9408e-01,  3.4856e-01,  3.6607e-02,  5.4223e-01,\n",
      "        -5.3518e-01,  1.6161e-01,  3.3563e-01,  3.1411e-02,  2.4285e+00,\n",
      "        -2.5359e-01, -3.6594e-01,  3.7891e-01, -5.9768e-01,  4.8498e-01,\n",
      "        -5.9829e-02,  2.8688e-01,  1.1233e+00,  2.8331e-01,  3.0573e-01,\n",
      "         8.3214e-02, -1.6163e-01,  1.2981e-01,  2.3029e-02, -3.5391e-01,\n",
      "         2.0321e-02, -3.7089e-01, -1.8120e-01,  1.1881e-02,  4.3363e-02,\n",
      "        -1.0829e-01,  1.3310e-01,  4.5036e-01,  1.0128e-02, -3.9757e-03,\n",
      "         2.7105e-01, -1.5666e-01, -1.4974e-01,  2.6448e-01, -3.4969e-01,\n",
      "         1.9362e-01,  5.9947e-01,  1.9994e-02,  1.8294e-01,  4.1082e-01,\n",
      "        -4.4952e-01,  3.3649e-02,  4.7714e-01, -1.8871e-01,  3.2600e-01,\n",
      "         5.3404e-01, -1.1233e-02,  5.4597e-01,  3.0025e-01, -2.9212e-01,\n",
      "         5.0919e-01,  1.9316e-01,  2.2735e-01,  5.5290e-01, -2.5207e-02,\n",
      "         1.0373e-01,  2.6678e-01,  1.3201e-01,  1.1333e-01, -5.1900e-01,\n",
      "        -3.8793e-02,  7.8467e-02,  1.1224e-02,  6.9999e-02,  5.4396e-02,\n",
      "        -3.4191e-01,  2.6340e-01, -1.2587e-01,  5.4879e-01, -3.0214e-01,\n",
      "         1.1340e-01, -4.5474e-01, -3.5073e-01,  2.7191e-01, -6.0366e-02,\n",
      "        -3.6797e-01, -5.2049e-02, -5.0582e-01, -2.3446e-01,  3.5367e-01,\n",
      "         1.0256e-01, -7.0324e-01,  4.3770e-01, -3.4840e-01, -8.3992e-02,\n",
      "        -4.6905e-01,  2.1068e-01,  2.7104e-01, -7.0982e-01,  1.4435e-01,\n",
      "         2.7004e-02,  3.0135e-01, -2.9995e-01,  1.4017e-01,  6.9272e-01,\n",
      "         4.6601e-01, -3.2137e-01, -5.1053e-01,  1.7233e-01,  1.1418e-03,\n",
      "        -8.6254e-01,  5.8132e-03, -9.7399e-02,  1.7953e-01,  2.5026e-01,\n",
      "         3.5943e-01, -1.4387e-01, -1.8456e-02,  3.4922e-01, -1.8016e-01,\n",
      "         5.3463e-01,  4.4872e-01, -3.8107e-03,  4.0581e-01, -3.3471e-01,\n",
      "         1.6328e-01, -3.5461e-01,  6.4396e-01,  3.7318e-01,  1.3619e-01,\n",
      "         2.5424e-01,  6.2345e-01, -7.1767e-02,  2.6577e-01,  1.4368e-01,\n",
      "        -2.4916e-01, -9.6528e-02,  5.7004e-01, -3.2234e-01,  1.4318e-01,\n",
      "        -1.8807e-01,  1.3421e-01, -1.2869e-01, -2.4334e-01, -2.6224e-01,\n",
      "         3.1682e-01, -8.9186e-02, -2.3940e-02, -2.9238e-02, -1.4538e-01,\n",
      "         3.2435e-01, -2.2072e-01,  1.1886e-01, -1.7520e-01,  7.6496e-02,\n",
      "        -5.1179e-01, -9.0755e-01,  1.7701e-01, -2.0997e-01, -1.8940e-01,\n",
      "         3.5581e-02, -3.9538e-01,  7.5430e-02, -7.8306e-02,  7.7891e-01,\n",
      "        -1.8605e-01,  1.8898e-01,  3.6021e-01, -4.9725e-01, -7.8943e-01,\n",
      "         2.6335e-02, -1.7678e-02,  1.9609e-01,  6.2440e-02,  2.2149e-01,\n",
      "         8.4633e-02,  2.2146e-02, -5.1076e-01, -2.6031e-01,  7.5607e-01,\n",
      "        -2.3137e-01, -7.5818e-01,  5.1348e-01,  4.5053e-02,  2.6652e-01,\n",
      "         5.2719e-02, -1.9533e-02, -1.9996e-01, -2.7840e-01, -3.5012e-01,\n",
      "         3.3830e-01, -8.9406e-02,  2.5177e-01,  8.1587e-02,  2.3643e-02,\n",
      "         4.4605e-01, -1.5867e-01,  3.0491e-01,  7.1984e-01,  3.1389e-01,\n",
      "         7.9606e-02,  8.1383e-01, -2.4965e-02, -8.8447e-02,  3.6373e-01,\n",
      "        -1.8832e-01, -2.0716e-01,  2.3061e-01,  7.5230e-02, -2.0186e-01,\n",
      "        -3.7217e-03, -3.1236e-01,  4.2424e-03,  2.7929e-01,  2.8400e-01,\n",
      "        -6.8477e-01,  3.9179e-01,  6.4430e-01,  2.1316e-01,  1.3427e-01,\n",
      "        -3.3671e-01, -3.2334e-01, -3.3813e-01,  2.3769e-01,  7.2654e-01,\n",
      "         2.4854e-01, -3.6933e-01,  3.3956e-01,  6.6900e-03, -1.1377e-01,\n",
      "        -2.2943e-01, -5.1586e-02,  2.6518e-01,  3.4685e-02,  8.1284e-02,\n",
      "        -3.6227e-01, -1.0407e-01, -1.3143e-01, -1.7180e-01, -4.6278e-01,\n",
      "        -6.7939e-01, -1.2503e-01, -6.7626e-02, -4.4020e-01, -5.7239e-02,\n",
      "        -1.4708e-01, -5.1518e-01,  2.3637e-01,  2.9633e-01, -2.8311e-01,\n",
      "        -1.6497e-01, -1.0222e-01, -6.3128e-02, -4.0656e-01,  4.2575e-02,\n",
      "         4.5596e-01,  3.1191e-01,  2.0526e-01, -2.3257e-01,  1.3931e-01,\n",
      "        -5.7205e-01,  8.2007e-02,  4.0015e-01, -8.7762e-02, -3.6494e-01,\n",
      "         3.0746e-01,  3.4459e-01, -9.3007e-01,  2.2648e-01,  4.9536e-01,\n",
      "        -1.5241e-01,  4.4131e-02, -9.9154e-02,  6.1083e-01, -7.8883e-02,\n",
      "         4.4459e-01, -3.0041e-01, -1.8617e-01, -1.2795e-01, -3.3108e-01,\n",
      "         3.9739e-02,  4.3983e-02,  2.3746e-01, -1.5575e-02, -6.0432e-01,\n",
      "        -1.1697e-03,  1.9598e-01, -5.8294e-01,  1.5352e-01, -6.0391e-01,\n",
      "         7.2298e-02, -1.7979e-01, -5.0774e-02,  3.4662e-01, -2.7781e-01,\n",
      "        -1.8627e-01, -3.5144e-01, -2.5866e-01,  2.5981e-01, -4.9962e-01,\n",
      "        -9.1029e-03, -2.7371e-01, -1.9904e-01,  3.4724e-02, -1.9060e-01]), tensor([-0.0828,  0.6720, -0.1499, -0.0650,  0.0565,  0.4023,  0.0028, -0.3311,\n",
      "        -0.3069,  2.0817,  0.0318,  0.0136,  0.3027,  0.0071, -0.5819, -0.2774,\n",
      "        -0.0623,  1.1451, -0.2423,  0.1235, -0.1224,  0.3315, -0.0062, -0.3054,\n",
      "        -0.1306, -0.0546,  0.0371, -0.0706,  0.5893, -0.3038,  0.2898, -0.1465,\n",
      "        -0.2705,  0.3716,  0.3203, -0.2912,  0.0052, -0.1321, -0.0527,  0.0873,\n",
      "        -0.2667, -0.1690,  0.0152, -0.0084, -0.1487,  0.2341, -0.2072, -0.0914,\n",
      "         0.4008, -0.1722,  0.1814,  0.3759, -0.2868,  0.3729, -0.1619,  0.1801,\n",
      "         0.3032, -0.1322,  0.1835,  0.0958,  0.0949,  0.0083,  0.1176,  0.3405,\n",
      "         0.0368, -0.2908,  0.0583, -0.0278,  0.0829,  0.1862, -0.0315,  0.2799,\n",
      "        -0.0744, -0.1376, -0.2187,  0.1814,  0.0409, -0.1130,  0.2411,  0.3657,\n",
      "        -0.2752, -0.0568,  0.3487,  0.0119,  0.1452, -0.7139,  0.4850,  0.1481,\n",
      "         0.6229,  0.2060,  0.5838, -0.1344,  0.4021,  0.1831,  0.2802, -0.4235,\n",
      "        -0.2563,  0.1771, -0.5410,  0.1660, -0.0361,  0.0850, -0.6499,  0.0755,\n",
      "        -0.2883,  0.4063, -0.2802,  0.0941,  0.3241,  0.2844, -0.2634,  0.1155,\n",
      "         0.0719, -0.4721, -0.1837, -0.3471,  0.2996, -0.6651,  0.0025, -0.4233,\n",
      "         0.2751,  0.3601,  0.1631,  0.2396, -0.0592,  0.3261,  0.2056,  0.0387,\n",
      "        -0.0458,  0.0898,  0.4315, -0.1595,  0.0853, -0.2657, -0.1500,  0.0843,\n",
      "        -0.1671, -0.4300,  0.0608,  0.1312, -0.2411,  0.6655,  0.4453, -0.1802,\n",
      "        -0.1392,  0.5625,  0.2146, -0.4644, -0.0122,  0.0300, -0.0511, -0.2014,\n",
      "         0.8079,  0.4738, -0.0576,  0.4622,  0.1608, -0.2095, -0.0545,  0.1557,\n",
      "        -0.1371,  0.1297, -0.0119, -0.0034, -0.1359, -0.0807,  0.2007,  0.0541,\n",
      "         0.0468,  0.0595,  0.0463,  0.1775, -0.3109,  0.2812, -0.2436,  0.0853,\n",
      "        -0.2101, -0.1947,  0.0027, -0.4634,  0.1479, -0.3152, -0.0659,  0.0361,\n",
      "         0.4290, -0.3376,  0.1643,  0.3257, -0.0504, -0.0543,  0.2407,  0.4192,\n",
      "         0.1301, -0.1717, -0.3781, -0.2309, -0.0195, -0.2929, -0.3082,  0.3030,\n",
      "        -0.2266,  0.0816, -0.1852, -0.2141,  0.4062, -0.2897,  0.0742, -0.1779,\n",
      "         0.2860, -0.0396, -0.2339, -0.3605, -0.0675, -0.0911,  0.2344, -0.0041,\n",
      "         0.0032,  0.0072,  0.0087,  0.2161,  0.0499,  0.3558,  0.1375,  0.0734,\n",
      "         0.1417,  0.2412, -0.0133,  0.1561,  0.0834,  0.0881, -0.0194,  0.4379,\n",
      "         0.0840,  0.4531, -0.5049, -0.1086, -0.2527, -0.1825,  0.2044,  0.1332,\n",
      "         0.1294,  0.0506, -0.1561, -0.3954,  0.1254,  0.2488, -0.1927, -0.3185,\n",
      "        -0.1272,  0.4341,  0.3118, -0.0041, -0.2094, -0.0800,  0.1161, -0.0508,\n",
      "         0.0153, -0.2803, -0.1249,  0.2359,  0.2339, -0.1402,  0.0285,  0.5692,\n",
      "        -0.1649, -0.0364,  0.0101, -0.1711, -0.0426,  0.0450, -0.4393, -0.2614,\n",
      "         0.3009, -0.0608, -0.4531, -0.1908, -0.2029,  0.2769, -0.0609,  0.1194,\n",
      "         0.6221, -0.1934,  0.4785, -0.3011,  0.0594,  0.0749,  0.0611, -0.4662,\n",
      "         0.4005, -0.1910, -0.1433,  0.0183, -0.1864,  0.2071, -0.3560,  0.0534,\n",
      "        -0.0508, -0.1918, -0.3785, -0.0659]), tensor([-3.3355e-01,  4.9611e-01, -2.7858e-01, -2.0506e-01,  6.0868e-02,\n",
      "         3.6219e-01,  5.5708e-02, -2.6858e-01,  1.9418e-01,  2.4102e+00,\n",
      "        -1.3740e-01, -3.9335e-03, -6.2856e-02, -3.0419e-02, -4.8369e-01,\n",
      "        -1.0061e-01, -1.5753e-01,  1.0080e+00, -2.8801e-01,  2.2219e-02,\n",
      "        -1.6155e-01,  8.8345e-02,  2.4689e-02, -2.1105e-01, -1.0158e-02,\n",
      "        -2.3615e-01,  3.3370e-01,  1.0458e-01,  1.8377e-01, -2.9969e-02,\n",
      "        -2.0267e-02,  4.4483e-02, -9.5139e-02, -4.9444e-01,  1.2493e-01,\n",
      "        -1.3943e-01,  2.9818e-01,  2.9310e-01, -1.3534e-01, -9.1974e-02,\n",
      "        -2.4596e-01,  1.7668e-01, -2.1340e-02,  8.2578e-02,  6.9658e-02,\n",
      "         3.0830e-01,  1.0623e-01, -1.9240e-01, -1.1606e-01, -4.9011e-02,\n",
      "        -4.2348e-01,  2.4769e-01,  2.8189e-01,  1.0741e-01,  8.6726e-02,\n",
      "        -3.0133e-01, -1.5233e-01, -1.7680e-01,  2.4868e-01, -6.5243e-02,\n",
      "        -1.6543e-01, -3.2022e-01, -6.2517e-01,  5.1593e-01,  3.5365e-02,\n",
      "        -1.8812e-01,  1.5681e-01,  2.2917e-01, -6.5665e-02,  3.6914e-02,\n",
      "         1.8434e-01, -6.8198e-02,  3.4766e-01, -2.6381e-02,  3.6707e-01,\n",
      "         6.4139e-02,  3.9060e-01,  1.6122e-01,  1.2151e-01,  2.1346e-01,\n",
      "         1.8902e-01, -1.5340e-01,  1.6616e-01, -2.3152e-01, -2.9595e-01,\n",
      "         2.4987e-02, -8.0100e-02, -2.2188e-02,  5.1489e-01, -2.0867e-02,\n",
      "         8.5940e-02, -2.6578e-01, -4.5969e-01,  2.5233e-01,  2.6321e-01,\n",
      "         2.8895e-01, -1.2653e-01,  1.6708e-01, -1.7940e-01, -1.5907e-02,\n",
      "        -5.6346e-01, -7.8087e-02, -1.4067e-01, -1.9848e-01,  7.9290e-01,\n",
      "        -9.0816e-01,  3.0528e-01,  9.5038e-02, -1.7883e-01,  2.1488e-02,\n",
      "         3.5597e-01, -4.7850e-01,  1.2447e-01, -2.6675e-01, -1.1365e-01,\n",
      "         1.3627e-01, -2.8853e-01, -2.3255e-02,  6.1261e-02, -3.2156e-01,\n",
      "         4.2849e-01, -4.4117e-01, -2.9358e-01, -1.0712e-01,  5.5027e-01,\n",
      "        -1.1268e-01, -3.3883e-03,  2.0357e-01, -1.4977e-01, -1.7515e-01,\n",
      "        -3.4922e-01,  8.4914e-02, -9.8243e-03, -3.6033e-01, -7.7617e-02,\n",
      "        -2.8615e-02, -9.9705e-03, -1.1325e-01,  9.9165e-02,  3.2609e-02,\n",
      "        -1.8852e+00,  4.3394e-01,  2.4373e-01,  3.3420e-01, -6.6911e-02,\n",
      "        -2.2639e-01, -3.8126e-01, -5.0618e-02, -3.2589e-02, -1.6153e-01,\n",
      "        -1.1164e-01,  1.8455e-01,  3.5149e-01, -1.4208e-01, -2.8523e-01,\n",
      "        -2.6175e-01,  3.0964e-01,  1.4867e-02,  1.6756e-01, -5.8644e-01,\n",
      "        -7.8788e-02, -8.7538e-02, -2.4387e-02, -1.0941e-01, -1.6767e-01,\n",
      "        -1.6368e-01, -2.3762e-01,  1.4273e-01,  4.7070e-01, -2.2918e-01,\n",
      "        -1.2802e-01,  4.7004e-02, -1.4506e-02,  1.1203e-01, -3.6718e-02,\n",
      "        -1.1387e-02, -4.1809e-01,  4.6348e-01,  1.4650e-01,  4.4775e-02,\n",
      "         2.9911e-01, -4.1217e-02, -2.1557e-01,  9.4903e-02, -2.0486e-01,\n",
      "        -2.9424e-01, -5.3723e-02, -3.1775e-01,  1.2587e-01,  4.7755e-01,\n",
      "         2.8757e-01,  1.3551e-02,  5.6441e-02, -6.9067e-02,  7.0738e-02,\n",
      "        -5.8923e-02,  1.1318e-02,  2.1257e-02, -1.9262e-01,  1.6365e-01,\n",
      "         1.1888e-01, -1.3006e-01,  1.0228e-02, -1.8261e-01, -7.4733e-01,\n",
      "         3.1832e-01, -1.3441e-02, -4.6336e-01,  1.3703e-01,  1.6440e-01,\n",
      "        -1.6710e-01, -1.9244e-01,  4.2014e-01, -6.9965e-01, -1.5621e-01,\n",
      "         1.4011e-01, -1.6616e-02, -3.8627e-01, -7.5750e-02,  2.5553e-01,\n",
      "         5.5594e-02,  3.7242e-03,  2.1203e-01, -4.4181e-02, -6.3948e-02,\n",
      "         9.2114e-02, -2.2168e-01,  3.7043e-02, -3.5804e-02, -3.7763e-02,\n",
      "         9.0152e-02,  8.9827e-02, -7.2716e-02, -1.2656e-01,  3.7679e-01,\n",
      "         6.9484e-02,  6.3979e-01,  3.4585e-02,  1.8984e-01,  2.6821e-01,\n",
      "         1.7729e-01,  3.9760e-01, -1.3643e-01,  3.9367e-01,  4.3105e-01,\n",
      "         2.8093e-02, -4.1677e-01, -2.3789e-01, -1.1742e-02,  1.9135e-01,\n",
      "        -6.7687e-02, -9.0378e-02,  2.9572e-01,  3.9146e-01,  1.3509e-01,\n",
      "         1.8621e-01,  1.2315e-01, -5.6707e-02,  1.8840e-03,  4.3136e-01,\n",
      "         4.7096e-02,  1.8980e-01, -2.4463e-01,  3.7556e-01,  1.9216e-01,\n",
      "        -5.5826e-02,  6.9369e-02,  1.3434e-02,  2.1119e-01,  9.4043e-02,\n",
      "        -8.0007e-02,  4.0379e-01, -1.9006e-01, -9.7488e-01, -1.0038e-01,\n",
      "        -1.3342e-01,  2.4097e-02, -1.7107e-01, -1.2310e-01,  2.1573e-01,\n",
      "        -8.3656e-02,  8.8146e-02,  3.1930e-02, -1.2684e-02,  3.3343e-02,\n",
      "        -6.8103e-02,  3.3957e-02, -4.2476e-01, -1.8707e-01, -2.6205e-01,\n",
      "        -6.0215e-01, -1.3500e-01,  1.2724e-01,  1.7424e-01,  2.3042e-01,\n",
      "         4.0913e-01, -2.1780e-01, -4.8043e-01,  6.3816e-02,  2.0620e-01]), tensor([-8.6931e-02,  2.5377e-01,  1.6810e-01,  7.5704e-02,  1.8061e-02,\n",
      "        -6.4389e-01,  1.7444e-01, -1.6433e-01, -2.4357e-01,  2.0393e+00,\n",
      "        -1.8395e-01, -3.2359e-01,  3.9382e-01,  1.1465e-01, -5.8393e-01,\n",
      "        -2.8376e-01, -7.9123e-03,  1.5639e+00,  5.6717e-02,  8.9370e-01,\n",
      "         2.6189e-01, -2.7468e-01,  9.5437e-02, -8.2834e-02,  3.3205e-01,\n",
      "         2.5640e-01,  7.9347e-02, -4.0802e-01, -4.5415e-02, -1.2211e-01,\n",
      "         7.7319e-02,  3.0104e-01, -6.9792e-01,  3.7858e-01, -3.2511e-01,\n",
      "        -3.4816e-01, -1.4897e-01, -1.2082e-01, -3.6768e-01, -4.6140e-01,\n",
      "         3.6606e-01, -1.7980e-01,  5.5668e-01,  1.5601e-01,  3.5077e-01,\n",
      "        -2.1335e-01,  3.0609e-02,  2.9482e-02,  1.7253e-01,  1.1802e-01,\n",
      "         5.6768e-01, -7.5744e-02,  2.2792e-01,  3.7455e-01,  1.0764e-01,\n",
      "         2.3349e-01, -4.8613e-02,  1.4903e-02, -1.8861e-02,  7.2076e-02,\n",
      "        -1.2824e-01, -5.6068e-02,  3.4755e-01, -2.2559e-01,  2.7096e-01,\n",
      "        -1.4799e-01,  2.8941e-01, -1.9283e-01, -1.3008e-01, -2.8928e-01,\n",
      "        -4.0841e-01, -1.1667e-01, -1.8544e-01,  1.0841e-02,  3.3931e-01,\n",
      "         3.0211e-01,  7.9449e-02,  4.9943e-01,  2.9937e-01,  4.1393e-01,\n",
      "        -7.4495e-02,  1.2421e-01, -3.3169e-01, -1.6158e-01,  5.2858e-01,\n",
      "         6.5366e-01,  2.9973e-01,  1.5875e-01,  6.7577e-01,  7.7287e-02,\n",
      "         1.1412e-01,  1.2254e-02, -2.9015e-01, -1.7928e-01, -4.9186e-01,\n",
      "        -1.2598e-01,  1.6042e-01, -2.2954e-01,  5.0506e-02, -6.6345e-02,\n",
      "         1.9868e-01,  3.5123e-01, -1.7286e-01,  4.6147e-01, -4.6016e-01,\n",
      "        -1.4044e+00, -1.4856e-01,  4.7593e-01,  2.2862e-01, -6.8214e-01,\n",
      "        -1.9437e-01, -2.6027e-01,  3.2618e-04,  5.4230e-02,  3.6361e-01,\n",
      "         2.0118e-01,  1.9304e-01, -1.8354e-01,  5.7294e-02, -2.1890e-01,\n",
      "        -1.8793e-01, -8.5771e-02, -1.8986e-01,  1.8665e-01, -1.9236e-01,\n",
      "        -3.2537e-01, -2.1477e-01, -2.4442e-01,  5.9846e-01,  1.7391e-01,\n",
      "         7.1084e-01,  3.0003e-01, -4.2107e-01, -3.0604e-01, -2.8967e-02,\n",
      "         1.7653e-01,  5.4666e-01, -4.3913e-01, -5.1071e-02,  2.0685e-01,\n",
      "        -7.2354e-01, -3.6712e-01,  8.8936e-01,  3.4360e-01, -3.3631e-01,\n",
      "         3.8445e-01, -1.4627e-01,  1.8470e-01,  2.3577e-01, -6.6380e-01,\n",
      "        -4.7945e-01, -1.9683e-01,  5.3875e-02,  3.1728e-02,  1.5154e-01,\n",
      "         2.1521e-01, -2.7518e-01, -2.7524e-01,  1.6966e-01,  3.4476e-01,\n",
      "         3.6126e-01, -7.2814e-02,  6.3696e-03, -6.8936e-02,  1.1748e-01,\n",
      "        -3.3441e-01,  9.4751e-02, -2.6346e-01, -1.7579e-01, -6.5886e-02,\n",
      "         9.8776e-02, -3.8819e-02, -3.0414e-02, -4.4638e-02,  2.5021e-01,\n",
      "         3.0640e-01, -6.1699e-01,  2.2005e-01,  3.7970e-01,  1.3509e-01,\n",
      "        -4.9354e-01, -1.8982e-01,  1.1159e-01, -2.2430e-02, -2.6495e-02,\n",
      "         8.8934e-02,  5.1640e-02, -1.0745e-01,  3.3793e-01,  3.2827e-01,\n",
      "        -7.8899e-01,  3.4429e-01,  4.9727e-01, -4.2502e-01,  1.4580e-01,\n",
      "         7.2040e-02,  6.3826e-01,  1.1769e-02, -3.5771e-01,  2.4299e-02,\n",
      "         7.5025e-02,  5.5158e-01,  2.5258e-01,  2.7976e-01,  1.7559e-01,\n",
      "        -6.4084e-02,  3.5076e-01, -3.6487e-01,  1.7129e-01,  1.1715e-01,\n",
      "         7.5078e-01,  5.3097e-01, -3.5169e-01,  1.1246e-01,  1.2781e-01,\n",
      "         8.0519e-01, -2.4990e-01, -1.7553e-01, -4.3607e-01,  6.0099e-01,\n",
      "        -1.9220e-01, -1.3045e-01,  2.3349e-02,  1.9654e-01, -7.5144e-02,\n",
      "        -3.4489e-04, -3.9902e-01, -6.9974e-02, -2.1452e-01, -2.7759e-01,\n",
      "        -7.5542e-01, -4.4597e-03,  3.7904e-01,  1.5843e-02,  2.5780e-01,\n",
      "        -2.1381e-01, -1.3249e-01,  3.1974e-01, -2.6245e-03,  2.6878e-01,\n",
      "         4.3700e-01, -8.5989e-02,  5.2564e-01,  8.4453e-02, -2.3008e-02,\n",
      "         2.7029e-01, -1.2239e-01,  1.0191e-01,  4.5072e-01, -2.9237e-01,\n",
      "         2.4293e-01,  2.4587e-01, -3.0860e-01, -2.7456e-01, -2.6117e-01,\n",
      "         7.3651e-01,  7.0003e-02,  5.1902e-02,  9.8995e-02,  3.2050e-01,\n",
      "        -5.5318e-02,  4.1742e-01, -5.1779e-01, -1.5360e-01, -7.4256e-01,\n",
      "         6.7100e-01,  1.3189e-01,  5.2296e-01,  1.6764e-01, -1.3867e-01,\n",
      "         1.3756e+00, -5.2925e-02,  3.9862e-01,  7.2141e-02,  2.6560e-01,\n",
      "         4.6330e-01,  5.7191e-02,  6.7450e-01,  4.9835e-01, -1.5570e-01,\n",
      "         4.4757e-02,  5.0085e-01,  2.8037e-01,  3.3379e-02, -2.8748e-01,\n",
      "        -4.2730e-02, -1.3433e-01, -2.7426e-01, -1.6603e-01,  6.1011e-01,\n",
      "        -2.6176e-02, -2.3683e-01, -1.1369e-01, -1.4368e-01,  1.0938e-01,\n",
      "         6.4238e-02,  6.0057e-01,  4.1425e-01, -2.3232e-01, -5.2258e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 0.1153,  0.0148, -0.4108, -0.0676,  0.3383,  0.0682, -0.0400,  0.2184,\n",
      "         0.0877,  2.2638, -0.3657,  0.0358,  0.2057, -0.3011, -0.0709,  0.2493,\n",
      "         0.0506,  0.9058, -0.5363, -0.2981,  0.4095, -0.0979,  0.0676, -0.0161,\n",
      "        -0.1391,  0.1383, -0.2411, -0.1333,  0.1613, -0.0384,  0.0067,  0.2724,\n",
      "         0.0522,  0.1971,  0.2580, -0.2293,  0.4764,  0.2745, -0.2141, -0.1709,\n",
      "        -0.5195, -0.1086,  0.2996,  0.0039, -0.0785,  0.1646, -0.1782,  0.0239,\n",
      "         0.0601, -0.0667,  0.0023,  0.0721,  0.1277, -0.0078,  0.1851, -0.0468,\n",
      "        -0.1781, -0.2111, -0.0986, -0.1150, -0.4039, -0.3116, -0.3862,  0.4498,\n",
      "         0.0228,  0.0495, -0.1168,  0.0687,  0.1787,  0.5021,  0.3181, -0.0956,\n",
      "         0.5041, -0.1783,  0.4569, -0.0139,  0.1379, -0.0822,  0.0748,  0.0637,\n",
      "         0.0033,  0.2510,  0.0266,  0.1509,  0.3904, -0.4584,  0.1801, -0.6626,\n",
      "         0.4363,  0.1691, -0.2195,  0.2171, -0.1086, -0.0577,  0.4960, -0.1345,\n",
      "        -0.2597,  0.0854,  0.1816,  0.2184, -0.1264, -0.1201,  0.0482, -0.1946,\n",
      "         0.2629, -0.4019,  0.0805, -0.1373, -0.0483,  0.0906, -0.0409, -0.1455,\n",
      "         0.3029, -0.0372,  0.3510,  0.0889, -0.0724, -0.3078, -0.0298, -0.1428,\n",
      "        -0.1078, -0.3684, -0.0789,  0.0122, -0.0368, -0.0735, -0.1405, -0.4407,\n",
      "        -0.0116, -0.0731, -0.2898, -0.0147,  0.0939,  0.0895,  0.1070,  0.0310,\n",
      "        -0.0153, -0.1624, -0.0778, -0.1533, -1.5694,  0.0677, -0.2810, -0.1810,\n",
      "        -0.1418, -0.3557, -0.1627,  0.2691, -0.0153, -0.1810, -0.0222,  0.0765,\n",
      "         0.0873, -0.4462, -0.0681,  0.0856,  0.0407,  0.0172,  0.1513, -0.1454,\n",
      "        -0.2887,  0.2386, -0.5133,  0.0521, -0.0761, -0.0348,  0.1886, -0.0220,\n",
      "         0.0312, -0.1456, -0.1645,  0.1282,  0.1561, -0.1076, -0.0354,  0.2495,\n",
      "        -0.2218,  0.2654, -0.2195,  0.0326,  0.1514,  0.0746, -0.0503,  0.0941,\n",
      "         0.1415,  0.0343, -0.0919, -0.1782,  0.0198,  0.0047,  0.0865, -0.1277,\n",
      "        -0.2635, -0.1091,  0.0938,  0.1876, -0.0374, -0.2545,  0.1783,  0.3111,\n",
      "        -0.2625, -0.2112, -0.3225, -0.1877,  0.3117,  0.1332,  0.2451,  0.0090,\n",
      "        -0.1539,  0.2117, -0.0275, -0.4092, -0.0096, -0.3661, -0.3162,  0.2269,\n",
      "        -0.0292,  0.1579, -0.2311, -0.2035,  0.2925, -0.1360,  0.0459,  0.1743,\n",
      "         0.1886, -0.0605, -0.1043,  0.2603,  0.1115,  0.1511, -0.2117,  0.3892,\n",
      "         0.4474,  0.2609,  0.3692, -0.0029, -0.0886,  0.0220,  0.0483,  0.2345,\n",
      "         0.0059,  0.1415,  0.0377,  0.3050,  0.4159, -0.2894, -0.0863,  0.3376,\n",
      "        -0.4010,  0.5925,  0.1866, -0.3602, -0.0952,  0.0064,  0.1121,  0.4657,\n",
      "         0.3359,  0.0509, -0.0237,  0.0439,  0.4569,  0.2262,  0.1868,  0.3613,\n",
      "         0.4835, -0.0452,  0.0967,  0.2507,  0.8151,  0.2228, -0.2420, -0.0353,\n",
      "         0.0662, -0.2067, -0.0227,  0.2557,  0.2014,  0.2476, -0.3505,  0.2476,\n",
      "         0.2806, -0.1576, -0.2390, -0.0868,  0.0457, -0.1211,  0.2467, -0.0954,\n",
      "         0.3217, -0.1777, -0.5413,  0.0445,  0.0712, -0.2353,  0.0648, -0.0280,\n",
      "        -0.2682,  0.0896,  0.4566,  0.1731]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([-4.2534e-02,  1.4615e-01, -1.2312e-01,  4.3070e-02,  1.2194e-01,\n",
      "         2.2085e-01, -2.6586e-01, -8.5717e-02, -2.1931e-01,  2.9240e+00,\n",
      "         1.0813e-01,  6.0737e-02,  1.5241e-01,  6.9866e-02,  6.7064e-03,\n",
      "        -1.5678e-01, -1.8753e-01,  4.5202e-01,  1.2032e-01, -2.7057e-01,\n",
      "        -2.8246e-01,  8.5209e-02, -1.1295e-02, -1.5100e-02, -5.4584e-02,\n",
      "        -2.3309e-02,  3.0347e-02,  1.7205e-02,  1.5991e-01, -1.5737e-01,\n",
      "        -2.4132e-01,  1.6739e-01, -2.0963e-02,  7.0803e-02, -2.9900e-02,\n",
      "         2.7282e-02,  2.2968e-01,  1.7784e-01,  2.1717e-01, -1.8117e-02,\n",
      "        -4.0860e-02,  1.5622e-01,  3.9091e-03,  4.7161e-02,  1.8567e-01,\n",
      "        -8.9776e-02, -1.3446e-01, -3.3960e-01,  1.9749e-01,  5.0050e-02,\n",
      "        -4.0637e-02,  1.9871e-01,  7.6238e-03, -1.9124e-03,  1.6683e-01,\n",
      "        -3.2074e-01,  3.4074e-03, -2.7431e-01,  2.3049e-01,  2.4339e-01,\n",
      "        -1.6289e-01, -3.2707e-01,  1.5522e-01,  1.8782e-01, -2.0739e-01,\n",
      "        -1.4058e-01, -1.4792e-01, -1.6964e-01, -7.4234e-02,  1.2305e-01,\n",
      "         1.2973e-01, -9.9632e-02, -4.9853e-02, -1.3720e-01,  1.0392e-01,\n",
      "         2.3708e-01,  1.0763e-01, -1.3993e-01, -3.5335e-01,  1.5515e-01,\n",
      "        -2.5155e-01, -1.1453e-01, -2.6921e-01,  2.8348e-02,  3.4739e-03,\n",
      "        -6.0695e-01, -3.9669e-02, -1.2917e-01,  1.5718e-01,  1.5967e-02,\n",
      "        -1.3516e-01,  5.7669e-02,  4.9911e-02,  1.8174e-01, -3.5968e-02,\n",
      "         7.0185e-02,  1.3468e-01, -1.2909e-01,  9.5835e-02,  4.2581e-01,\n",
      "        -3.3054e-01, -6.8045e-02,  1.4686e-01,  2.0802e-01,  3.4205e-01,\n",
      "        -1.5534e+00, -1.1813e-01, -2.2777e-02, -2.8054e-01,  3.2763e-01,\n",
      "         1.8951e-01, -2.5865e-01,  3.7832e-02,  5.0448e-02, -3.6881e-01,\n",
      "         1.0887e-02, -1.7962e-01, -1.4217e-01,  1.3138e-02, -1.8824e-02,\n",
      "         2.0962e-01, -1.7685e-01, -8.4375e-02,  9.7416e-02,  8.9203e-02,\n",
      "         6.7252e-02,  1.9059e-02, -1.9180e-01, -9.1074e-02, -1.2484e-02,\n",
      "        -1.2177e-01, -1.3027e-01,  1.8407e-02,  5.0278e-02,  4.2988e-02,\n",
      "        -1.1633e-01,  1.1250e-01, -4.5492e-01, -7.4640e-02, -1.0026e-01,\n",
      "        -1.4454e+00,  5.4292e-01,  2.4956e-02,  9.0540e-02, -6.5494e-02,\n",
      "        -3.0791e-01,  1.1288e-01,  1.0782e-02,  1.4293e-01,  2.6646e-01,\n",
      "         1.7819e-01,  4.2787e-02,  1.2413e-01,  2.2493e-01,  1.0526e-01,\n",
      "        -6.6528e-02,  1.8528e-02, -2.4828e-01,  4.8424e-02,  5.3610e-04,\n",
      "        -2.6157e-01,  2.1704e-02, -2.1987e-01, -1.6376e-01, -2.1385e-01,\n",
      "        -1.1655e-01, -7.5096e-02,  1.2821e-01,  1.4677e-01, -1.2402e-02,\n",
      "        -1.4096e-01,  1.5708e-01,  1.4545e-01, -8.7458e-02, -2.6402e-01,\n",
      "         4.9907e-03,  4.7945e-02, -3.1578e-01,  1.4053e-01, -2.4104e-01,\n",
      "        -1.1526e-01, -1.0695e-01,  1.6044e-01, -7.9503e-02, -2.5563e-02,\n",
      "        -2.3976e-01, -7.0954e-03, -2.4235e-02, -1.5123e-01,  7.4665e-02,\n",
      "         2.1353e-02,  3.4002e-01, -1.8745e-01,  3.8427e-02,  2.4345e-01,\n",
      "        -3.5968e-01, -1.3098e-01, -8.1376e-02, -7.7301e-02,  1.1661e-01,\n",
      "         1.5449e-01, -2.4894e-01, -1.8337e-01, -1.5447e-01, -1.1461e-01,\n",
      "        -1.1875e-02,  5.6828e-02, -5.0318e-01,  2.6741e-02,  2.2157e-01,\n",
      "         4.3068e-02, -1.9235e-01, -1.7261e-01, -3.8963e-01,  1.8220e-01,\n",
      "         7.8455e-02,  1.0578e-01,  1.7050e-01, -2.1002e-01, -2.3040e-01,\n",
      "         4.8482e-01,  1.0756e-02,  2.9305e-02,  7.7919e-04,  1.0501e-01,\n",
      "        -2.2093e-01,  2.1006e-01, -1.6616e-01, -1.8810e-01, -2.6730e-02,\n",
      "        -2.7318e-01,  1.9346e-01,  1.1058e-01,  3.0166e-01,  1.3388e-01,\n",
      "        -5.9327e-02,  2.7708e-01, -1.0932e-02, -1.0083e-01,  2.0011e-01,\n",
      "        -9.7478e-02,  6.2982e-02, -1.1338e-01,  6.9647e-02,  5.0826e-02,\n",
      "        -1.1414e-01,  2.9545e-01, -5.6267e-02, -1.7374e-01, -4.1006e-02,\n",
      "         3.0789e-01, -1.3854e-01,  8.0699e-02,  3.1884e-02, -2.5646e-01,\n",
      "         8.2693e-02, -6.3358e-03, -2.1942e-02,  3.8696e-01,  3.1964e-01,\n",
      "         4.3996e-01,  2.5984e-01,  1.6600e-01,  2.2644e-01, -3.9346e-02,\n",
      "         7.7204e-02, -3.2684e-02,  4.9542e-02,  2.6486e-01,  1.4939e-01,\n",
      "         1.6033e-01,  1.5812e-01,  1.7113e-01, -4.0355e-01, -2.9446e-01,\n",
      "         5.1798e-02,  6.9843e-02, -1.9339e-01, -3.3579e-02,  4.2320e-01,\n",
      "         4.8158e-01,  1.3949e-02,  5.1943e-01, -1.3640e-01,  1.8432e-01,\n",
      "        -1.5196e-01,  2.2528e-01, -1.9016e-01,  1.7606e-01,  6.4288e-02,\n",
      "        -3.7669e-01,  1.4819e-01, -1.4993e-01,  1.7879e-01,  3.6555e-02,\n",
      "         3.0801e-01,  4.0052e-04, -2.0407e-01, -1.9746e-02, -2.1324e-01]), tensor([-1.2762e-01,  7.3494e-01,  5.4907e-01,  1.7448e-01, -5.0525e-02,\n",
      "        -1.5257e-01, -2.1988e-01, -1.6580e-01,  2.8049e-01,  1.0967e+00,\n",
      "        -2.3147e-01,  3.9843e-01, -1.8928e-01,  3.7527e-01, -5.5640e-01,\n",
      "        -1.4159e-01, -1.1128e-01,  1.7853e+00, -3.2560e-01, -3.0963e-02,\n",
      "         6.3512e-02,  4.5728e-01, -1.1720e-01, -2.7267e-01,  1.4581e-01,\n",
      "         1.0000e-01, -1.0673e-01, -1.0590e-01,  2.2357e-01,  2.4868e-01,\n",
      "         2.6083e-01,  2.7820e-01, -4.0698e-01, -1.8921e-01,  2.6216e-02,\n",
      "        -7.1488e-02, -2.4300e-01, -3.4368e-02,  8.2229e-02,  3.9826e-03,\n",
      "         4.5285e-01,  1.0145e-01,  6.1922e-01, -1.0167e-02,  5.3998e-02,\n",
      "         3.4510e-01, -4.7159e-01,  2.0935e-01,  5.1093e-02,  2.9429e-01,\n",
      "         2.9511e-01, -1.3599e-01, -1.7620e-01, -1.2557e-01,  8.5487e-02,\n",
      "         4.0441e-01,  3.7610e-01,  2.0887e-01,  3.3538e-01,  2.3727e-01,\n",
      "         5.1457e-01, -1.2402e-01, -1.2397e-01,  4.3083e-01, -1.1635e-01,\n",
      "        -2.0321e-01, -3.3455e-01,  4.1592e-01,  1.8722e-01,  3.8379e-01,\n",
      "         3.3385e-01,  9.6036e-02,  1.0999e-02,  3.4958e-01,  2.6517e-01,\n",
      "         3.3180e-01,  6.4544e-01,  1.4813e-01,  1.9786e-01,  2.6075e-01,\n",
      "         7.8834e-01, -1.6524e-01, -3.8958e-02, -4.5216e-01,  2.4891e-01,\n",
      "        -1.2719e-01,  2.1756e-01, -4.6008e-01,  6.3495e-01,  5.1016e-01,\n",
      "         1.9100e-01, -4.0886e-01,  4.7280e-01, -1.4733e-01, -1.9317e-02,\n",
      "        -1.4883e-01,  3.0991e-02,  2.3010e-01, -2.5109e-01, -2.3810e-01,\n",
      "        -4.5739e-02,  1.6020e-01, -4.6093e-01, -2.6561e-01,  7.9564e-02,\n",
      "         7.6028e-01,  1.5629e-01, -9.0054e-02,  3.1964e-01, -6.3228e-02,\n",
      "         3.4821e-01, -6.0482e-01,  1.6986e-01,  1.4040e-01,  1.7810e-02,\n",
      "        -4.7827e-01,  9.5400e-02, -4.0555e-02,  8.8041e-02,  3.3962e-01,\n",
      "         4.9666e-01,  6.7107e-02, -2.7386e-01, -4.6262e-03,  1.7882e-01,\n",
      "         1.2267e-01,  1.5476e-01,  5.5262e-02, -1.7370e-01, -4.0822e-01,\n",
      "         1.6418e-01, -1.3220e-01,  3.7936e-01,  6.3541e-03,  8.0904e-02,\n",
      "        -3.0888e-01, -1.5746e-01,  2.1796e-01, -2.4386e-02,  1.9568e-01,\n",
      "        -3.8627e-01,  3.4183e-01,  8.9342e-02,  1.1375e-01,  3.6859e-01,\n",
      "         3.9455e-01, -4.1678e-02, -1.8957e-01,  4.2419e-01,  3.6445e-02,\n",
      "         6.3781e-02, -3.9712e-01, -3.3859e-01, -5.3028e-02, -1.2845e-01,\n",
      "        -1.8626e-01, -3.2655e-01,  8.1454e-02,  2.2192e-02,  2.1297e-01,\n",
      "         1.7846e-01, -4.2297e-01,  5.8842e-02, -1.5428e-01, -2.9639e-01,\n",
      "         3.6014e-01,  2.1601e-01, -1.2390e-01,  5.3018e-02, -7.4691e-02,\n",
      "         2.9759e-01, -5.9446e-03, -2.4968e-01,  2.8318e-01, -3.1694e-01,\n",
      "         7.9995e-02, -3.0997e-02, -3.5972e-01,  2.4082e-01,  1.5274e-01,\n",
      "        -9.1765e-03,  6.2451e-01, -3.4254e-01, -7.3291e-02, -2.2989e-01,\n",
      "        -7.2879e-02, -1.3482e-01, -6.8929e-02,  3.6341e-01,  1.7104e-01,\n",
      "        -1.2901e-01,  8.3831e-02, -6.2355e-04, -6.4895e-02, -1.8362e-01,\n",
      "         1.5714e-01, -1.2612e-01,  3.9028e-02,  1.0627e-01, -5.3141e-01,\n",
      "         6.3381e-01,  1.2257e-01,  5.9297e-02,  1.8091e-01,  2.9064e-01,\n",
      "         4.7942e-01, -2.5454e-01, -3.0639e-01,  1.6536e-01, -1.7169e-01,\n",
      "         2.5374e-01, -9.5750e-02,  5.1993e-02, -2.1094e-01,  4.0642e-01,\n",
      "         5.0812e-02, -2.0426e-01, -7.6309e-02,  1.5829e-01,  3.0772e-02,\n",
      "         1.0813e-01,  9.7014e-02, -3.0905e-01,  2.7979e-02,  2.3147e-01,\n",
      "         4.9316e-02,  5.5969e-01,  2.0407e-01,  3.6362e-01, -2.6846e-02,\n",
      "         1.6024e-01, -2.9773e-02,  3.4123e-01, -6.8201e-02, -2.2344e-02,\n",
      "        -5.7171e-01,  6.7203e-03,  5.4539e-02, -2.1343e-01, -1.8606e-01,\n",
      "         1.3330e-02,  9.4596e-02,  1.2128e-01,  2.1501e-02,  7.4167e-02,\n",
      "        -2.4893e-01,  4.7665e-01,  3.9757e-01, -4.2577e-01,  1.6933e-01,\n",
      "        -3.5161e-01, -2.2675e-01,  3.1191e-01,  1.9610e-01,  3.2982e-01,\n",
      "         7.9780e-01, -3.6385e-01, -2.8176e-01,  1.5772e-01,  1.7106e-01,\n",
      "         9.0250e-02,  4.2732e-01,  1.3108e-01,  2.2266e-01, -5.4200e-01,\n",
      "        -3.1957e-01,  2.4337e-01, -1.7125e-02,  1.1255e-01, -2.2135e-01,\n",
      "         1.0501e-01,  1.3506e-01, -3.4426e-01, -2.9451e-01, -5.6189e-02,\n",
      "         1.0945e-02, -1.6881e-01,  1.0453e-01, -1.3741e-01,  4.0727e-01,\n",
      "         9.8829e-02, -7.0535e-03, -1.6497e-01,  2.2343e-01,  2.1542e-01,\n",
      "        -7.7298e-02, -5.6521e-02, -5.2750e-01,  2.5576e-01,  1.2971e+00,\n",
      "         1.6683e-01,  7.0332e-02, -3.6581e-02,  1.3411e-01, -4.6247e-01,\n",
      "        -4.7795e-01, -1.6444e-01, -1.5776e-02, -2.4094e-01, -9.0567e-02]), tensor([-1.9686e-01,  1.1579e-01, -4.1091e-01, -4.6998e-01, -2.9972e-01,\n",
      "         6.7654e-02, -8.8857e-02,  3.2210e-02,  2.5616e-01,  3.2108e+00,\n",
      "        -2.7731e-01,  7.0743e-02,  2.1918e-02, -1.0867e-01, -1.5828e-01,\n",
      "        -1.4976e-01, -5.1743e-01,  7.3892e-01, -4.4249e-01, -1.2340e-01,\n",
      "         4.4607e-02,  1.9652e-01,  4.3265e-03, -5.3208e-02,  3.1904e-01,\n",
      "        -3.3364e-01,  9.6965e-02,  8.2695e-02, -7.0981e-02, -2.4714e-01,\n",
      "         2.9223e-01, -3.7456e-02, -4.6527e-01, -2.2640e-01,  4.3721e-01,\n",
      "         5.2628e-02, -2.3859e-01, -1.6096e-01, -1.4652e-01,  3.2018e-01,\n",
      "        -1.1260e-01, -1.8967e-02, -1.5709e-01, -9.2215e-02,  7.6994e-02,\n",
      "        -3.0975e-02, -1.0931e-01,  1.3912e-01,  1.1352e-02, -1.3433e-01,\n",
      "        -7.5631e-01, -1.5791e-01, -2.6654e-02, -2.1694e-01,  2.7343e-01,\n",
      "         5.9012e-03, -7.3400e-02, -6.6727e-02, -1.8656e-01,  1.0346e-01,\n",
      "        -2.4448e-03, -4.1683e-01, -5.6282e-01,  3.4100e-01,  2.5238e-01,\n",
      "        -2.2164e-01, -1.6711e-01,  9.6288e-03,  1.4804e-01,  4.2298e-01,\n",
      "         3.8793e-03,  1.3070e-01,  6.1025e-01, -1.7952e-01,  5.7403e-01,\n",
      "        -2.6145e-01,  4.2594e-01,  2.0034e-01,  2.7907e-01,  5.3277e-01,\n",
      "         2.6033e-01,  5.1359e-02,  1.2221e-01, -2.8394e-01,  1.5687e-01,\n",
      "        -1.1928e-01, -5.0459e-01, -6.1818e-01,  2.3585e-01, -3.7804e-01,\n",
      "        -1.7496e-01, -4.1944e-01, -2.5162e-01,  2.6579e-01,  8.0013e-02,\n",
      "        -4.6997e-02, -1.4191e-01, -2.4902e-02,  7.2114e-02, -2.6104e-01,\n",
      "        -1.4287e-01,  3.2012e-01,  1.4717e-01, -3.7147e-01,  6.2168e-01,\n",
      "        -1.3571e+00, -9.7738e-02, -1.6252e-01,  4.9355e-02,  3.7343e-01,\n",
      "         4.1569e-01, -6.5020e-01, -2.0782e-01, -4.4522e-01, -6.1022e-02,\n",
      "        -8.5939e-02, -5.2818e-02, -3.8140e-02, -1.6339e-01, -4.4295e-02,\n",
      "         1.1409e-01, -3.1593e-01, -2.7018e-02, -6.1272e-01,  6.2118e-01,\n",
      "        -1.6870e-01,  4.5207e-01, -2.4500e-01,  9.6310e-02, -1.5215e-01,\n",
      "         1.6770e-01,  1.1891e-01, -1.6849e-01, -1.9749e-01, -2.0939e-02,\n",
      "        -4.2006e-01,  1.1354e-02, -1.8515e-01,  1.3675e-01,  2.5329e-01,\n",
      "        -1.5745e+00,  2.1741e-01, -1.7040e-02,  2.4579e-01,  1.6026e-01,\n",
      "         4.7112e-03, -2.0889e-02, -5.2599e-02, -3.2691e-01, -3.4819e-01,\n",
      "        -1.3395e-01,  2.5405e-02, -8.4282e-02,  1.3262e-03, -1.7753e-01,\n",
      "         3.4388e-01,  2.3656e-01, -1.5996e-01, -1.3427e-01, -1.8038e-01,\n",
      "         1.0236e-01, -4.8935e-02, -1.1984e-02,  2.2873e-01,  2.7904e-01,\n",
      "         1.4517e-01,  8.1365e-02, -2.2411e-01, -2.0964e-01, -5.1920e-02,\n",
      "         4.5646e-02,  1.6435e-01,  1.8239e-01,  2.0082e-01, -3.7734e-02,\n",
      "         3.6389e-02, -2.7248e-01,  7.6205e-02,  4.7619e-01, -1.4818e-01,\n",
      "         1.2624e-01,  2.0367e-01, -2.8018e-01, -2.3791e-01, -3.2136e-02,\n",
      "         2.0686e-01, -3.3678e-02, -2.5944e-01,  3.2182e-01,  1.7986e-02,\n",
      "         3.1356e-02, -1.7455e-01, -2.4845e-02, -1.7800e-01,  7.9404e-02,\n",
      "         3.5348e-01, -3.2009e-01, -5.9247e-01,  3.7324e-03, -1.6122e-02,\n",
      "         1.4389e-01, -1.3901e-01,  3.3740e-01, -1.1756e-01,  3.6375e-01,\n",
      "         2.9247e-01, -9.8322e-02, -2.8628e-01,  9.2209e-03,  3.8727e-02,\n",
      "         4.3220e-02, -2.8232e-01,  1.8218e-02,  9.4614e-02,  1.4456e-01,\n",
      "        -2.7625e-01,  4.6469e-02, -1.2904e-01, -1.5591e-01, -3.0345e-01,\n",
      "         9.9123e-02,  2.4686e-01,  1.2471e-03, -6.5270e-02, -1.9097e-01,\n",
      "        -1.2912e-01, -5.0761e-02,  1.1594e-01, -3.7174e-01, -3.3113e-01,\n",
      "        -3.2153e-01, -1.7946e-01, -8.3406e-03, -1.4949e-01,  4.6403e-01,\n",
      "         3.3473e-02,  2.6567e-01,  3.3427e-02,  1.9559e-01,  1.5838e-01,\n",
      "        -2.5213e-01,  1.4155e-01,  3.7133e-01,  1.7297e-01,  2.5766e-01,\n",
      "        -2.1319e-01, -2.1755e-01, -2.7419e-01, -6.3401e-01,  2.7682e-01,\n",
      "         1.5022e-01,  2.3776e-01,  1.2569e-01,  3.7617e-01, -1.3221e-01,\n",
      "         7.3441e-01, -3.0163e-02, -2.3734e-01, -1.0193e-01,  2.8865e-01,\n",
      "        -7.5750e-02,  3.2836e-01, -3.0645e-01,  1.8341e-01,  1.1045e-01,\n",
      "        -3.6757e-01,  1.4363e-01,  2.8824e-01,  4.7819e-01,  4.1435e-01,\n",
      "        -3.4703e-01, -1.6787e-01, -1.2824e-01, -3.5126e-01, -2.2585e-01,\n",
      "        -7.9352e-02,  1.6748e-02,  2.6776e-01, -1.6806e-01,  8.6580e-02,\n",
      "        -2.7428e-01,  2.1008e-01,  8.6993e-02,  1.7836e-01,  5.5991e-02,\n",
      "        -2.8375e-02,  4.3394e-01,  2.7395e-02, -1.7000e-02,  2.1599e-01,\n",
      "        -7.5303e-01, -1.3934e-01,  7.2140e-02, -3.2722e-01, -7.1864e-02,\n",
      "         3.2818e-01, -2.6540e-01,  5.3146e-02, -9.9581e-02,  1.9510e-01]), tensor([ 1.2068e-01, -6.8778e-01,  2.3724e-01,  1.4929e-01,  1.3060e-01,\n",
      "         8.6327e-01, -2.2608e-01, -2.7859e-01, -8.7173e-03,  1.1919e+00,\n",
      "        -1.8170e-01, -6.6141e-01,  3.1508e-01, -1.0409e-01, -1.0011e+00,\n",
      "        -3.6048e-01, -5.0077e-01,  1.1372e+00, -8.5858e-02, -2.3853e-01,\n",
      "         3.3329e-01,  1.8856e-01, -1.4365e-01,  2.9901e-01,  5.5190e-02,\n",
      "         3.4018e-01, -1.2494e-01, -1.7170e-01,  1.1000e-01, -2.5690e-01,\n",
      "        -1.3818e-01,  8.0722e-02, -1.4921e-01,  2.6769e-01, -2.6696e-01,\n",
      "         4.3565e-01, -1.8308e-01,  4.5150e-01, -4.5320e-02,  1.5004e-01,\n",
      "         7.9688e-02, -1.3857e-01, -1.5733e-02,  2.2566e-01, -6.1519e-01,\n",
      "        -4.7227e-02,  2.7356e-01,  3.3813e-01, -2.2540e-01, -7.0835e-02,\n",
      "         4.7841e-02,  4.2405e-01,  5.2420e-01,  9.6423e-02,  3.2555e-01,\n",
      "         1.9156e-01, -3.8527e-01, -2.9542e-01, -3.4486e-01,  2.9394e-02,\n",
      "        -4.3760e-01, -2.0589e-01, -2.3535e-01,  1.5243e-01,  5.7842e-01,\n",
      "         5.1381e-01,  1.2925e-01, -5.4917e-01,  1.1281e-01,  3.8680e-01,\n",
      "        -1.9964e-01,  2.4321e-01,  7.0461e-01,  2.3034e-01, -1.0036e-01,\n",
      "         3.2769e-01, -1.4110e-01,  4.9831e-02,  5.1886e-01,  1.0560e-01,\n",
      "         3.4869e-02, -1.6183e-01,  1.3393e-01, -6.3147e-01, -4.6548e-01,\n",
      "         2.4356e-01,  9.4820e-01,  2.3236e-01,  1.1882e-01,  6.8750e-01,\n",
      "        -3.7826e-01, -2.0253e-01,  5.0263e-01, -5.6114e-01,  2.5641e-01,\n",
      "        -1.4678e-01, -4.5415e-01,  2.0910e-01,  1.0077e-01,  3.0680e-01,\n",
      "         1.5955e-01, -1.3362e-01,  6.3496e-02,  8.6152e-02,  2.3055e-01,\n",
      "        -1.0401e+00,  2.6652e-01,  3.7551e-01,  9.9860e-02, -2.2697e-01,\n",
      "         1.0939e-01, -5.4537e-02, -2.2191e-01, -2.5197e-01, -1.2207e-01,\n",
      "        -6.0130e-02,  2.4562e-01,  3.6662e-01, -1.4235e-01, -4.0968e-01,\n",
      "        -2.9911e-01,  4.4864e-02, -3.1162e-01, -3.7974e-01, -6.8736e-02,\n",
      "        -7.4145e-02, -1.8266e-01,  7.6758e-02, -3.4329e-01, -2.3711e-01,\n",
      "        -3.6815e-01,  6.1969e-01, -8.7666e-02,  3.5130e-01, -2.7511e-01,\n",
      "         6.4125e-02,  4.0022e-01,  3.2987e-01, -1.8096e-01,  1.8185e-02,\n",
      "        -1.6149e+00, -3.0447e-01, -1.4722e-01,  3.9040e-01, -1.0856e-01,\n",
      "        -4.5758e-01, -3.2117e-01, -1.0958e-02,  3.0677e-01, -1.6705e-01,\n",
      "         8.7645e-02,  5.7996e-01, -6.3114e-02,  1.3517e-01,  9.0517e-02,\n",
      "        -3.8002e-02, -6.4628e-02,  4.2031e-01, -1.6971e-01, -1.3931e-01,\n",
      "         2.2762e-01,  3.0051e-01, -2.3618e-01,  4.6785e-01, -5.3985e-01,\n",
      "         5.9454e-01, -2.7862e-01,  3.1890e-01,  1.2813e-01, -3.3260e-01,\n",
      "        -1.2442e-01, -1.7997e-01, -3.5720e-01, -1.3535e-01,  2.6111e-01,\n",
      "         1.1142e-01, -4.1010e-01,  8.5529e-02,  4.6526e-02,  2.9048e-01,\n",
      "        -2.0403e-01, -2.3937e-01, -5.1185e-01, -2.7914e-01, -1.5422e-01,\n",
      "        -2.0019e-01, -1.1308e-01, -1.6116e-01, -9.9716e-02,  4.5213e-02,\n",
      "        -1.1161e-01, -6.5251e-02, -4.0483e-01, -1.4037e-01,  1.2457e-01,\n",
      "        -2.1901e-01, -4.9303e-01,  1.1837e-01,  7.1657e-02, -3.9066e-01,\n",
      "        -1.5331e-01, -3.2047e-01,  4.5860e-01, -4.1106e-01, -2.0040e-01,\n",
      "        -3.8479e-01, -8.8657e-02,  1.0591e-01,  8.9181e-01, -1.4347e-01,\n",
      "         1.0916e-01, -1.6951e-01, -6.3606e-02,  3.8560e-01,  4.7242e-01,\n",
      "         5.3345e-03, -1.0050e-01,  5.0863e-01, -3.4507e-01,  1.5553e-01,\n",
      "         1.7826e-01,  4.3895e-01,  4.5711e-01, -9.2184e-02,  3.8860e-01,\n",
      "        -1.6177e-01,  1.2344e-01,  2.5216e-01, -6.4692e-01,  1.3502e-01,\n",
      "         1.1518e-01,  5.3011e-02,  2.4229e-01,  2.2201e-02,  7.8828e-02,\n",
      "         7.7050e-02,  7.2676e-01,  2.4889e-01, -2.3173e-02, -9.5413e-02,\n",
      "         3.6491e-01, -7.7696e-02, -2.7767e-01,  1.9872e-02,  6.1213e-02,\n",
      "        -2.2533e-01,  1.8636e-01, -2.7395e-01, -1.3476e-01,  4.0247e-01,\n",
      "        -4.4172e-01, -4.2750e-01, -4.9515e-01, -1.2706e-01, -1.5228e-01,\n",
      "        -2.4468e-01, -3.0870e-01, -1.3902e-01, -4.3183e-01, -1.9877e-01,\n",
      "        -1.5428e-01,  1.3042e-01,  5.3068e-01, -3.6848e-01,  3.2619e-01,\n",
      "        -2.1031e-01, -2.8744e-01,  1.8757e-02,  2.0462e-01, -9.5564e-02,\n",
      "         6.1451e-01,  1.1248e-01,  3.1089e-01, -3.9186e-01, -1.9755e-01,\n",
      "        -2.5630e-01, -4.7619e-02,  6.6432e-01, -7.3597e-04, -4.6861e-01,\n",
      "         4.2194e-02, -2.6037e-01, -6.0886e-02, -1.2673e-01,  2.1854e-01,\n",
      "        -1.7868e-01, -3.3772e-01, -4.1209e-01,  3.4772e-02,  6.9706e-02,\n",
      "         2.7232e-01, -1.9780e-01,  5.6148e-01, -2.9668e-01, -8.6783e-02,\n",
      "        -2.9992e-01, -3.3147e-01, -4.9815e-03, -5.6487e-01, -1.0824e-01]), tensor([ 1.0183e-01,  3.8036e-02, -6.6025e-01, -2.4779e-02, -2.4898e-02,\n",
      "         1.1468e-01, -1.7538e-01,  1.1621e-02, -2.3979e-02,  2.7031e+00,\n",
      "        -6.3406e-02,  3.1654e-01,  7.7228e-02, -1.1174e-01, -5.0132e-02,\n",
      "         8.2496e-02,  3.8234e-02,  1.3710e+00, -3.5457e-02, -4.7966e-02,\n",
      "        -9.8730e-02, -4.2207e-02, -5.3232e-01, -2.8461e-01,  4.0777e-02,\n",
      "        -2.2604e-01,  1.3070e-01, -2.1035e-01, -8.0208e-02, -9.4161e-02,\n",
      "        -1.0420e-01,  3.4257e-01,  1.1669e-01,  1.1959e-01,  2.9522e-02,\n",
      "         1.4690e-01,  1.4658e-02,  3.6070e-01, -2.7095e-01, -9.7110e-03,\n",
      "        -1.6835e-01, -3.8007e-02,  1.3587e-01,  2.7245e-01,  2.0485e-01,\n",
      "        -6.5047e-02,  2.3436e-02,  1.3803e-01,  9.4945e-03,  2.6878e-01,\n",
      "        -3.2575e-01, -1.3016e-01, -1.9430e-02,  1.5018e-01,  1.7575e-01,\n",
      "         1.8589e-01, -1.3061e-03, -4.0351e-01, -2.4883e-02, -1.7656e-02,\n",
      "         2.8558e-01, -1.2149e-01,  1.7198e-02,  2.5776e-01, -6.5523e-02,\n",
      "         2.2386e-01,  1.1224e-01, -2.7200e-02, -4.3638e-02, -1.4015e-01,\n",
      "         3.6252e-01,  7.7347e-02,  1.4373e-01, -1.5636e-01,  6.6736e-02,\n",
      "         9.9078e-02, -1.4970e-01, -1.7740e-02,  1.1405e-01,  3.3820e-02,\n",
      "        -6.5001e-02, -2.6704e-01, -4.8345e-01, -1.2948e-01,  2.3077e-01,\n",
      "        -1.2791e-01, -2.1541e-01, -3.1293e-02,  1.0397e-01,  1.9404e-02,\n",
      "        -1.8536e-01, -2.0471e-02, -1.1086e-01, -9.9542e-02,  4.9773e-01,\n",
      "        -4.3341e-02,  2.2239e-02, -3.4308e-01, -9.4109e-02,  1.5871e-01,\n",
      "        -7.4898e-02,  1.5256e-01, -2.7394e-02, -4.1435e-02,  3.8497e-01,\n",
      "        -2.2488e+00, -2.1590e-01, -7.0071e-02, -3.1491e-01,  2.0208e-01,\n",
      "         6.7866e-02,  2.0282e-01, -2.0211e-01, -1.3368e-01, -2.1818e-01,\n",
      "        -8.5502e-02, -4.5193e-02,  2.6889e-02,  4.7289e-02, -6.9021e-02,\n",
      "         2.6901e-01,  2.9949e-02, -9.1587e-02,  1.6245e-01,  1.1095e-01,\n",
      "        -2.3984e-02, -6.1923e-02,  1.0598e-01,  9.6927e-02,  9.3505e-02,\n",
      "        -3.8464e-02, -2.0603e-01, -1.4116e-01, -8.5065e-02, -1.3862e-01,\n",
      "         2.0741e-01, -1.4316e-01, -3.3674e-01,  7.6693e-02,  2.4646e-01,\n",
      "        -7.0068e-01, -8.9953e-02,  1.3859e-01,  2.9812e-01, -1.0164e-01,\n",
      "         2.6175e-01,  3.0568e-01, -2.6894e-01, -2.4430e-01, -1.4858e-01,\n",
      "         2.2918e-01, -7.8447e-02, -9.9082e-02, -1.9096e-01,  2.8247e-02,\n",
      "        -1.8021e-01, -2.3662e-01,  4.6331e-02, -2.1663e-01, -1.3190e-01,\n",
      "        -2.0643e-01, -3.7431e-02,  4.6078e-02,  7.4510e-02, -1.5127e-01,\n",
      "        -2.2669e-01,  4.8610e-01,  4.0403e-01, -5.3061e-02, -2.9176e-01,\n",
      "         2.7973e-02,  2.9423e-01,  2.3989e-01, -8.6836e-02,  1.7828e-01,\n",
      "         9.3448e-02, -1.1386e-01, -9.3845e-02,  1.8748e-01,  1.5724e-01,\n",
      "         2.1994e-01, -7.1249e-02,  5.9835e-02, -2.2260e-02, -5.3702e-01,\n",
      "        -9.2959e-02, -1.0405e-01,  5.7773e-02, -1.8153e-02, -3.5716e-02,\n",
      "         2.2277e-01, -3.7132e-02, -2.3460e-01, -4.6880e-01,  2.1942e-01,\n",
      "         1.4530e-01, -3.4313e-01,  1.3081e-01, -3.0395e-01,  2.9751e-01,\n",
      "        -1.0295e-01, -1.4493e-02, -1.9611e-01, -2.6505e-02, -3.5469e-01,\n",
      "         2.9862e-01,  2.1855e-01,  2.3190e-02,  2.5569e-02,  9.7139e-02,\n",
      "         1.5167e-01,  3.0383e-01, -2.5810e-01, -2.5566e-01, -3.3237e-01,\n",
      "         3.2271e-01,  3.8838e-03,  1.9129e-01, -3.7998e-01,  8.9573e-02,\n",
      "         3.9509e-01,  1.1632e-01, -2.5433e-01,  2.7967e-01,  1.6203e-02,\n",
      "        -9.4949e-02, -1.1562e-01,  5.9826e-02, -2.4113e-01, -2.4098e-01,\n",
      "        -2.1312e-01,  2.0693e-02, -2.5573e-02,  1.2751e-01, -5.6822e-02,\n",
      "        -5.5459e-02,  5.3598e-02,  3.0531e-01, -3.0709e-01,  1.6257e-01,\n",
      "         1.5218e-01,  4.9133e-01, -3.6898e-02, -8.8908e-02,  7.6746e-02,\n",
      "        -2.0356e-01,  1.7744e-01, -2.6223e-02, -2.0506e-01,  5.1539e-02,\n",
      "        -2.9753e-02,  2.9346e-02, -1.9197e-01,  1.1215e-01, -1.0747e-01,\n",
      "         9.4084e-01, -1.4257e-02,  1.7442e-01,  3.5576e-01,  3.4818e-01,\n",
      "        -1.3929e-01,  1.7779e-01, -1.7842e-01,  1.5391e-01, -2.3923e-01,\n",
      "         2.5536e-01, -2.0729e-01,  1.0623e-01,  1.2002e+00, -2.5539e-01,\n",
      "         2.1623e-01,  3.2518e-01,  1.2773e-01, -5.1345e-01,  1.9569e-01,\n",
      "         7.5269e-02, -1.9003e-01,  4.4788e-01,  1.4966e-01,  4.6119e-01,\n",
      "        -7.3948e-02,  2.4173e-01,  1.6204e-01, -2.8791e-01,  1.2861e-01,\n",
      "         1.1408e-01,  1.8312e-01, -2.1722e-01,  1.3522e-01, -1.9312e-01,\n",
      "        -6.5547e-01,  1.4517e-03, -2.0655e-01,  9.7522e-02, -6.1551e-02,\n",
      "         1.1497e-01, -2.1659e-01, -3.4982e-01,  5.5048e-01,  1.7670e-01]), tensor([-6.5997e-01,  4.7525e-01, -1.7474e-01, -2.5347e-02, -7.6390e-01,\n",
      "         3.0729e-01, -4.8804e-01, -1.5103e-01,  2.9710e-01,  2.1505e+00,\n",
      "        -3.6817e-01,  6.6258e-01, -1.8598e-01,  1.5628e-01, -8.6197e-03,\n",
      "        -5.4291e-02, -8.9996e-02,  1.9509e+00, -2.1846e-01, -2.0772e-01,\n",
      "        -1.2684e-01, -8.3089e-02, -2.9848e-01, -3.9885e-01, -2.3848e-01,\n",
      "        -3.6709e-01,  3.2495e-02, -1.6355e-01,  3.6754e-02, -3.1578e-01,\n",
      "         2.3094e-01,  4.0611e-02, -9.4751e-02,  3.7152e-01, -3.9477e-02,\n",
      "        -1.5837e-01, -3.6900e-01,  8.0127e-02,  1.0326e-01, -1.3774e-01,\n",
      "         4.0570e-01,  3.3531e-01,  3.0476e-01, -3.0999e-01,  9.3940e-02,\n",
      "         3.7856e-02,  9.4021e-02,  1.4603e-01,  4.3868e-01,  3.0687e-01,\n",
      "        -2.4872e-01, -3.0817e-01,  2.8750e-01, -8.5075e-02,  2.0596e-01,\n",
      "        -6.7259e-02,  2.4283e-01, -6.2952e-01, -6.4753e-02, -2.4871e-01,\n",
      "         3.3241e-02, -2.7250e-01, -1.4841e-01,  3.3033e-01, -1.4199e-01,\n",
      "        -3.1648e-01,  1.7151e-01,  3.3997e-01, -3.7890e-01, -4.1518e-01,\n",
      "         2.4339e-01,  1.8242e-01,  2.7408e-01, -3.2282e-01,  2.2710e-02,\n",
      "         1.8852e-01,  2.5845e-01,  1.8331e-01,  2.1136e-01,  9.9660e-02,\n",
      "         2.5124e-01,  1.2490e-01, -1.8174e-01, -8.4037e-02,  6.0730e-02,\n",
      "        -2.6481e-01,  2.2966e-01,  3.9521e-01,  2.0464e-01, -7.9674e-02,\n",
      "         4.8331e-02,  6.9915e-02, -1.3455e-01, -9.6021e-02, -3.4864e-01,\n",
      "        -1.2018e-01, -4.5954e-01,  7.2383e-02, -8.8967e-02,  3.9102e-01,\n",
      "        -1.6187e-01, -6.8510e-02, -4.2568e-01,  2.8913e-01,  3.9129e-01,\n",
      "        -2.0815e+00,  2.7508e-01, -2.9732e-02, -1.7493e-01, -4.5889e-01,\n",
      "        -2.3931e-01, -4.8611e-01,  3.6057e-02,  2.1967e-01,  2.9403e-02,\n",
      "        -1.0297e-01, -1.8407e-01, -2.2711e-01,  2.6786e-01, -1.2461e-01,\n",
      "         3.1592e-01,  8.9514e-02, -4.0548e-01, -3.0665e-01, -6.4576e-03,\n",
      "        -2.9522e-01, -5.7136e-01, -8.2421e-02, -2.9367e-01, -1.5003e-02,\n",
      "         1.1279e-01,  7.5086e-02,  1.9910e-01,  8.2660e-02, -1.0234e-01,\n",
      "         2.3732e-02, -1.8086e-02, -4.7446e-02, -7.1982e-02, -1.4620e-01,\n",
      "        -5.9882e-01,  6.4360e-01,  1.1151e-01,  4.4330e-01, -2.0906e-02,\n",
      "        -2.6041e-01, -2.2493e-02, -3.5753e-02,  1.7426e-02, -1.4945e-01,\n",
      "         5.6114e-01, -7.1756e-02, -1.0569e-01, -2.2341e-01, -2.3026e-01,\n",
      "        -5.9972e-01,  3.3505e-01,  3.2096e-01, -4.0738e-01, -1.4868e-01,\n",
      "         1.4155e-01,  1.1095e-01, -5.8212e-02,  3.8213e-01, -3.7626e-01,\n",
      "         2.3773e-01,  4.8466e-02,  1.0310e-01, -9.4711e-02,  3.3645e-01,\n",
      "         1.4481e-01, -3.9748e-01,  2.8610e-01, -3.5524e-01, -1.5431e-01,\n",
      "         9.3662e-02, -2.7120e-01,  6.3640e-02, -9.4075e-02, -3.5388e-01,\n",
      "         8.7025e-02,  3.8984e-02, -2.3888e-01,  3.6587e-01, -7.2174e-01,\n",
      "         5.2487e-02, -3.9737e-01, -1.7652e-01, -1.3961e-01,  4.2823e-01,\n",
      "         2.4622e-01,  1.6096e-01, -4.0602e-02,  6.9860e-03,  2.4927e-01,\n",
      "        -3.5480e-01, -4.6664e-03,  2.3166e-01, -2.0136e-01,  2.3812e-01,\n",
      "         5.3396e-01, -4.7683e-01,  1.2030e-01, -2.1140e-02, -4.5491e-01,\n",
      "         3.5957e-01,  2.0376e-01,  3.0141e-01,  2.0735e-01,  2.7404e-01,\n",
      "         1.1197e-01,  3.6652e-01, -8.0403e-02,  1.1519e-02,  4.3433e-02,\n",
      "         4.5265e-01, -1.5103e-01,  9.3182e-02,  3.7051e-02,  5.2837e-01,\n",
      "         8.4807e-02, -7.4409e-02, -1.4797e-01, -2.1187e-01, -1.8465e-01,\n",
      "        -2.7594e-01,  7.4536e-02, -6.9196e-02,  3.1097e-01, -8.3333e-02,\n",
      "         7.4295e-01, -2.8423e-01, -9.0552e-02,  3.7878e-02, -4.1159e-01,\n",
      "         1.9748e-01, -1.2807e-01,  1.3686e-02, -2.8433e-01,  1.2132e-01,\n",
      "        -5.6361e-02,  4.0019e-01, -2.3165e-02,  2.3558e-02,  4.5175e-01,\n",
      "        -3.8647e-01,  1.0114e-01, -2.9169e-01,  4.6815e-02, -1.5834e-01,\n",
      "        -2.9591e-02, -4.0870e-01,  1.6634e-01, -2.2297e-03, -7.7138e-02,\n",
      "         1.2623e+00, -3.8100e-01, -2.2215e-01,  3.3289e-01,  3.3647e-01,\n",
      "         4.5612e-02, -1.5282e-02, -4.7777e-01,  5.3737e-01,  1.2828e-01,\n",
      "         1.0190e-01,  4.2714e-02, -3.1651e-01,  7.2345e-01, -3.3714e-01,\n",
      "         9.0672e-01,  1.6290e-01, -3.1256e-02, -8.3629e-01, -1.3138e-01,\n",
      "        -1.2685e-01, -5.4180e-01,  4.0443e-04, -1.3345e-01,  2.6344e-01,\n",
      "         1.0633e-01,  3.4139e-01, -1.7880e-01,  1.3548e-01, -3.9443e-01,\n",
      "         9.4963e-02, -5.9723e-02, -1.4807e-01, -3.3261e-02,  3.3264e-01,\n",
      "        -5.4458e-01,  2.6185e-01,  4.8051e-03, -2.5650e-01, -7.3062e-02,\n",
      "        -6.2573e-03, -2.9650e-01, -7.2638e-01, -1.7235e-01, -1.5254e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([-0.4263,  0.4431, -0.3452, -0.1326, -0.0582,  0.0526,  0.2157, -0.3672,\n",
      "        -0.0452,  2.2444, -0.2909,  0.1667, -0.0521,  0.1596, -0.4276, -0.1115,\n",
      "        -0.1495,  1.1800, -0.1960,  0.1559, -0.0611, -0.0116,  0.2685, -0.3018,\n",
      "        -0.0558,  0.1212,  0.0105, -0.1806,  0.2328, -0.2637,  0.1103,  0.0622,\n",
      "         0.0150, -0.1069,  0.0985,  0.0485,  0.3336, -0.1618, -0.2850, -0.2865,\n",
      "        -0.1125,  0.1242, -0.2498, -0.2008,  0.2603,  0.2521, -0.1784,  0.1540,\n",
      "        -0.1980, -0.2264, -0.0741,  0.5029,  0.3210, -0.0348,  0.1654,  0.0571,\n",
      "        -0.2097,  0.0984,  0.0351, -0.0231, -0.1174, -0.5133, -0.0210,  0.3996,\n",
      "         0.3053, -0.3884,  0.0026,  0.2902,  0.0170,  0.0640,  0.1079,  0.2901,\n",
      "         0.0617,  0.0682, -0.0140,  0.0486, -0.0117, -0.2653, -0.1449,  0.4540,\n",
      "         0.0672,  0.1419,  0.3730, -0.0077,  0.0184, -0.1022, -0.0052, -0.1223,\n",
      "         0.2585, -0.1121, -0.0540, -0.1995, -0.3229,  0.2621,  0.3576, -0.2607,\n",
      "         0.3793, -0.4268,  0.0613,  0.0085, -0.3106, -0.1509, -0.2257,  0.0741,\n",
      "         0.2642, -0.9689,  0.3205,  0.0132,  0.0207, -0.2406,  0.2145, -0.3893,\n",
      "        -0.0580, -0.0558,  0.2232,  0.1833, -0.0242, -0.1512, -0.0109, -0.2756,\n",
      "         0.3115,  0.2192, -0.0915,  0.0552,  0.0065,  0.1343, -0.2837, -0.3831,\n",
      "         0.0740, -0.0614,  0.1159, -0.0932, -0.0917, -0.2275, -0.1191,  0.2101,\n",
      "         0.0098, -0.2344,  0.2953, -0.2639, -2.1549,  0.3910,  0.6084,  0.0214,\n",
      "        -0.2912, -0.5258, -0.3045, -0.1279,  0.3959,  0.2025, -0.3807, -0.0760,\n",
      "         0.0463, -0.2457,  0.0144, -0.0095, -0.0292, -0.1123, -0.0300, -0.5239,\n",
      "         0.0536,  0.0321,  0.3562,  0.0406,  0.2837, -0.5109,  0.2068, -0.3715,\n",
      "         0.1904, -0.0481,  0.0026, -0.0696,  0.2058, -0.4011,  0.0067,  0.0664,\n",
      "        -0.1958,  0.1930,  0.1475, -0.0423, -0.0449, -0.4694, -0.3840,  0.0192,\n",
      "        -0.2486, -0.1429, -0.0854, -0.0881,  0.2324, -0.1667, -0.0250, -0.0293,\n",
      "        -0.0047, -0.1214, -0.2083,  0.2437,  0.0600, -0.1849,  0.3388,  0.0585,\n",
      "         0.1193,  0.0669, -0.2004, -0.0544,  0.0373,  0.2203, -0.2282,  0.0489,\n",
      "         0.0609,  0.0269, -0.2008, -0.0055,  0.0437, -0.6060, -0.2084,  0.1301,\n",
      "         0.1803, -0.0868, -0.1320,  0.0576, -0.1610, -0.0711,  0.0158,  0.4078,\n",
      "         0.5395,  0.1383, -0.2069,  0.0767,  0.0979,  0.0717, -0.1065,  0.0542,\n",
      "        -0.2932,  0.1468,  0.1678, -0.2044,  0.0470, -0.3186, -0.2226,  0.1279,\n",
      "         0.1733, -0.1027, -0.1596,  0.2546,  0.2758,  0.0113, -0.2191, -0.5016,\n",
      "        -0.1505,  0.0988,  0.3162, -0.0879, -0.4827, -0.1241, -0.1147,  0.2252,\n",
      "         0.2810, -0.3834, -0.1975,  0.0671, -0.1339,  0.1416,  0.2693,  0.4270,\n",
      "         0.1372, -0.1330,  0.1373,  0.3249,  0.5503,  0.2532,  0.0774,  0.0491,\n",
      "        -0.3611, -0.5255, -0.3736,  0.3665,  0.0321, -0.2845,  0.1439,  0.7067,\n",
      "        -0.2256, -0.2962, -0.1896, -0.0450, -0.0239,  0.0782,  0.0855, -0.2375,\n",
      "         0.1743,  0.0398, -0.4591, -0.0528, -0.3205, -0.1217,  0.3155,  0.0455,\n",
      "         0.2264, -0.4303, -0.0689,  0.1287]), tensor([-2.6253e-02,  4.1114e-01, -4.6808e-01, -1.1607e-01,  2.2080e-01,\n",
      "         2.0059e-01,  1.7782e-01, -1.5760e-01, -4.7263e-02,  2.6491e+00,\n",
      "        -4.0295e-01, -6.0323e-02,  2.5007e-01, -1.3078e-01, -3.6755e-01,\n",
      "        -6.8406e-02, -1.2434e-01,  5.4362e-01, -3.8307e-01, -8.9131e-02,\n",
      "         4.0154e-01, -1.1680e-01, -8.2915e-02, -2.5571e-02, -2.2326e-01,\n",
      "        -5.7022e-02, -1.9173e-01, -1.2071e-01,  5.0005e-01, -2.3356e-01,\n",
      "        -7.2946e-02,  4.7379e-01, -1.9689e-02,  4.0735e-02,  3.5604e-02,\n",
      "         2.9909e-01,  2.1224e-01,  2.8975e-01, -1.9879e-01, -9.4861e-02,\n",
      "        -3.6231e-01, -1.6967e-01, -8.7346e-02, -6.6327e-02,  2.1555e-01,\n",
      "         2.2150e-01, -2.0643e-01, -2.1694e-01,  2.2083e-01,  7.4699e-02,\n",
      "        -1.6566e-01,  5.0853e-02,  5.5035e-02, -8.5316e-02,  3.7982e-01,\n",
      "        -1.2180e-01, -1.0634e-01, -1.9172e-01,  6.6343e-02, -8.3216e-02,\n",
      "        -1.6345e-01, -4.7134e-01, -2.7012e-01,  5.5117e-01,  2.2192e-01,\n",
      "        -8.1492e-02, -7.8703e-02,  2.3611e-01,  3.2529e-01,  2.4142e-01,\n",
      "         5.4494e-02,  3.9628e-02,  4.3925e-01, -2.8236e-02,  1.6166e-01,\n",
      "         3.7985e-01,  1.7732e-01, -1.7527e-01, -1.0603e-01,  3.2054e-01,\n",
      "         4.5432e-02,  4.7100e-02, -2.2273e-01, -1.5223e-01,  1.6190e-01,\n",
      "        -4.7330e-01, -1.0049e-01, -7.3164e-01,  4.0342e-01, -1.8357e-01,\n",
      "        -1.6873e-01, -1.8010e-01, -4.9175e-01,  2.4319e-01,  2.8859e-01,\n",
      "         2.8541e-02,  3.1377e-02, -3.0766e-01, -1.4750e-01,  1.1294e-01,\n",
      "        -2.7288e-01,  6.5612e-02,  1.1546e-01, -1.6716e-02,  3.4443e-01,\n",
      "        -5.8627e-01, -7.9068e-03, -3.0392e-01, -1.5009e-01,  2.4832e-01,\n",
      "         1.0956e-01, -2.3923e-01,  2.0125e-01, -7.7826e-02,  3.2598e-01,\n",
      "         2.7762e-02,  7.4227e-04, -7.9963e-02, -2.4501e-01, -2.8008e-01,\n",
      "         1.6071e-01, -5.5964e-01,  1.3096e-01, -2.7048e-01,  5.2206e-01,\n",
      "         1.4861e-02,  3.9519e-02, -5.1414e-01,  5.9013e-02, -1.3979e-01,\n",
      "         6.0754e-03,  5.6710e-02, -1.5732e-01,  2.5091e-01,  2.9526e-01,\n",
      "        -1.8611e-01, -9.1597e-02, -1.6574e-01,  4.2112e-02, -5.3309e-02,\n",
      "        -2.0649e+00,  2.1768e-02,  4.3290e-02,  1.5988e-01, -6.1915e-02,\n",
      "        -2.0167e-01, -2.6453e-01,  3.5073e-01, -3.5387e-01, -2.3858e-01,\n",
      "        -5.0072e-02, -3.6170e-02, -8.1493e-02, -6.0257e-02, -2.9292e-02,\n",
      "         2.1701e-02,  6.3416e-02, -2.4915e-01, -1.4959e-01,  1.7111e-02,\n",
      "        -2.1232e-01,  2.4030e-01, -2.5176e-01,  6.8250e-02,  2.1020e-01,\n",
      "        -2.4638e-02,  2.1119e-01, -3.0185e-01,  3.8409e-02,  8.6446e-02,\n",
      "        -2.2249e-01, -1.6174e-01,  1.2949e-01, -4.2277e-01, -9.1328e-02,\n",
      "         1.5716e-01, -4.0425e-01,  2.6495e-01,  3.8758e-02,  1.0048e-01,\n",
      "         2.8384e-01, -2.4140e-02, -2.0202e-01, -8.4607e-02,  5.9191e-02,\n",
      "        -1.8987e-04, -1.5551e-01, -1.8898e-01,  1.4182e-01,  1.7789e-01,\n",
      "         1.4816e-01, -8.5768e-02, -2.2884e-01, -3.0741e-01,  1.3850e-01,\n",
      "         7.8822e-02,  3.9452e-02, -1.8836e-01,  3.1088e-01,  4.1552e-01,\n",
      "        -1.5816e-01, -6.5923e-02, -8.2620e-02, -3.5303e-01,  3.1391e-02,\n",
      "         3.3925e-02,  2.4806e-01, -3.8790e-02,  2.1579e-01,  1.2207e-01,\n",
      "        -1.8095e-01, -2.5094e-01, -2.0220e-01, -1.0523e-01,  5.0853e-02,\n",
      "         4.6060e-02, -2.2937e-01, -1.2315e-01, -4.1685e-01, -2.1201e-01,\n",
      "         2.2706e-01,  2.6521e-01,  9.0586e-02, -1.5632e-02,  9.4330e-02,\n",
      "         2.2849e-01,  1.0682e-01,  2.6619e-01, -1.9058e-01, -2.1441e-01,\n",
      "        -3.7245e-01,  2.4061e-02, -1.3342e-02,  1.5929e-01, -1.4696e-01,\n",
      "        -7.0773e-02,  4.6464e-02, -2.4139e-01, -1.5272e-01,  3.3306e-01,\n",
      "         2.9590e-01, -8.1171e-02,  1.4009e-01,  1.7841e-01,  7.7220e-02,\n",
      "        -1.0883e-01, -9.9546e-02,  4.6577e-02, -1.5119e-01,  4.9712e-01,\n",
      "         3.2069e-01, -1.9259e-01, -1.5380e-01, -9.3683e-03, -2.3859e-01,\n",
      "         1.5952e-01, -1.3513e-01, -1.9482e-01,  4.2889e-02,  2.2077e-01,\n",
      "         2.0161e-01,  2.2125e-01,  1.9316e-02,  1.3354e-01,  7.4426e-02,\n",
      "         1.7663e-01, -6.4972e-02,  2.8518e-01,  7.3072e-01,  4.3225e-01,\n",
      "        -2.3363e-02,  7.4753e-03, -3.8010e-01, -3.0049e-01, -1.7177e-01,\n",
      "         5.7312e-03, -3.3477e-02, -2.1187e-02,  3.0726e-04,  8.9830e-02,\n",
      "        -1.8270e-01, -4.3976e-02,  1.4204e-01, -1.8358e-01,  4.5025e-02,\n",
      "        -1.2959e-01,  3.5429e-01, -2.4448e-01, -1.1895e-03,  1.3399e-01,\n",
      "        -2.5789e-01, -1.1015e-01, -3.2256e-01,  4.3125e-02,  4.1910e-01,\n",
      "        -1.2782e-01, -3.3473e-01, -2.3413e-02,  4.7505e-01,  1.2385e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([ 1.3893e-01, -1.9056e-02, -3.3891e-01,  1.2151e-01,  3.6523e-01,\n",
      "        -1.7391e-01, -2.6735e-02, -5.0335e-02,  2.4743e-01,  2.4531e+00,\n",
      "        -4.2113e-01,  2.3632e-01,  2.0513e-01, -1.0937e-02, -1.1480e-01,\n",
      "        -3.7648e-02, -1.3440e-01,  8.6124e-01, -3.5803e-01,  9.2525e-02,\n",
      "         2.8075e-01,  1.3649e-01,  2.0819e-01,  6.0206e-02, -1.8229e-01,\n",
      "         1.0172e-01, -1.3200e-01, -3.1598e-01,  2.2241e-01, -1.9076e-01,\n",
      "        -1.0884e-02,  1.6988e-01,  8.0345e-03,  1.3337e-01,  1.7724e-01,\n",
      "        -1.9162e-01,  3.3681e-01,  3.0186e-01,  6.1654e-02,  7.6906e-03,\n",
      "        -5.4406e-01,  5.0142e-02, -4.3115e-02, -2.6241e-01,  4.7462e-02,\n",
      "         3.3670e-01, -2.8649e-01, -2.7414e-01,  2.6776e-02, -6.5939e-02,\n",
      "         1.1021e-01,  2.8869e-01,  4.6712e-01,  1.2063e-01,  3.3831e-01,\n",
      "        -3.0427e-04, -1.2116e-01, -1.5900e-01, -1.0514e-01, -3.8560e-02,\n",
      "        -6.2205e-02,  3.5631e-02, -1.7852e-01, -1.3308e-01,  2.6103e-01,\n",
      "        -1.1082e-01, -2.7463e-01,  1.8556e-01,  4.5257e-01,  3.0336e-01,\n",
      "         6.1801e-02,  7.7310e-02,  3.4645e-01,  3.6526e-03,  4.6815e-01,\n",
      "         2.0228e-02, -2.5509e-02, -1.9465e-02, -5.3998e-03,  8.6497e-02,\n",
      "        -5.3099e-02, -8.6426e-02, -4.6913e-01,  6.5788e-02, -1.2720e-01,\n",
      "        -2.4254e-01,  2.4149e-01, -3.7684e-01,  6.5707e-01,  1.4106e-01,\n",
      "        -2.1080e-01,  1.1095e-01,  1.2741e-01, -2.8938e-01, -7.5295e-02,\n",
      "         4.4109e-02,  5.4280e-02, -2.9666e-01,  1.6423e-02,  4.4086e-02,\n",
      "         7.2862e-02, -3.0149e-01,  3.4613e-02,  8.6731e-02,  3.1091e-01,\n",
      "        -3.7156e-01,  1.7382e-01,  2.1996e-01,  6.0312e-02,  1.6767e-01,\n",
      "         3.8469e-02, -6.3231e-01,  3.2331e-01,  1.0421e-01,  2.5080e-01,\n",
      "         2.6267e-01,  1.7882e-01, -2.4515e-01, -1.7214e-01,  2.8319e-01,\n",
      "         6.5598e-02, -4.4386e-02,  3.7064e-02,  4.5018e-02,  3.9367e-01,\n",
      "        -1.3580e-01, -4.6021e-02,  2.3260e-01,  3.4156e-02,  8.4838e-02,\n",
      "         3.8056e-02, -3.4659e-03, -6.8177e-02,  8.2606e-02,  1.5811e-01,\n",
      "        -1.9388e-01,  6.1247e-02, -3.4282e-01, -2.3392e-01,  9.1131e-02,\n",
      "        -2.0934e+00,  1.3815e-01,  1.7597e-01, -3.8005e-01,  2.4690e-01,\n",
      "        -2.2482e-01, -5.9415e-02,  4.2415e-01, -1.3768e-01, -6.4184e-02,\n",
      "        -6.3230e-02,  1.0228e-01,  3.9662e-02, -2.8910e-01,  8.0242e-02,\n",
      "        -4.2854e-01,  1.0474e-01, -1.4070e-01, -5.0420e-02, -1.3486e-01,\n",
      "        -1.3077e-01, -1.1560e-01, -3.7648e-01,  1.4467e-02,  2.8400e-02,\n",
      "        -1.4921e-01,  2.9029e-01, -9.9163e-02,  2.2967e-01,  4.9717e-02,\n",
      "        -2.4345e-01,  2.7722e-02,  7.4055e-02, -4.2579e-01,  1.6724e-01,\n",
      "         6.5469e-02,  7.7571e-02,  2.1529e-01, -7.1330e-02, -5.2742e-02,\n",
      "         1.2080e-01, -5.6503e-02, -3.5852e-01, -8.5641e-02,  5.3364e-01,\n",
      "         1.8189e-01, -1.7887e-01, -2.0100e-01,  4.3655e-01,  1.7912e-01,\n",
      "         2.2238e-02, -4.8491e-02, -8.8347e-02, -1.7544e-01, -1.7052e-01,\n",
      "         2.7578e-01, -2.7629e-01, -5.6030e-02,  3.0416e-01,  4.5115e-01,\n",
      "         6.8440e-02, -1.5926e-01, -2.7197e-01, -2.2628e-02,  3.4567e-01,\n",
      "        -8.8622e-02,  1.9358e-01, -4.1653e-02,  4.1661e-01,  1.0848e-01,\n",
      "        -6.9752e-02, -2.3749e-01, -1.8511e-01,  8.8535e-03, -1.2773e-01,\n",
      "        -8.2802e-02,  4.5794e-02,  3.3554e-01, -3.0644e-01,  4.4171e-01,\n",
      "         1.5975e-01, -1.2756e-02, -2.6972e-01, -7.8977e-02, -4.8264e-02,\n",
      "        -6.5962e-02, -3.0006e-01,  1.0440e-01, -1.2715e-01, -1.4488e-02,\n",
      "        -3.5107e-01, -1.1407e-01,  6.6343e-01,  1.6589e-01,  1.5040e-02,\n",
      "        -8.3249e-03,  1.3835e-02, -1.9600e-01, -3.6130e-02,  2.0337e-01,\n",
      "         1.1822e-01,  1.4760e-01, -3.9074e-02,  2.4619e-01, -9.6280e-02,\n",
      "        -2.2719e-01, -2.2597e-01,  1.9236e-01, -4.1362e-01,  3.7821e-01,\n",
      "         2.8114e-01, -7.8232e-02, -2.4852e-01,  8.4978e-02,  4.5680e-01,\n",
      "         4.7818e-01, -7.2192e-02, -2.2441e-01, -2.5713e-01,  1.1820e-01,\n",
      "         1.8028e-01,  5.1181e-01,  4.0904e-01, -2.4304e-01,  4.9090e-01,\n",
      "        -3.9707e-01, -5.1963e-02,  1.7818e-02,  2.5160e-01,  2.8290e-01,\n",
      "         2.2776e-01, -2.5844e-01,  1.4281e-01, -7.2607e-02,  1.5194e-01,\n",
      "         2.5309e-01,  4.7232e-02,  2.5905e-01, -9.3313e-02,  1.1226e-01,\n",
      "        -1.7449e-01, -3.4896e-01, -2.0145e-01,  1.1628e-01, -1.0769e-01,\n",
      "        -7.8528e-02,  9.3096e-02, -1.6539e-01,  4.3994e-02,  5.9698e-02,\n",
      "        -1.3047e-01,  7.2147e-02,  3.3663e-03, -1.8181e-01,  3.1465e-02,\n",
      "        -3.5351e-02, -4.7912e-03,  9.2753e-02,  2.8618e-01,  1.3646e-01]), tensor([-2.1745e-01,  1.3114e-01, -2.0697e-01, -1.5096e-01, -1.4201e-02,\n",
      "         2.9557e-01,  1.5195e-01,  3.4463e-01, -2.9805e-01,  1.5322e+00,\n",
      "        -1.5180e-01,  6.7626e-02,  1.7394e-01,  1.8759e-01,  3.1848e-01,\n",
      "         2.7023e-01,  8.1128e-02,  1.9199e+00,  5.4141e-02, -7.9649e-01,\n",
      "         1.5135e-01, -8.8425e-02,  1.6010e-01, -4.5368e-01,  5.1205e-03,\n",
      "         3.7180e-02,  7.4731e-01, -7.5222e-03, -3.9668e-01,  8.4160e-02,\n",
      "        -3.3054e-02,  2.2431e-01, -3.0193e-01,  7.6283e-02, -2.6262e-01,\n",
      "        -2.0405e-01, -1.8768e-01,  5.0285e-01,  2.8577e-02, -2.1821e-01,\n",
      "         1.0173e-01, -3.7767e-01,  2.0292e-01, -2.0671e-01,  4.3850e-03,\n",
      "        -1.6705e-01, -2.0502e-01,  2.3374e-01,  4.0937e-01,  2.3284e-01,\n",
      "        -2.4677e-01,  2.5387e-01,  5.0731e-01, -3.7701e-02, -1.6737e-01,\n",
      "         4.6965e-01,  1.5604e-01,  2.9975e-02,  7.4534e-02, -3.5609e-01,\n",
      "        -4.2527e-01, -5.1183e-01,  1.5270e-01,  3.8583e-01, -9.1424e-02,\n",
      "         1.1336e-01, -9.0852e-02,  3.8450e-01,  1.9425e-01,  3.6672e-01,\n",
      "        -3.6339e-01, -1.1771e-01,  1.5189e-01,  4.5433e-02,  2.2344e-01,\n",
      "        -3.6473e-01, -8.2859e-02, -3.7223e-01, -7.6625e-01, -8.0180e-02,\n",
      "         2.2757e-01, -1.1509e-01,  6.8108e-02,  1.6408e-01, -1.3072e-01,\n",
      "        -2.4388e-01,  1.7242e-02,  5.3826e-01,  6.1014e-01,  4.0197e-01,\n",
      "        -1.4247e-01,  3.6139e-01, -4.1070e-01,  4.4337e-01,  6.1432e-01,\n",
      "        -1.2497e-01, -2.9634e-01, -1.4156e-01,  9.5091e-02, -1.7901e-01,\n",
      "        -1.9862e-02,  6.1664e-02,  4.0566e-01,  3.8947e-02,  1.0405e-01,\n",
      "        -1.0102e+00, -6.0302e-02,  1.8685e-02, -2.6599e-01,  5.7303e-02,\n",
      "        -3.2375e-01, -7.5163e-02,  6.5763e-01,  2.9079e-01,  3.8475e-01,\n",
      "        -2.6434e-01, -5.9122e-01, -4.1221e-01,  3.0553e-01, -1.2933e-01,\n",
      "        -1.3971e-01, -3.9343e-01,  3.6891e-02,  6.5859e-01,  1.6040e-01,\n",
      "        -3.1997e-01, -6.1391e-01, -5.5902e-01, -2.2469e-02, -4.5389e-01,\n",
      "         3.4886e-02, -2.6915e-02, -4.7474e-01, -3.4566e-02,  8.7964e-02,\n",
      "         3.7504e-01, -1.4416e-01, -9.6533e-02,  3.4589e-02, -1.4342e-02,\n",
      "        -6.1180e-01,  4.0466e-01, -2.4954e-01,  3.0977e-02,  2.4368e-02,\n",
      "        -2.0349e-01, -1.9368e-01,  2.5362e-01,  4.1816e-01,  2.5944e-01,\n",
      "         5.7609e-01, -2.4984e-01, -5.0079e-02,  5.3789e-02, -1.7335e-01,\n",
      "         2.3727e-01, -1.7271e-01,  8.3314e-03,  1.6348e-02, -1.8197e-01,\n",
      "        -4.0808e-01,  6.0396e-02, -2.3573e-01,  2.0875e-01,  2.5584e-01,\n",
      "         4.7309e-03, -1.5659e-01, -5.0804e-03,  3.4238e-01, -6.8916e-02,\n",
      "        -6.7008e-01, -1.8267e-01,  3.7005e-01, -6.1534e-02,  1.6587e-02,\n",
      "         2.8747e-01, -1.5200e-01,  1.7665e-01,  3.6557e-01,  1.3264e-01,\n",
      "         1.3481e-02, -1.8607e-01, -4.9240e-02,  2.2912e-01,  7.9026e-02,\n",
      "        -1.1507e-01, -2.4860e-01,  1.1677e-02, -2.2476e-02,  3.3939e-01,\n",
      "        -3.0429e-01, -3.5450e-02, -6.4396e-02,  2.3031e-01, -4.5288e-01,\n",
      "        -2.6630e-01,  1.0016e-01, -4.4333e-01, -1.2060e-01,  2.7969e-01,\n",
      "        -9.6379e-03,  5.4800e-02, -2.0265e-01,  1.3010e-01, -1.5520e-02,\n",
      "         4.1225e-01,  1.3123e-01,  3.9273e-01, -9.1365e-01,  4.7533e-01,\n",
      "         1.3277e-01,  4.3498e-01, -1.5617e-01, -5.1415e-01,  1.3926e-01,\n",
      "         7.8042e-01, -9.5738e-02, -4.1756e-03, -3.2609e-01, -1.4075e-01,\n",
      "         2.5397e-01,  1.6173e-01, -1.5558e-01,  4.5077e-01,  1.9911e-01,\n",
      "         3.7115e-03, -3.3901e-01,  6.3926e-02, -3.4187e-02,  2.1881e-01,\n",
      "        -4.0520e-01, -7.8843e-02, -3.2853e-01,  3.8944e-01,  4.6295e-04,\n",
      "         2.2877e-01, -2.0082e-01,  1.1240e-04,  2.2979e-01, -1.8071e-02,\n",
      "        -1.0946e-01, -1.4996e-02, -3.1341e-01, -1.4965e-01,  8.9754e-02,\n",
      "        -1.2396e-01, -2.7436e-01,  5.6516e-01,  4.7040e-01, -5.1018e-02,\n",
      "         2.5609e-01,  2.0187e-01, -2.0582e-01, -3.2338e-01, -1.5851e-01,\n",
      "         1.6477e-02,  1.1412e-01, -7.8148e-02, -1.0547e-01, -4.3039e-02,\n",
      "         4.1810e-01,  3.9019e-02,  3.0853e-02, -2.4565e-02, -1.8470e-01,\n",
      "         5.8593e-03,  6.8271e-01, -3.9504e-02,  5.8849e-01, -4.7760e-02,\n",
      "        -5.0115e-01,  1.6058e-01,  2.0844e-02, -3.7717e-01, -2.0841e-01,\n",
      "         4.4230e-01,  2.5077e-01,  1.9255e-01, -3.6256e-01,  3.5549e-01,\n",
      "         6.5131e-01,  1.8835e-01,  1.4914e-01, -4.4921e-01, -4.7373e-01,\n",
      "        -3.7410e-01, -2.3440e-01,  5.8526e-01, -4.2449e-01, -5.2219e-01,\n",
      "        -8.2359e-01,  3.2194e-01, -9.9301e-02,  4.1343e-02, -2.8033e-02,\n",
      "        -3.9585e-01, -2.3733e-01,  3.8942e-01,  2.2295e-01,  3.2208e-01])], [tensor([-2.1375e-01, -4.3317e-01, -2.1541e-01,  1.0495e-02,  6.1001e-02,\n",
      "        -1.9225e-01,  3.8801e-01,  2.4068e-01,  4.5931e-02,  1.4974e+00,\n",
      "        -3.5434e-01,  6.7997e-02,  4.6448e-01, -1.6813e-01, -1.8319e-01,\n",
      "         5.1620e-01, -2.6643e-01, -1.4191e-01,  3.2636e-02,  9.6928e-02,\n",
      "         1.2457e-01,  1.8834e-01, -3.6294e-03,  2.7656e-01, -1.6885e-01,\n",
      "        -1.0793e-01,  2.6790e-01, -9.0576e-02, -4.1713e-02,  1.8329e-01,\n",
      "        -5.3854e-01, -1.6618e-01, -4.9394e-01,  3.0560e-01,  1.0706e-01,\n",
      "        -4.2486e-01, -2.7043e-01,  1.4972e-02,  2.3322e-01,  3.9917e-01,\n",
      "         1.3801e-01, -6.1464e-01, -3.8771e-02, -6.3980e-01, -4.0879e-01,\n",
      "        -8.8403e-02,  4.7192e-01,  6.6210e-01,  1.0021e-02, -2.8487e-01,\n",
      "         3.7833e-01,  2.1082e-01, -8.7186e-02, -5.6171e-02, -9.9881e-02,\n",
      "         2.0284e-01, -3.4095e-01, -8.7585e-04, -5.8599e-01, -1.1326e-01,\n",
      "        -4.4644e-01,  1.8008e-01, -1.7198e-01, -1.8428e-01, -8.9921e-02,\n",
      "         2.5368e-01,  2.0533e-01, -4.7211e-01,  3.8157e-01,  3.5150e-01,\n",
      "        -9.3468e-03,  6.8211e-01, -6.7230e-02, -9.9754e-02,  5.5715e-02,\n",
      "         3.9644e-01,  3.2007e-01, -2.0044e-02, -3.2665e-01, -9.8502e-02,\n",
      "        -3.7882e-01, -3.5445e-02, -5.1318e-01, -2.1438e-01, -1.6453e-01,\n",
      "        -2.8031e-01,  1.2282e+00, -6.0194e-01,  7.8507e-01,  9.9473e-02,\n",
      "        -1.5043e-01, -2.0889e-01,  5.0976e-02,  3.3214e-02, -1.1086e-01,\n",
      "         1.8478e-01, -9.2336e-02,  1.8798e-02, -4.6559e-01, -8.0631e-02,\n",
      "        -3.9988e-02, -2.7017e-01,  8.1497e-02,  3.7614e-01,  2.1293e-01,\n",
      "        -9.3592e-01,  4.4987e-01, -9.3417e-02, -2.3087e-01,  3.5589e-01,\n",
      "         3.1907e-01, -2.5546e-02,  1.4818e-01,  1.4713e-01,  3.0935e-01,\n",
      "        -2.1505e-01, -3.8848e-01, -8.5840e-01, -1.6958e-01, -1.0437e-01,\n",
      "         1.4205e-01, -3.3164e-01,  1.9357e-01,  9.2382e-03,  1.2119e-01,\n",
      "         2.1103e-02,  2.8477e-01, -2.4157e-02,  1.1284e-01,  2.4834e-01,\n",
      "         7.1229e-01,  3.6160e-01,  6.5830e-03, -2.0776e-01, -5.1394e-01,\n",
      "         1.9086e-01, -1.0913e-01, -1.6820e-01,  1.6154e-01, -8.5045e-02,\n",
      "        -1.7307e+00,  9.2403e-02, -6.0962e-01, -3.1797e-01,  2.5866e-01,\n",
      "        -3.9801e-01,  9.1096e-02,  3.9571e-01, -2.7534e-02, -4.8091e-02,\n",
      "        -1.9069e-02,  1.4950e-01,  2.6089e-01,  1.3398e-01,  4.3134e-01,\n",
      "        -2.3609e-02,  3.0801e-01, -6.1032e-01,  2.2342e-01, -1.8652e-02,\n",
      "        -1.8159e-01, -1.2116e-01, -1.1409e-01,  4.6467e-01, -3.4142e-01,\n",
      "         2.5740e-01, -1.4225e-01, -3.7142e-01, -2.8859e-01,  4.7596e-01,\n",
      "        -2.1978e-01, -5.4629e-01,  7.4465e-01, -2.9948e-02,  5.8623e-01,\n",
      "         5.5271e-01, -3.3035e-01,  3.3537e-01, -4.1431e-01, -6.7753e-02,\n",
      "         5.0335e-02,  8.9296e-02,  1.2207e-02,  5.5041e-02, -1.9908e-02,\n",
      "        -2.2893e-01, -3.2889e-01, -1.0928e-01,  7.0159e-02,  3.2943e-01,\n",
      "         2.1423e-01, -3.6913e-01, -2.0333e-01, -3.3156e-01,  2.3316e-01,\n",
      "        -2.6697e-01,  2.2797e-01, -2.3447e-01,  1.7602e-02,  1.6081e-01,\n",
      "        -2.0085e-01, -1.8288e-03, -5.3669e-01, -4.5682e-01,  1.5619e-01,\n",
      "        -2.4415e-01,  2.6879e-01,  1.0841e-01,  5.1525e-01, -2.4101e-01,\n",
      "        -5.3683e-02, -3.6503e-01, -1.9920e-01,  1.0243e-01,  5.7760e-02,\n",
      "         3.2624e-01, -1.3829e-01,  3.3479e-01, -1.6005e-01,  1.9989e-01,\n",
      "         8.2842e-03, -3.2592e-01,  1.2745e-01,  2.7000e-02, -1.3297e-02,\n",
      "         2.4671e-01, -4.2196e-01, -3.7080e-02, -4.7705e-01, -2.9745e-01,\n",
      "         6.1411e-02, -7.2499e-02,  3.9115e-02,  6.8150e-02, -2.2590e-01,\n",
      "        -1.7549e-01, -1.7949e-02, -2.5895e-01,  2.8838e-01,  3.2258e-01,\n",
      "        -7.6891e-02, -3.3711e-01, -2.7017e-01,  1.9005e-01, -1.6135e-02,\n",
      "        -5.4992e-01,  3.5767e-01, -1.1754e-01, -3.1369e-01,  5.4489e-01,\n",
      "        -4.1917e-02,  1.9684e-01, -3.0797e-02, -1.9377e-01,  1.4768e-01,\n",
      "         2.0577e-01, -1.0369e-01, -2.0868e-01, -9.9568e-02,  4.8858e-01,\n",
      "        -2.9656e-01, -2.8555e-01, -1.0074e-01, -2.4314e-01, -3.1418e-01,\n",
      "         9.7955e-02,  7.1188e-02,  3.9479e-01, -5.0672e-01,  8.7479e-02,\n",
      "         1.4447e-01, -2.0827e-01, -7.5078e-03,  3.1978e-01, -1.7285e-01,\n",
      "        -1.2892e-01,  1.4492e-01,  9.4306e-02,  2.3283e-02,  3.7209e-01,\n",
      "         2.4985e-02,  7.8568e-02,  5.8662e-01, -1.2783e-01, -5.5413e-01,\n",
      "         3.8879e-02,  2.7775e-01,  1.1299e-01, -3.7738e-01,  5.3210e-01,\n",
      "         1.5656e-01, -4.9745e-02, -7.6334e-01, -1.4821e-01,  1.8838e-01,\n",
      "        -4.8609e-02,  1.8413e-01,  1.8890e-01,  1.1724e-01, -9.9626e-02]), tensor([-2.6554e-01,  3.3531e-01,  2.1860e-01, -3.0100e-01, -5.5470e-02,\n",
      "        -2.4236e-01,  1.7236e-01, -1.6334e-01, -1.0900e-01,  1.2671e+00,\n",
      "        -3.3449e-01,  2.0911e-01, -1.0205e-02,  2.7530e-01, -1.8455e-01,\n",
      "         1.7111e-02, -3.7401e-02,  1.3706e+00, -1.7785e-01, -1.5351e-01,\n",
      "         9.9583e-02, -3.1839e-01,  7.7433e-02,  4.9495e-02, -5.3451e-02,\n",
      "        -3.4892e-02,  1.6875e-01,  2.8741e-02,  2.0523e-01, -1.0273e-01,\n",
      "         1.2935e-01,  3.5585e-01,  4.0188e-03,  7.9254e-02,  2.4425e-01,\n",
      "         2.7667e-01,  8.0892e-02,  3.0308e-01, -8.5076e-02,  1.0352e-03,\n",
      "         1.2730e-01,  1.1868e-01,  2.0868e-01, -1.4019e-01,  2.4865e-01,\n",
      "         3.1383e-01, -5.5654e-01,  8.6916e-02,  4.0284e-01,  3.6714e-02,\n",
      "         1.4341e-01,  3.0447e-01,  1.7679e-01, -2.0325e-01, -8.6745e-02,\n",
      "        -5.9375e-02,  1.0775e-01,  2.6919e-01,  3.6491e-02,  1.2037e-01,\n",
      "        -1.8979e-01,  1.9414e-01, -1.8552e-02, -4.5914e-01,  1.2681e-01,\n",
      "        -5.4521e-02, -2.2054e-01,  1.1147e-01,  8.4313e-03,  2.0667e-01,\n",
      "         3.1060e-01, -9.2659e-02,  3.1766e-01,  1.6209e-01,  4.5862e-01,\n",
      "         1.1182e-04, -8.8286e-02, -3.7030e-01,  5.3689e-02,  7.9508e-01,\n",
      "        -2.4994e-01,  4.3256e-01,  8.8471e-02,  4.1864e-01,  1.1771e-01,\n",
      "         4.6896e-02,  5.3549e-01, -8.6838e-01,  1.5809e-01,  4.9917e-01,\n",
      "         2.6179e-01,  5.2140e-01,  3.5645e-01,  1.4372e-01, -3.6987e-01,\n",
      "        -1.4000e-01, -6.2828e-01, -3.1675e-01, -1.9247e-02, -7.4357e-02,\n",
      "         2.0714e-01, -1.5843e-01, -2.9743e-01, -2.1549e-01,  8.0076e-02,\n",
      "         1.1832e+00,  4.8673e-01,  1.4721e-01,  1.2630e-01,  2.6231e-02,\n",
      "         3.6053e-01, -6.8196e-01,  5.5184e-01,  6.1528e-02,  3.3425e-03,\n",
      "         4.8489e-02,  1.3825e-01, -1.5156e-01, -6.9840e-02, -9.9947e-02,\n",
      "         2.3865e-01,  1.3611e-01,  2.6055e-01, -4.4013e-02,  2.5868e-02,\n",
      "        -2.7526e-01, -8.4552e-02,  4.6746e-02,  8.6153e-02, -1.8508e-01,\n",
      "        -9.3114e-02, -5.9787e-01, -2.5463e-01,  8.2126e-02, -1.4104e-01,\n",
      "         2.4358e-01, -2.4225e-01,  2.9690e-01, -1.6202e-01,  6.0339e-01,\n",
      "        -2.0813e+00,  5.5412e-01,  7.6675e-01, -1.9920e-01,  3.2305e-01,\n",
      "        -1.7755e-01, -1.6761e-01,  3.8451e-01, -3.4128e-01,  3.8295e-02,\n",
      "        -2.0701e-01,  8.7338e-01, -2.2934e-01, -1.4054e-01,  4.9033e-01,\n",
      "        -3.6845e-01,  2.6926e-01, -4.0554e-01,  3.4307e-01, -1.7314e-01,\n",
      "         1.8955e-01, -1.5305e-01, -7.7203e-02, -3.4467e-01,  9.9602e-02,\n",
      "         2.4910e-01, -1.5662e-01, -1.4328e-01,  3.2020e-02,  5.7149e-01,\n",
      "        -9.7738e-03, -8.4682e-02, -3.1799e-01,  1.0101e-01, -1.6099e-01,\n",
      "         6.6370e-02,  2.5543e-01,  1.5427e-01, -3.7382e-01, -1.0029e-01,\n",
      "        -2.4851e-01, -9.9441e-02, -1.6696e-01, -2.5520e-01, -2.6483e-01,\n",
      "        -5.4984e-01, -4.7636e-01, -3.0128e-01,  1.9842e-01,  6.2700e-02,\n",
      "        -1.1024e-01, -2.1813e-01,  3.3200e-01,  2.7030e-01,  2.4467e-02,\n",
      "         2.2990e-01,  2.9060e-03, -3.2990e-01,  7.4210e-01,  1.7305e-01,\n",
      "        -3.4286e-01,  1.0717e-01,  2.5081e-01, -5.1652e-02,  2.1430e-01,\n",
      "         5.6340e-02, -5.5078e-02,  2.3547e-01,  9.8905e-02, -4.9870e-01,\n",
      "        -4.0825e-02, -4.3741e-01, -1.5599e-01,  1.2596e-01, -5.2259e-03,\n",
      "         4.2925e-01,  3.7281e-01, -5.4302e-02, -5.4095e-01,  3.6250e-01,\n",
      "        -3.0536e-01,  1.4411e-01, -2.7903e-01,  4.5630e-02,  2.7276e-01,\n",
      "        -4.9394e-02, -3.0396e-01,  5.3267e-01, -6.6274e-03, -1.0888e-01,\n",
      "         1.2579e-01, -3.4876e-01, -1.7502e-01, -2.6133e-02,  2.5876e-02,\n",
      "         4.6289e-01, -1.1516e-01, -1.9461e-01, -1.7781e-01, -1.8374e-01,\n",
      "         2.0147e-01, -2.1280e-01, -1.5289e-01,  1.7298e-01,  2.2503e-01,\n",
      "        -9.5777e-02, -7.4261e-02,  5.2321e-02,  1.6853e-01,  5.8565e-01,\n",
      "         2.7345e-02,  1.2770e-01, -4.0630e-01, -1.3299e-01, -2.1093e-01,\n",
      "         5.9611e-01,  1.7409e-01,  1.2483e-01, -1.5014e-01, -4.6455e-02,\n",
      "        -1.0728e-02, -1.4175e-01, -3.8314e-01,  4.1410e-02, -2.5619e-01,\n",
      "        -4.2536e-02,  3.5050e-01, -2.4369e-01,  5.3533e-01,  2.5372e-01,\n",
      "        -5.9328e-01, -1.6591e-02, -7.2031e-01,  9.2813e-02, -4.5688e-01,\n",
      "        -1.0833e-01, -3.8946e-02, -3.5834e-02,  2.0215e-01,  4.0055e-01,\n",
      "         3.7802e-01, -1.2920e-01, -9.1766e-03, -1.0482e-02,  4.3290e-02,\n",
      "         1.3123e-01,  3.3219e-01,  1.5346e-01,  3.5997e-02, -8.3019e-03,\n",
      "        -3.8645e-01, -1.5056e-01, -3.2827e-02, -1.0529e-01,  2.8397e-01,\n",
      "        -2.5500e-01,  1.5195e-01, -1.7859e-01, -6.2878e-02,  1.6232e-01])], [tensor([ 2.4498e-01,  1.7973e-01, -4.9191e-01,  1.2429e-01,  5.4470e-01,\n",
      "        -1.1258e-01, -2.2837e-01, -4.2478e-02,  1.3143e-01,  2.6448e+00,\n",
      "        -2.5930e-01,  3.0903e-01, -4.6845e-02,  5.8319e-02, -1.9684e-01,\n",
      "        -2.2155e-02, -2.2821e-01,  1.1278e+00, -2.5243e-01,  1.1636e-01,\n",
      "         7.5598e-02,  4.8716e-02,  1.8727e-01, -3.2490e-01,  2.8231e-02,\n",
      "        -3.0675e-01,  5.8118e-03, -2.4703e-01,  3.4676e-02, -1.4749e-01,\n",
      "         9.1599e-02,  2.9625e-01,  7.5177e-02,  2.5304e-01,  8.6464e-02,\n",
      "         3.9885e-03, -1.5262e-01,  9.2531e-02, -2.7002e-01, -1.5531e-01,\n",
      "        -2.3120e-01,  2.3151e-01, -4.7052e-01, -2.0252e-01,  1.5311e-01,\n",
      "         2.8793e-01, -3.8947e-01, -2.2848e-01, -2.8524e-01, -7.7195e-02,\n",
      "         1.2883e-01,  3.6220e-01, -1.5384e-01,  1.4605e-01,  2.1578e-01,\n",
      "        -9.9416e-02,  1.2956e-01, -1.5691e-01, -8.9919e-02, -3.8154e-01,\n",
      "        -2.6094e-01, -5.6228e-02,  1.5524e-01,  3.6326e-01,  3.9776e-01,\n",
      "        -1.5396e-01, -2.1966e-01, -3.2676e-03,  1.9904e-01,  1.7114e-01,\n",
      "         2.9464e-02,  9.9572e-02,  5.3585e-01,  6.4559e-02, -8.0625e-02,\n",
      "        -1.2405e-01,  3.2002e-01, -2.9716e-01, -2.0656e-01, -5.6908e-02,\n",
      "        -1.7928e-01,  3.0715e-01,  9.1507e-02,  2.8014e-01, -7.8898e-02,\n",
      "         2.4502e-01,  3.7296e-01, -1.9800e-01,  4.6024e-01,  1.6299e-02,\n",
      "        -3.1077e-02,  8.8482e-02,  1.1320e-01,  2.8058e-01,  1.8246e-01,\n",
      "        -2.0707e-01, -5.1813e-01, -3.5000e-01,  1.5409e-01, -2.3215e-01,\n",
      "        -2.1623e-01, -1.7890e-01,  2.6002e-01,  6.2191e-02,  4.0326e-01,\n",
      "        -5.8886e-01,  1.3819e-02,  3.4795e-02, -2.1756e-01,  3.8578e-01,\n",
      "        -1.5722e-01, -1.2098e-01,  4.8606e-02,  1.3307e-01,  4.1042e-01,\n",
      "         2.6994e-01,  5.8005e-02, -7.7229e-02, -2.8127e-01, -2.9094e-02,\n",
      "         1.7076e-01, -2.3250e-02,  3.2220e-01,  3.2751e-01,  6.7714e-02,\n",
      "         1.4124e-01, -2.7823e-01, -1.7043e-01, -1.5698e-01, -6.3559e-02,\n",
      "        -1.3311e-01, -2.6129e-01, -9.6243e-02, -1.1270e-01,  7.5621e-02,\n",
      "        -4.2429e-02,  1.8267e-02,  2.6391e-02, -1.2504e-01,  6.7258e-02,\n",
      "        -1.7528e+00,  1.6933e-01, -3.1463e-01,  6.4982e-02,  1.8901e-01,\n",
      "        -1.8856e-01, -1.5670e-01, -1.2425e-01, -4.1318e-02,  3.4542e-02,\n",
      "        -3.8035e-01, -9.9705e-02,  1.4546e-01, -2.3221e-01, -1.7633e-01,\n",
      "         1.1423e-01, -6.1160e-02, -7.3944e-02, -1.4333e-01,  1.6908e-01,\n",
      "        -2.2675e-02,  9.6898e-02, -1.3966e-01,  1.1116e-01,  5.3619e-02,\n",
      "        -3.7228e-01,  1.0494e-01,  9.0221e-02,  3.6803e-01,  1.4964e-01,\n",
      "        -9.8395e-02, -3.1496e-01, -1.7175e-01, -4.3477e-01,  9.1846e-02,\n",
      "         8.3158e-02, -3.7460e-01, -1.1624e-01,  6.7491e-02, -1.0670e-01,\n",
      "         2.3328e-01, -2.1242e-01, -1.7353e-01, -2.2342e-01,  7.1008e-02,\n",
      "         1.6430e-01, -1.6975e-01, -5.2061e-01,  1.9495e-01,  5.8516e-02,\n",
      "        -8.0125e-02, -2.0989e-01,  2.1990e-01, -7.0059e-02,  2.7256e-01,\n",
      "         2.7535e-01,  1.5762e-01, -1.5093e-01,  4.5139e-02,  7.3498e-01,\n",
      "        -3.3560e-01,  2.8694e-01, -6.3161e-02, -7.8611e-02,  1.3628e-01,\n",
      "         3.8350e-01,  1.2466e-01, -2.4877e-01, -1.0306e-01, -1.5148e-01,\n",
      "        -5.8404e-02, -2.4681e-01,  1.3591e-01, -1.3578e-01,  1.5568e-01,\n",
      "         2.0310e-01, -1.9195e-01,  2.1136e-01, -3.1806e-01,  1.1897e-01,\n",
      "        -1.1872e-01, -1.9652e-01, -1.9575e-01, -2.3096e-02,  4.6078e-01,\n",
      "        -4.1096e-01, -2.8599e-01,  1.2833e-01,  2.0667e-01, -2.0054e-01,\n",
      "        -4.2896e-01, -1.1261e-02,  4.4412e-01,  2.4096e-01,  3.8138e-02,\n",
      "        -2.3037e-01,  3.0130e-01, -2.0100e-01,  8.2807e-03, -6.2039e-02,\n",
      "         4.8129e-01,  1.6556e-01,  8.4501e-02,  4.6395e-01, -1.0592e-01,\n",
      "        -2.5434e-01, -2.4599e-01, -6.6526e-02, -6.6260e-01,  2.7794e-01,\n",
      "        -2.2119e-01, -1.4337e-01,  1.2034e-01, -1.0214e-01, -2.0465e-01,\n",
      "         5.1383e-01,  3.2635e-01,  7.7044e-02,  1.1295e-01, -1.1206e-03,\n",
      "        -1.9568e-01,  8.8547e-03,  4.6611e-01, -4.1398e-01,  3.6870e-01,\n",
      "         2.0834e-02, -9.7065e-02, -1.7683e-01,  6.9659e-01,  8.6765e-02,\n",
      "         2.7708e-02, -1.4932e-01, -1.3559e-01, -3.8356e-01,  3.0686e-02,\n",
      "        -1.2247e-01,  4.5502e-02, -6.3452e-02,  2.4374e-02,  1.1859e-01,\n",
      "         1.4230e-01, -5.8382e-02, -2.9158e-01,  9.9985e-02, -1.3216e-01,\n",
      "         6.5382e-02, -1.4264e-01, -1.3792e-01,  4.1462e-01, -1.5035e-01,\n",
      "         4.9602e-03,  4.8956e-02,  3.8412e-03, -3.2283e-01,  2.7687e-01,\n",
      "        -2.6963e-01, -1.1004e-01, -1.5867e-01,  1.7981e-01,  1.9019e-01]), tensor([-0.0828,  0.6720, -0.1499, -0.0650,  0.0565,  0.4023,  0.0028, -0.3311,\n",
      "        -0.3069,  2.0817,  0.0318,  0.0136,  0.3027,  0.0071, -0.5819, -0.2774,\n",
      "        -0.0623,  1.1451, -0.2423,  0.1235, -0.1224,  0.3315, -0.0062, -0.3054,\n",
      "        -0.1306, -0.0546,  0.0371, -0.0706,  0.5893, -0.3038,  0.2898, -0.1465,\n",
      "        -0.2705,  0.3716,  0.3203, -0.2912,  0.0052, -0.1321, -0.0527,  0.0873,\n",
      "        -0.2667, -0.1690,  0.0152, -0.0084, -0.1487,  0.2341, -0.2072, -0.0914,\n",
      "         0.4008, -0.1722,  0.1814,  0.3759, -0.2868,  0.3729, -0.1619,  0.1801,\n",
      "         0.3032, -0.1322,  0.1835,  0.0958,  0.0949,  0.0083,  0.1176,  0.3405,\n",
      "         0.0368, -0.2908,  0.0583, -0.0278,  0.0829,  0.1862, -0.0315,  0.2799,\n",
      "        -0.0744, -0.1376, -0.2187,  0.1814,  0.0409, -0.1130,  0.2411,  0.3657,\n",
      "        -0.2752, -0.0568,  0.3487,  0.0119,  0.1452, -0.7139,  0.4850,  0.1481,\n",
      "         0.6229,  0.2060,  0.5838, -0.1344,  0.4021,  0.1831,  0.2802, -0.4235,\n",
      "        -0.2563,  0.1771, -0.5410,  0.1660, -0.0361,  0.0850, -0.6499,  0.0755,\n",
      "        -0.2883,  0.4063, -0.2802,  0.0941,  0.3241,  0.2844, -0.2634,  0.1155,\n",
      "         0.0719, -0.4721, -0.1837, -0.3471,  0.2996, -0.6651,  0.0025, -0.4233,\n",
      "         0.2751,  0.3601,  0.1631,  0.2396, -0.0592,  0.3261,  0.2056,  0.0387,\n",
      "        -0.0458,  0.0898,  0.4315, -0.1595,  0.0853, -0.2657, -0.1500,  0.0843,\n",
      "        -0.1671, -0.4300,  0.0608,  0.1312, -0.2411,  0.6655,  0.4453, -0.1802,\n",
      "        -0.1392,  0.5625,  0.2146, -0.4644, -0.0122,  0.0300, -0.0511, -0.2014,\n",
      "         0.8079,  0.4738, -0.0576,  0.4622,  0.1608, -0.2095, -0.0545,  0.1557,\n",
      "        -0.1371,  0.1297, -0.0119, -0.0034, -0.1359, -0.0807,  0.2007,  0.0541,\n",
      "         0.0468,  0.0595,  0.0463,  0.1775, -0.3109,  0.2812, -0.2436,  0.0853,\n",
      "        -0.2101, -0.1947,  0.0027, -0.4634,  0.1479, -0.3152, -0.0659,  0.0361,\n",
      "         0.4290, -0.3376,  0.1643,  0.3257, -0.0504, -0.0543,  0.2407,  0.4192,\n",
      "         0.1301, -0.1717, -0.3781, -0.2309, -0.0195, -0.2929, -0.3082,  0.3030,\n",
      "        -0.2266,  0.0816, -0.1852, -0.2141,  0.4062, -0.2897,  0.0742, -0.1779,\n",
      "         0.2860, -0.0396, -0.2339, -0.3605, -0.0675, -0.0911,  0.2344, -0.0041,\n",
      "         0.0032,  0.0072,  0.0087,  0.2161,  0.0499,  0.3558,  0.1375,  0.0734,\n",
      "         0.1417,  0.2412, -0.0133,  0.1561,  0.0834,  0.0881, -0.0194,  0.4379,\n",
      "         0.0840,  0.4531, -0.5049, -0.1086, -0.2527, -0.1825,  0.2044,  0.1332,\n",
      "         0.1294,  0.0506, -0.1561, -0.3954,  0.1254,  0.2488, -0.1927, -0.3185,\n",
      "        -0.1272,  0.4341,  0.3118, -0.0041, -0.2094, -0.0800,  0.1161, -0.0508,\n",
      "         0.0153, -0.2803, -0.1249,  0.2359,  0.2339, -0.1402,  0.0285,  0.5692,\n",
      "        -0.1649, -0.0364,  0.0101, -0.1711, -0.0426,  0.0450, -0.4393, -0.2614,\n",
      "         0.3009, -0.0608, -0.4531, -0.1908, -0.2029,  0.2769, -0.0609,  0.1194,\n",
      "         0.6221, -0.1934,  0.4785, -0.3011,  0.0594,  0.0749,  0.0611, -0.4662,\n",
      "         0.4005, -0.1910, -0.1433,  0.0183, -0.1864,  0.2071, -0.3560,  0.0534,\n",
      "        -0.0508, -0.1918, -0.3785, -0.0659]), tensor([-1.2486e-01,  6.9180e-02, -3.1364e-01, -3.1354e-01,  1.4388e-01,\n",
      "         1.6573e-01, -4.0073e-02, -3.4590e-01, -1.7483e-01,  2.6147e+00,\n",
      "         9.1120e-03,  1.8054e-02,  8.3494e-02, -9.3186e-02, -1.0852e-01,\n",
      "        -1.4856e-01,  1.4402e-01,  1.1995e+00, -5.1814e-01, -4.3844e-02,\n",
      "        -2.8039e-01,  1.3527e-01, -3.6054e-02, -1.3734e-01,  3.1807e-02,\n",
      "         1.7668e-02,  4.7540e-02, -3.0738e-02,  1.7169e-01, -1.0349e-01,\n",
      "         1.0784e-01,  1.9757e-02,  6.9675e-02, -1.5200e-01, -1.9508e-01,\n",
      "        -1.7867e-01,  1.1583e-01,  4.7459e-02, -4.5048e-02, -1.0148e-02,\n",
      "        -6.7003e-02,  3.0717e-02, -9.5259e-02, -2.2538e-02,  8.2868e-02,\n",
      "         1.9983e-01, -1.2923e-01, -1.3680e-01,  2.9010e-02,  1.8272e-01,\n",
      "         2.2101e-02,  1.5804e-01,  3.7986e-02,  3.1765e-02, -3.0443e-03,\n",
      "         3.1779e-02, -9.1168e-02,  3.6951e-02,  4.4161e-02,  1.0407e-01,\n",
      "         1.5687e-02, -9.7470e-02,  4.2405e-02,  2.6701e-01, -1.0596e-01,\n",
      "        -1.4289e-01, -6.7763e-02,  1.7992e-01,  2.6175e-01,  4.5349e-02,\n",
      "         2.5674e-01,  1.2484e-01,  3.6875e-01,  7.5486e-02, -1.4867e-01,\n",
      "         8.2897e-03,  8.9685e-02, -1.3242e-01, -2.4698e-01,  2.3017e-01,\n",
      "        -2.4372e-03,  1.8298e-01, -2.2386e-01,  1.7260e-01, -2.6223e-02,\n",
      "        -3.0136e-01, -1.8803e-01,  1.0426e-01, -4.1197e-02,  6.9884e-02,\n",
      "        -3.3139e-03, -1.4249e-01,  4.4817e-02,  3.6930e-01,  5.2759e-01,\n",
      "        -1.4461e-01,  2.2260e-01, -2.1296e-01, -2.1575e-01, -2.1324e-02,\n",
      "        -2.3094e-01, -9.1427e-02, -1.3952e-01, -6.5416e-02,  9.9365e-02,\n",
      "        -1.1914e+00, -1.0889e-01, -3.6120e-01, -6.4289e-02, -1.4312e-01,\n",
      "         9.1272e-03, -1.6777e-01,  2.1744e-01, -4.6958e-02,  7.1629e-03,\n",
      "        -8.1238e-03,  4.3175e-02, -5.4813e-02, -1.1981e-01,  4.2927e-02,\n",
      "         2.3405e-01,  1.0804e-01,  1.9480e-01, -5.6464e-02,  1.2108e-01,\n",
      "         1.0770e-01, -9.7876e-02, -2.4924e-01,  2.4288e-01, -2.4311e-02,\n",
      "        -8.8623e-02, -3.1197e-01, -1.8214e-01,  2.1236e-01,  2.4771e-01,\n",
      "         3.9045e-01,  1.9372e-01, -4.0742e-01,  1.3977e-01,  1.5621e-01,\n",
      "        -1.2266e+00,  2.0881e-01,  4.3454e-01, -1.0045e-01, -1.3093e-01,\n",
      "        -2.2994e-01, -2.5303e-01, -5.7255e-02,  4.4188e-02,  3.9772e-03,\n",
      "        -2.1284e-01,  2.0268e-01,  1.5135e-01, -8.1819e-03, -1.3508e-01,\n",
      "        -6.2223e-02,  1.2250e-01, -7.0757e-02, -5.4248e-02, -4.5870e-01,\n",
      "         2.6266e-01,  1.4630e-01,  4.0067e-02, -1.7087e-01, -2.3487e-02,\n",
      "        -2.6435e-01,  5.8678e-02, -7.8438e-02,  3.0261e-01, -1.4065e-01,\n",
      "        -5.5911e-02,  1.8330e-01, -1.0979e-01, -7.1047e-02, -1.7407e-01,\n",
      "        -1.4674e-01, -2.8062e-01,  1.3984e-01,  1.1339e-01,  1.0495e-01,\n",
      "        -1.4357e-01, -1.2663e-01, -3.4565e-01, -1.4041e-01, -1.2706e-01,\n",
      "        -2.8720e-01, -2.9107e-02,  5.2271e-02,  1.9180e-01, -5.9188e-02,\n",
      "         1.1118e-02, -3.6953e-02, -4.6103e-02, -5.5561e-02, -4.2408e-02,\n",
      "        -5.4556e-02, -8.5381e-02, -2.5072e-01,  1.3272e-01,  8.9385e-02,\n",
      "         5.0679e-02, -1.4402e-01,  1.5704e-02,  8.2595e-02,  2.8950e-01,\n",
      "         1.1995e-01,  8.2218e-03,  8.6943e-02, -1.4487e-01, -6.4140e-02,\n",
      "        -2.8995e-01, -4.3396e-02,  1.0147e-01, -3.6916e-01,  1.3197e-01,\n",
      "         2.2112e-01,  2.2586e-01, -1.3024e-01,  3.4924e-02,  1.7595e-01,\n",
      "        -5.5850e-04,  1.4002e-01,  7.2031e-02,  9.4518e-02,  2.5377e-01,\n",
      "         1.5240e-01, -9.7878e-02,  8.5805e-02,  3.9108e-02,  1.6801e-01,\n",
      "        -2.7371e-01, -8.4246e-02, -1.9891e-01,  1.9488e-01,  1.0244e-01,\n",
      "        -2.1371e-01,  1.9158e-01, -4.9702e-01, -7.6887e-02,  1.3054e-01,\n",
      "         1.4384e-01,  9.2271e-02, -2.4776e-01,  2.9863e-01,  4.5713e-01,\n",
      "         6.3761e-02, -2.8826e-01, -1.8834e-01, -6.4870e-02,  2.0241e-01,\n",
      "         2.9338e-01, -1.1416e-01, -2.9192e-01, -1.3655e-01,  5.2752e-02,\n",
      "         2.9894e-02,  3.6916e-01,  1.2743e-02, -2.2503e-01,  8.0966e-02,\n",
      "         3.2966e-01,  1.3930e-01, -7.8549e-02,  1.1004e-01, -9.0624e-02,\n",
      "        -1.9984e-02,  2.2853e-02,  3.1763e-03,  6.1005e-01,  2.6677e-01,\n",
      "         4.9331e-02, -2.5631e-01, -2.4592e-01, -3.0870e-01, -4.1584e-01,\n",
      "         3.6741e-01,  1.0777e-01, -1.3235e-02, -8.0141e-02,  4.4847e-01,\n",
      "         2.7414e-01,  1.1039e-01, -8.1114e-02, -1.6639e-01,  1.8136e-02,\n",
      "         7.6002e-02,  2.0605e-01, -1.8203e-01,  2.9575e-01,  5.4778e-02,\n",
      "        -4.6968e-01,  1.5817e-02, -2.2619e-01,  1.1062e-02,  1.8545e-01,\n",
      "        -1.1914e-01,  2.1583e-01, -4.0342e-01,  1.7759e-01,  8.9240e-02]), tensor([ 1.4715e-01, -1.1582e-01, -5.4517e-01,  6.3476e-02,  2.3003e-01,\n",
      "        -3.7568e-01,  7.3924e-02,  4.7439e-02,  2.1673e-01,  1.6028e+00,\n",
      "         1.1293e-01,  1.0662e-01,  1.5826e-02,  1.9258e-01,  5.8314e-01,\n",
      "        -8.2635e-02,  1.4559e-02,  1.1670e+00,  2.6718e-01,  1.9524e-02,\n",
      "        -2.4109e-02, -3.4138e-01,  3.0578e-03, -4.3124e-02, -1.4028e-01,\n",
      "        -1.8755e-01,  4.1151e-01, -1.1568e-01,  1.5766e-01, -2.2755e-01,\n",
      "         2.7488e-01,  4.7669e-01,  6.5869e-02,  3.1986e-01, -1.0051e-01,\n",
      "         3.7083e-01,  3.7431e-01,  2.5888e-01,  4.0302e-02, -3.1139e-01,\n",
      "        -1.0606e-01,  2.5696e-01,  9.7714e-02,  1.4968e-02,  2.4271e-01,\n",
      "        -4.3234e-02, -2.3071e-02,  1.5036e-01, -6.0187e-02,  1.9132e-01,\n",
      "         1.8148e-01,  3.2150e-01,  3.4938e-03, -6.1647e-03,  1.5353e-01,\n",
      "         4.2268e-01, -7.4902e-02,  2.0026e-01, -3.2006e-01,  3.0167e-02,\n",
      "        -1.0760e-03,  3.6133e-02,  2.2295e-01, -3.9488e-01, -4.0617e-01,\n",
      "         2.9054e-01,  1.9603e-01, -2.5721e-01, -1.7330e-01,  3.5926e-01,\n",
      "         1.7871e-01,  1.5513e-01, -2.3746e-01, -1.0571e-01, -3.4771e-01,\n",
      "        -3.5807e-01, -4.2530e-01, -3.0446e-02, -3.6697e-01, -2.7928e-02,\n",
      "         3.8220e-02, -2.7102e-01,  2.1589e-01, -7.4943e-02,  2.8359e-01,\n",
      "        -1.2902e-02, -1.0033e-01,  2.5573e-01,  4.4544e-01,  6.7352e-02,\n",
      "         1.7149e-01, -1.7992e-01, -2.2241e-01,  2.3474e-01, -1.0735e-01,\n",
      "         1.9629e-01,  1.9664e-01, -4.7034e-01, -2.8128e-02,  1.3506e-01,\n",
      "         1.5568e-02, -1.5034e-01,  2.5599e-01, -2.2114e-01,  6.4259e-01,\n",
      "        -1.8362e+00,  1.8304e-01,  3.3422e-02, -4.2940e-01,  3.0359e-01,\n",
      "        -1.4178e-01,  2.6308e-01, -4.4832e-01,  1.3854e-01, -2.0441e-01,\n",
      "         3.6254e-01, -2.6688e-01,  7.4261e-02,  4.7154e-02, -2.3485e-01,\n",
      "        -6.3171e-02,  1.3521e-01, -2.8758e-01,  3.6608e-01, -1.1151e-01,\n",
      "         3.3508e-01, -3.2147e-01, -1.8507e-01, -2.1315e-01, -3.1168e-01,\n",
      "         5.1512e-01, -2.4459e-01, -2.5648e-01,  1.5668e-01, -1.6676e-01,\n",
      "         2.3520e-01, -1.0022e-01, -6.0912e-02, -2.0150e-01, -1.8814e-02,\n",
      "        -1.0786e+00,  3.4753e-01,  1.4271e-01,  1.6089e-01,  3.5357e-02,\n",
      "        -3.7278e-01, -5.1753e-02, -1.3560e-01,  2.7432e-01,  2.9843e-01,\n",
      "         1.0458e-01, -3.1359e-01,  1.3246e-01, -5.4911e-02, -2.6731e-01,\n",
      "        -1.7006e-01, -4.9054e-02, -5.5594e-01,  2.1565e-01, -1.0568e-01,\n",
      "         8.0646e-02, -5.8083e-02, -5.2684e-02, -3.1216e-01, -5.4530e-01,\n",
      "        -1.7713e-01, -4.7450e-01,  4.4390e-01, -1.2511e-01, -2.4697e-02,\n",
      "         9.8863e-02,  9.7319e-02,  2.2930e-01, -6.1309e-01,  1.1531e-01,\n",
      "         3.0035e-01,  1.9316e-01,  1.4729e-01, -4.3964e-02, -4.9253e-02,\n",
      "         2.1258e-01,  2.5144e-01,  1.6178e-01,  2.5861e-01, -9.4990e-02,\n",
      "        -6.9519e-02, -1.8239e-01, -8.2662e-02, -2.0446e-01, -1.6873e-02,\n",
      "         5.7029e-02, -9.8274e-02, -1.3385e-01, -7.0159e-02,  5.5204e-01,\n",
      "        -3.3839e-01, -2.1163e-01,  2.6825e-01,  1.9538e-01,  3.1757e-01,\n",
      "        -3.9660e-01,  2.5081e-01, -7.3162e-02,  9.2691e-02, -3.3523e-01,\n",
      "         1.6182e-01, -2.1684e-01,  1.3388e-01,  2.9618e-01,  5.4414e-01,\n",
      "        -1.8215e-01, -4.1298e-02,  6.6103e-02, -4.3536e-01, -3.5745e-01,\n",
      "         1.1068e-01, -2.3157e-02,  1.5253e-02,  5.8017e-03,  2.1508e-01,\n",
      "         3.3433e-01, -2.1859e-02,  5.5076e-02,  3.7080e-01,  3.5145e-01,\n",
      "        -4.8199e-02, -6.3034e-02, -2.6022e-01, -3.4653e-01, -5.0301e-01,\n",
      "        -1.2221e-01,  2.0986e-01, -1.6465e-01, -1.6785e-01, -1.8947e-03,\n",
      "         1.2674e-01, -2.1056e-01, -2.1199e-01, -4.7311e-01,  4.5814e-01,\n",
      "        -2.1135e-02,  1.2670e-01,  3.5335e-02,  1.6073e-01, -4.4626e-01,\n",
      "         1.7758e-01,  4.9194e-01, -1.0981e-01,  5.0496e-01, -8.9363e-02,\n",
      "        -2.3453e-01,  1.0038e-02,  2.4377e-01,  2.4996e-01, -6.7692e-01,\n",
      "         3.9861e-01,  1.5860e-01, -1.8841e-01,  1.8410e-01, -1.2347e-02,\n",
      "        -5.3329e-01, -8.8296e-02, -1.6284e-01,  5.7844e-01, -2.2034e-01,\n",
      "         9.7378e-02,  3.2253e-01,  9.8434e-02,  3.0301e-01,  1.2053e-01,\n",
      "        -2.2086e-01,  2.6342e-01, -1.7154e-01, -3.5860e-01, -4.9456e-01,\n",
      "        -3.0840e-01,  2.7307e-04,  2.9338e-01, -6.4159e-02,  4.2129e-01,\n",
      "         1.8359e-01,  1.5461e-01,  1.8370e-02, -4.7623e-01, -2.1693e-01,\n",
      "        -2.3409e-01, -1.3778e-01,  8.3451e-02,  1.1838e-01,  2.3653e-01,\n",
      "        -1.4459e-01,  2.0312e-01, -9.5995e-02, -1.6595e-01,  3.1252e-01,\n",
      "         8.8183e-02,  2.1741e-01, -3.9344e-01,  1.4425e-01, -1.8363e-01]), tensor([-4.1522e-01,  5.9725e-01, -3.9885e-01,  2.1376e-02, -4.5714e-05,\n",
      "        -1.3344e-01,  2.4180e-01, -1.6782e-01, -7.8721e-02,  2.3190e+00,\n",
      "        -4.8470e-01, -1.5428e-01,  3.0822e-01, -1.6608e-02, -6.1571e-01,\n",
      "        -4.6689e-02, -2.5608e-01,  9.5015e-01, -5.2796e-01, -2.5196e-01,\n",
      "         2.4296e-01, -6.5759e-03,  3.2050e-01,  8.8810e-03, -5.4806e-02,\n",
      "        -7.9210e-02,  2.4581e-01, -1.6659e-01,  2.3097e-01, -2.3619e-01,\n",
      "        -1.2448e-01,  6.6080e-01,  9.1145e-02, -2.2101e-01,  5.5231e-02,\n",
      "         2.8337e-01, -1.7409e-03,  9.5935e-02, -2.1530e-01, -4.5002e-01,\n",
      "        -9.2293e-02, -2.3264e-01, -1.7770e-01, -4.5392e-01, -1.2129e-01,\n",
      "         9.2727e-02, -2.3930e-01,  2.9664e-01,  9.6340e-02,  7.5992e-02,\n",
      "        -3.4071e-01,  4.9645e-01, -1.2729e-01, -2.5224e-01, -2.8236e-01,\n",
      "        -1.4170e-01,  1.9368e-01, -4.8376e-01, -2.3027e-01,  2.1445e-02,\n",
      "        -2.3873e-01, -1.5552e-01, -1.6071e-01,  3.4934e-02,  4.6324e-01,\n",
      "         4.7870e-03, -2.6607e-01, -6.0496e-02,  1.7287e-01,  1.1171e-01,\n",
      "         5.8216e-02,  6.0577e-02,  6.2680e-01,  1.3450e-01,  1.0206e-01,\n",
      "         1.7880e-01,  3.5884e-01, -4.8722e-01,  1.1519e-01,  6.8923e-01,\n",
      "        -1.9642e-01, -1.0225e-01, -3.8921e-01, -6.6613e-02,  4.3546e-01,\n",
      "        -3.9954e-01,  2.7437e-02, -7.1600e-01,  1.8382e-01,  1.3216e-02,\n",
      "        -3.3098e-01, -1.0427e-01,  4.4662e-02,  2.1868e-01,  2.4992e-01,\n",
      "        -6.4130e-03, -9.8991e-02, -4.2687e-01,  7.8384e-02,  1.2763e-01,\n",
      "         1.8732e-01, -2.6735e-01,  1.4506e-01, -1.5150e-01,  1.0740e-01,\n",
      "        -6.5238e-01,  3.3334e-01, -2.8314e-01, -5.6338e-01,  1.6603e-01,\n",
      "         1.6469e-01, -3.6502e-01,  1.4882e-01,  2.2180e-01,  7.1580e-02,\n",
      "         8.4300e-02, -3.1053e-01, -1.4137e-01, -1.3316e-01, -3.5319e-01,\n",
      "         1.6356e-01, -5.8851e-01, -2.2827e-01,  2.1109e-01,  1.8559e-01,\n",
      "         4.8936e-02, -6.4612e-02,  7.5456e-02, -1.9342e-01, -3.5690e-02,\n",
      "         4.4275e-01, -1.9159e-01,  4.6182e-03, -3.2677e-01, -2.1012e-01,\n",
      "         2.1142e-01,  3.0893e-01,  2.1771e-01, -3.6381e-01, -1.0195e-01,\n",
      "        -1.2208e+00,  2.3867e-01, -3.2669e-01,  1.9597e-02,  2.2588e-01,\n",
      "        -8.8192e-02, -3.8442e-01, -7.2765e-02, -1.7413e-01,  2.6651e-01,\n",
      "         3.8651e-01, -2.2049e-01, -3.2424e-01,  1.0624e-02,  8.8732e-02,\n",
      "         3.5537e-01,  3.1233e-01, -7.8978e-01, -5.4889e-02, -9.6068e-02,\n",
      "        -1.7028e-01, -1.7486e-01, -5.3728e-03, -4.0017e-01, -6.2794e-02,\n",
      "        -9.8330e-02, -3.8823e-01, -2.9146e-02, -2.1005e-01,  1.2125e-01,\n",
      "        -1.6846e-01, -1.7903e-01,  3.2017e-01, -3.3043e-01, -1.7317e-01,\n",
      "         2.2400e-01,  1.9758e-01, -1.5241e-01, -3.0253e-01,  1.9678e-01,\n",
      "        -2.9589e-02,  1.6264e-01, -9.3428e-03,  1.3466e-01,  2.7128e-01,\n",
      "        -3.0955e-01, -1.6480e-01, -1.1208e-01, -1.2947e-01,  1.8453e-01,\n",
      "        -5.5901e-02,  3.5141e-01, -1.8833e-01, -3.5208e-02,  3.6352e-02,\n",
      "        -1.2225e-01, -6.4973e-03,  1.3750e-01,  4.7989e-01,  3.9047e-01,\n",
      "        -4.1341e-01,  2.0885e-01, -5.1203e-01,  1.1231e-02,  1.5094e-02,\n",
      "         1.3351e-01,  3.4086e-01, -9.2462e-03,  2.1810e-01,  5.0050e-01,\n",
      "        -3.1301e-01, -3.3961e-01,  6.8402e-02, -4.3998e-01,  4.6311e-01,\n",
      "        -3.5325e-01, -1.3567e-01,  3.4502e-01, -5.2113e-01,  7.8403e-02,\n",
      "        -5.5352e-03, -1.8428e-01,  2.2385e-02,  4.4021e-01,  1.4049e-01,\n",
      "         1.2029e-01,  1.0146e-02,  5.0111e-02, -2.4788e-01, -6.6045e-01,\n",
      "         9.8222e-02,  2.6683e-01,  8.8462e-02,  9.7028e-02, -4.3458e-01,\n",
      "        -3.5165e-03, -1.5493e-01, -2.5781e-01, -2.3479e-01,  2.4528e-01,\n",
      "         2.6878e-01, -2.0105e-01, -1.0099e-01, -2.4570e-01,  1.6319e-01,\n",
      "        -4.6451e-01,  3.8521e-01, -1.4064e-02, -3.9749e-01,  6.1870e-03,\n",
      "         1.0476e-01, -5.0876e-02, -4.3475e-01, -3.2513e-02,  5.4997e-02,\n",
      "         1.9497e-01, -8.9715e-02, -1.2888e-01,  1.2592e-01, -6.3591e-02,\n",
      "        -3.6074e-01,  2.2004e-02,  2.1604e-01, -1.6215e-01, -9.4189e-02,\n",
      "         3.5134e-02, -4.9535e-02,  6.0918e-01,  7.2586e-01,  1.2466e-01,\n",
      "         9.0288e-02,  4.1847e-01, -2.9998e-01, -4.0671e-01, -4.4611e-01,\n",
      "        -1.2693e-01,  2.8021e-01,  1.2125e-01,  2.3467e-01, -2.9132e-01,\n",
      "         1.8137e-01,  4.1672e-01,  1.8799e-01, -8.2601e-02, -1.5347e-01,\n",
      "        -3.7858e-01,  1.3705e-02,  1.1031e-01, -2.0587e-01,  6.1893e-01,\n",
      "         3.8482e-02,  1.5562e-01, -1.7655e-01, -1.4225e-01,  4.0489e-01,\n",
      "        -3.2753e-01,  8.0509e-02,  1.9364e-01,  4.8776e-01,  6.0276e-02]), tensor([ 3.1091e-02,  5.6825e-01, -3.1070e-02,  4.3010e-03, -3.0250e-02,\n",
      "        -2.2010e-01,  1.6359e-02, -2.7483e-01,  5.4576e-01,  6.9811e-01,\n",
      "        -9.2913e-01, -3.2617e-01,  3.4225e-01, -3.6393e-01,  1.7427e-01,\n",
      "         1.0333e-01, -2.2877e-01,  6.2709e-01,  4.0462e-01, -2.7718e-01,\n",
      "         5.1787e-02,  2.6553e-01,  2.8972e-03, -3.7731e-01, -9.2281e-02,\n",
      "         2.6781e-01, -5.1189e-01, -3.4465e-01, -8.9694e-02, -1.3627e-01,\n",
      "        -7.3969e-02, -2.3845e-01,  4.2230e-01, -2.7770e-01, -6.8097e-01,\n",
      "         6.3363e-01,  8.4718e-02,  2.7264e-01, -2.4687e-01, -6.4634e-03,\n",
      "        -1.9284e-01,  2.2436e-02, -1.5938e-01,  5.0185e-01, -5.1570e-01,\n",
      "         4.3452e-01, -7.7770e-02, -1.4402e-01,  2.1616e-01, -1.1667e-01,\n",
      "         1.3378e-02,  1.2769e-01,  3.1937e-01,  5.2952e-02,  2.0743e-01,\n",
      "         2.5537e-01, -4.2906e-01,  5.8272e-02,  2.4935e-01, -3.8469e-01,\n",
      "        -7.0756e-01, -2.8694e-01,  2.1439e-01, -4.9421e-01,  7.1887e-02,\n",
      "         2.8562e-02, -3.9900e-01,  4.3777e-01, -1.5642e-01,  3.9649e-01,\n",
      "        -1.7438e-01, -2.3927e-01,  3.8615e-02,  2.2490e-01,  7.2184e-01,\n",
      "         3.6085e-01,  4.8800e-02,  7.3647e-01, -1.5500e-01,  5.7072e-01,\n",
      "        -4.0056e-02,  2.7431e-01, -1.2806e-01, -1.5260e-01,  1.4863e-01,\n",
      "        -6.5193e-03,  1.0662e+00, -3.6083e-01,  7.0706e-01,  4.3639e-02,\n",
      "         4.7063e-01,  2.7411e-02, -2.3215e-01, -4.6128e-01, -4.9949e-02,\n",
      "         2.0991e-02, -4.1238e-02,  4.3573e-01,  3.0043e-01,  3.5162e-01,\n",
      "        -2.9331e-01, -6.8115e-01,  2.5255e-01,  2.3526e-01, -1.3769e-01,\n",
      "        -6.2365e-01,  5.7710e-01, -1.3667e-01, -2.5982e-02, -5.9300e-02,\n",
      "        -1.6144e-02, -6.7935e-01,  1.8109e-01,  5.5385e-02, -1.6223e-01,\n",
      "         4.3419e-01,  2.3547e-01,  1.0630e-01,  1.4108e-01,  1.3307e-01,\n",
      "         5.8862e-01,  9.1575e-02, -1.8413e-01,  1.9386e-01,  1.4480e-01,\n",
      "        -9.5191e-02,  1.9922e-01,  7.5761e-02, -1.9164e-02, -7.7082e-02,\n",
      "         2.3526e-01, -8.0003e-01, -2.7262e-01,  2.3965e-01, -2.6556e-02,\n",
      "        -8.9179e-02, -3.0789e-03, -2.0901e-01, -1.3612e-01, -2.2583e-01,\n",
      "        -2.2758e+00, -1.8385e-01, -1.6255e-01, -4.2371e-01,  1.5869e-01,\n",
      "         3.5939e-01,  7.4838e-02,  2.4797e-01, -5.1820e-02, -2.6273e-01,\n",
      "        -1.1361e-01, -4.2738e-01,  8.3827e-02, -2.0052e-01,  1.3626e-01,\n",
      "        -2.8534e-01,  2.2639e-01, -3.2933e-01, -1.1853e-01,  8.5149e-02,\n",
      "        -3.9490e-03, -3.5466e-01, -2.3401e-01, -1.3937e-01,  6.8301e-03,\n",
      "        -1.2079e-01, -1.7910e-01,  7.3794e-01, -2.4173e-01,  1.8064e-01,\n",
      "        -4.4553e-02,  9.4685e-02, -3.1870e-01,  1.4406e-03, -4.2592e-01,\n",
      "         2.9623e-01, -1.7538e-01, -5.1084e-01, -4.1933e-02,  1.8008e-01,\n",
      "        -1.6072e-01, -6.2000e-02, -2.5270e-01,  3.5847e-01,  1.8067e-01,\n",
      "        -1.1788e-01, -3.8845e-02,  2.4696e-01,  1.6047e-01, -5.1667e-03,\n",
      "         2.4596e-01, -2.4756e-01, -1.5568e-01, -3.7533e-01,  9.8757e-02,\n",
      "         6.4188e-01, -3.6217e-03, -5.0042e-02,  2.1930e-01, -2.9602e-01,\n",
      "        -2.0227e-01,  2.1918e-01,  3.6836e-01,  2.9122e-01,  1.6094e-01,\n",
      "        -7.0123e-01, -4.9206e-01,  3.2254e-01,  2.6288e-01,  1.2186e-02,\n",
      "         3.2156e-01,  4.9782e-01,  3.9978e-03,  3.6138e-01, -2.7197e-01,\n",
      "        -3.0703e-01,  9.3815e-02, -7.6536e-01, -3.4780e-01,  4.8628e-01,\n",
      "         4.4034e-01, -6.2981e-01, -4.9056e-01,  1.2199e-01, -1.5922e-01,\n",
      "        -8.1561e-02, -1.4558e-01, -1.6878e-01, -3.7092e-01, -3.3377e-01,\n",
      "        -2.9117e-01,  5.9100e-01,  5.2894e-02, -2.8036e-02, -1.0446e-01,\n",
      "        -3.7111e-01, -3.8053e-01, -2.2004e-01, -2.2515e-01,  2.5515e-01,\n",
      "        -1.1202e-01, -5.5380e-01,  8.6523e-02,  4.8785e-01,  7.2203e-02,\n",
      "         2.9461e-01,  2.3643e-01, -1.1222e-01, -9.2494e-02, -2.8043e-01,\n",
      "        -1.3144e-01,  2.3400e-01,  1.1143e-01, -6.7456e-01,  4.3617e-01,\n",
      "         2.3155e-02, -5.7365e-01, -3.9816e-01, -7.3945e-01, -4.4138e-01,\n",
      "         2.1267e-01, -1.8604e-02, -2.5674e-01, -2.5934e-02, -2.3015e-01,\n",
      "        -2.5172e-01, -4.0583e-01, -8.3189e-02, -5.4541e-02,  1.5206e-01,\n",
      "        -3.1548e-01, -1.4732e-01, -2.3183e-01,  7.5427e-01,  1.8009e-02,\n",
      "         3.0702e-01, -2.2941e-01, -1.3627e-02,  3.8182e-01,  2.6575e-01,\n",
      "         6.3149e-01, -8.8812e-01, -6.6730e-01,  8.0639e-02,  2.3583e-01,\n",
      "         4.9035e-01,  1.0201e-01, -1.6356e-01, -1.1952e-01,  6.0617e-01,\n",
      "         3.8027e-01, -7.8457e-03,  3.9968e-02, -7.1060e-03,  3.2000e-01,\n",
      "        -2.6781e-01,  4.1864e-01,  1.2264e-01, -4.3825e-01,  9.0428e-02]), tensor([-0.0828,  0.6720, -0.1499, -0.0650,  0.0565,  0.4023,  0.0028, -0.3311,\n",
      "        -0.3069,  2.0817,  0.0318,  0.0136,  0.3027,  0.0071, -0.5819, -0.2774,\n",
      "        -0.0623,  1.1451, -0.2423,  0.1235, -0.1224,  0.3315, -0.0062, -0.3054,\n",
      "        -0.1306, -0.0546,  0.0371, -0.0706,  0.5893, -0.3038,  0.2898, -0.1465,\n",
      "        -0.2705,  0.3716,  0.3203, -0.2912,  0.0052, -0.1321, -0.0527,  0.0873,\n",
      "        -0.2667, -0.1690,  0.0152, -0.0084, -0.1487,  0.2341, -0.2072, -0.0914,\n",
      "         0.4008, -0.1722,  0.1814,  0.3759, -0.2868,  0.3729, -0.1619,  0.1801,\n",
      "         0.3032, -0.1322,  0.1835,  0.0958,  0.0949,  0.0083,  0.1176,  0.3405,\n",
      "         0.0368, -0.2908,  0.0583, -0.0278,  0.0829,  0.1862, -0.0315,  0.2799,\n",
      "        -0.0744, -0.1376, -0.2187,  0.1814,  0.0409, -0.1130,  0.2411,  0.3657,\n",
      "        -0.2752, -0.0568,  0.3487,  0.0119,  0.1452, -0.7139,  0.4850,  0.1481,\n",
      "         0.6229,  0.2060,  0.5838, -0.1344,  0.4021,  0.1831,  0.2802, -0.4235,\n",
      "        -0.2563,  0.1771, -0.5410,  0.1660, -0.0361,  0.0850, -0.6499,  0.0755,\n",
      "        -0.2883,  0.4063, -0.2802,  0.0941,  0.3241,  0.2844, -0.2634,  0.1155,\n",
      "         0.0719, -0.4721, -0.1837, -0.3471,  0.2996, -0.6651,  0.0025, -0.4233,\n",
      "         0.2751,  0.3601,  0.1631,  0.2396, -0.0592,  0.3261,  0.2056,  0.0387,\n",
      "        -0.0458,  0.0898,  0.4315, -0.1595,  0.0853, -0.2657, -0.1500,  0.0843,\n",
      "        -0.1671, -0.4300,  0.0608,  0.1312, -0.2411,  0.6655,  0.4453, -0.1802,\n",
      "        -0.1392,  0.5625,  0.2146, -0.4644, -0.0122,  0.0300, -0.0511, -0.2014,\n",
      "         0.8079,  0.4738, -0.0576,  0.4622,  0.1608, -0.2095, -0.0545,  0.1557,\n",
      "        -0.1371,  0.1297, -0.0119, -0.0034, -0.1359, -0.0807,  0.2007,  0.0541,\n",
      "         0.0468,  0.0595,  0.0463,  0.1775, -0.3109,  0.2812, -0.2436,  0.0853,\n",
      "        -0.2101, -0.1947,  0.0027, -0.4634,  0.1479, -0.3152, -0.0659,  0.0361,\n",
      "         0.4290, -0.3376,  0.1643,  0.3257, -0.0504, -0.0543,  0.2407,  0.4192,\n",
      "         0.1301, -0.1717, -0.3781, -0.2309, -0.0195, -0.2929, -0.3082,  0.3030,\n",
      "        -0.2266,  0.0816, -0.1852, -0.2141,  0.4062, -0.2897,  0.0742, -0.1779,\n",
      "         0.2860, -0.0396, -0.2339, -0.3605, -0.0675, -0.0911,  0.2344, -0.0041,\n",
      "         0.0032,  0.0072,  0.0087,  0.2161,  0.0499,  0.3558,  0.1375,  0.0734,\n",
      "         0.1417,  0.2412, -0.0133,  0.1561,  0.0834,  0.0881, -0.0194,  0.4379,\n",
      "         0.0840,  0.4531, -0.5049, -0.1086, -0.2527, -0.1825,  0.2044,  0.1332,\n",
      "         0.1294,  0.0506, -0.1561, -0.3954,  0.1254,  0.2488, -0.1927, -0.3185,\n",
      "        -0.1272,  0.4341,  0.3118, -0.0041, -0.2094, -0.0800,  0.1161, -0.0508,\n",
      "         0.0153, -0.2803, -0.1249,  0.2359,  0.2339, -0.1402,  0.0285,  0.5692,\n",
      "        -0.1649, -0.0364,  0.0101, -0.1711, -0.0426,  0.0450, -0.4393, -0.2614,\n",
      "         0.3009, -0.0608, -0.4531, -0.1908, -0.2029,  0.2769, -0.0609,  0.1194,\n",
      "         0.6221, -0.1934,  0.4785, -0.3011,  0.0594,  0.0749,  0.0611, -0.4662,\n",
      "         0.4005, -0.1910, -0.1433,  0.0183, -0.1864,  0.2071, -0.3560,  0.0534,\n",
      "        -0.0508, -0.1918, -0.3785, -0.0659]), tensor([-2.1788e-01,  4.4128e-01, -4.3204e-01, -1.9803e-01, -2.7968e-03,\n",
      "         2.8803e-01,  8.0648e-02, -1.4643e-01,  2.2300e-02,  2.5941e+00,\n",
      "        -2.5959e-01, -8.4183e-02,  4.2613e-01,  8.7662e-03, -3.3843e-01,\n",
      "        -1.7814e-01, -4.2161e-01,  3.3757e-01, -3.9092e-01, -6.0522e-02,\n",
      "         2.9517e-01,  1.4590e-01,  3.2846e-01, -5.8106e-02, -1.9982e-01,\n",
      "         1.1735e-01, -3.0825e-01, -2.2648e-01,  4.7433e-01, -2.4415e-01,\n",
      "        -3.0177e-01,  6.7390e-01,  6.5974e-02,  4.5855e-02, -3.6646e-02,\n",
      "         9.9892e-02,  1.3664e-01,  1.6360e-01, -1.7109e-01, -2.4558e-01,\n",
      "        -1.2538e-01,  2.1834e-01, -1.5026e-01,  1.3336e-01,  3.3971e-01,\n",
      "         9.4071e-02, -5.1316e-01, -1.5819e-01,  2.7468e-02, -3.4402e-02,\n",
      "        -5.5910e-02,  6.9633e-02, -1.2256e-02, -5.1804e-02,  2.7225e-01,\n",
      "        -1.8355e-01, -2.4559e-01, -3.1370e-01,  1.5620e-01,  6.3014e-02,\n",
      "        -3.2111e-01, -5.1905e-01, -1.1712e-01,  3.6818e-01,  4.0482e-02,\n",
      "        -4.3880e-01, -8.3865e-02,  9.5061e-02,  3.1995e-01,  5.2088e-02,\n",
      "         2.3889e-01, -1.6807e-03,  3.1965e-01, -6.8731e-02,  1.3477e-01,\n",
      "         3.2888e-01,  2.7228e-02, -1.9567e-01, -1.0522e-01,  4.3544e-01,\n",
      "         1.8869e-02, -2.4586e-02,  9.5041e-02, -1.0182e-01,  2.2237e-01,\n",
      "        -3.9997e-01,  7.7279e-02, -8.7118e-01,  3.3649e-01, -2.3464e-01,\n",
      "        -1.7064e-01, -1.6163e-01, -2.1596e-01,  4.3201e-01,  2.2237e-01,\n",
      "         5.4215e-02,  2.4430e-01,  8.3594e-02,  9.7403e-03,  1.6315e-01,\n",
      "        -1.7864e-01, -7.8538e-02, -3.2577e-02, -1.3266e-01,  4.1890e-01,\n",
      "        -7.7905e-01, -2.1269e-01, -2.8179e-01, -3.6263e-01,  2.7969e-01,\n",
      "         5.1118e-02, -4.3791e-01, -6.6222e-02, -2.9007e-01,  9.8879e-02,\n",
      "         6.8701e-02, -1.7953e-01, -2.4516e-01,  6.2370e-02, -1.8344e-01,\n",
      "         2.3848e-01, -3.8926e-01,  1.4563e-02, -1.5011e-01,  4.1463e-01,\n",
      "         2.3519e-01,  1.5768e-01, -4.2338e-01, -5.9981e-02, -8.5539e-02,\n",
      "        -1.9645e-01,  1.6238e-01,  1.3915e-02,  3.5895e-02,  1.5087e-01,\n",
      "        -1.2057e-01,  2.5404e-03, -3.2900e-01,  1.1253e-01, -1.1478e-01,\n",
      "        -2.2095e+00,  2.1364e-01,  1.4400e-02,  3.3077e-01, -7.3231e-02,\n",
      "        -3.3165e-01, -3.4116e-01,  1.9457e-01, -2.5111e-01, -2.9986e-01,\n",
      "        -2.3206e-02, -4.6035e-02, -8.0109e-02,  8.9126e-02,  5.2734e-02,\n",
      "        -9.5490e-02,  2.0326e-02, -3.4696e-01, -1.3078e-01,  4.9967e-02,\n",
      "        -3.3681e-01,  2.7430e-01, -4.5855e-01, -5.0902e-02, -2.4579e-01,\n",
      "        -9.9564e-02,  2.7532e-01, -2.2780e-01,  1.1668e-01, -9.2933e-02,\n",
      "        -1.3185e-01, -2.0557e-01,  6.7947e-02, -4.6485e-01,  8.9792e-02,\n",
      "        -1.6480e-02, -1.4847e-01,  1.8379e-01,  1.9782e-01, -8.6026e-02,\n",
      "         9.0624e-02, -8.4892e-02, -3.7597e-01, -1.9855e-01, -1.2090e-02,\n",
      "         1.2820e-02,  7.7705e-02, -1.2059e-01,  1.1353e-01,  2.9137e-01,\n",
      "         1.0847e-01,  1.3505e-01, -2.9519e-01, -3.0900e-01,  1.1161e-01,\n",
      "        -4.1132e-02, -7.6808e-02, -2.6873e-01,  9.1791e-02,  3.3636e-01,\n",
      "         1.9916e-01, -1.8500e-01, -1.0462e-01, -3.0590e-01,  1.5874e-01,\n",
      "         9.2589e-02,  2.1171e-02, -1.8780e-01,  2.0077e-01,  2.4509e-01,\n",
      "        -2.2700e-01, -2.1141e-01,  1.9871e-02, -4.0445e-01,  2.5579e-01,\n",
      "         2.2388e-01, -2.2641e-01, -7.4679e-02, -2.8030e-01, -1.1511e-01,\n",
      "         1.2736e-01,  1.9723e-01,  3.1854e-02,  3.5542e-02,  1.6587e-01,\n",
      "         1.0235e-01,  2.4897e-01,  1.0350e-01, -4.2974e-02, -8.1860e-02,\n",
      "        -4.3416e-01,  1.0390e-01, -1.6777e-02,  1.6120e-01,  7.4300e-02,\n",
      "        -9.9311e-02,  1.8984e-01, -1.2747e-01, -6.0094e-02,  4.9008e-01,\n",
      "         1.0554e-01, -6.0390e-02,  2.0226e-02,  5.3835e-01, -7.1150e-02,\n",
      "        -1.4458e-01,  8.6395e-02, -5.1988e-02, -3.2138e-01,  4.9567e-01,\n",
      "         2.9081e-01, -2.8324e-01, -1.6194e-01,  1.0306e-02, -3.6499e-01,\n",
      "        -4.5294e-02, -1.7151e-01, -5.6910e-02,  1.6989e-01,  1.8708e-01,\n",
      "         4.0052e-01,  2.4493e-01,  1.2178e-01,  3.4254e-01,  1.5890e-01,\n",
      "         8.0175e-02, -1.1652e-01,  3.3864e-01,  4.5713e-01,  5.0961e-01,\n",
      "        -1.7444e-01, -1.1862e-02, -9.4227e-02, -4.2007e-01, -2.2938e-01,\n",
      "         8.4131e-02,  1.8915e-01, -3.5540e-01, -1.7737e-01,  3.4414e-01,\n",
      "        -1.9804e-01, -2.3456e-01,  2.3658e-02, -4.2666e-02,  7.3081e-02,\n",
      "        -2.1149e-02,  3.0316e-01, -2.9115e-01,  8.3060e-02,  3.4784e-02,\n",
      "        -1.5084e-01,  2.7544e-02, -2.7939e-01,  3.8548e-02,  2.2003e-01,\n",
      "         1.8208e-01, -5.0746e-01, -1.6472e-01,  3.2255e-01,  3.0579e-01]), tensor([-3.2077e-01,  5.1624e-01, -3.5279e-01, -1.7975e-01,  2.7505e-01,\n",
      "        -9.6307e-02,  8.9750e-02, -2.7993e-01, -9.8183e-02,  2.7178e+00,\n",
      "        -2.5693e-01, -2.6030e-01,  4.3015e-01,  8.1071e-02, -5.1958e-01,\n",
      "        -1.7466e-01, -1.2741e-01,  2.3598e-01, -8.7545e-02, -2.8880e-01,\n",
      "         2.5814e-01,  1.9867e-01,  4.5692e-01, -1.6863e-01, -9.8067e-02,\n",
      "        -1.8419e-01, -3.2963e-01, -2.5338e-01,  4.2643e-01, -3.7293e-01,\n",
      "        -1.7392e-01,  5.2264e-01,  1.0384e-01,  1.2486e-01,  1.9901e-01,\n",
      "         1.0656e-01, -1.5283e-01,  1.2158e-01, -1.2973e-01, -1.7194e-01,\n",
      "        -1.5373e-01, -6.4963e-04,  4.0749e-02, -2.0035e-01,  1.8725e-01,\n",
      "        -8.3519e-02, -2.6455e-01, -1.4924e-01,  6.1567e-02,  2.3747e-01,\n",
      "        -4.0349e-01,  3.9675e-01, -3.8913e-02,  4.6031e-02,  4.5320e-01,\n",
      "        -1.2772e-02, -4.0872e-01, -2.2673e-01,  1.9934e-02,  1.0021e-02,\n",
      "        -7.2433e-02, -1.6969e-01, -1.9066e-01,  3.4971e-01, -2.6471e-02,\n",
      "        -2.4239e-01, -9.5951e-02,  1.1674e-01,  4.3099e-01,  3.2793e-01,\n",
      "        -7.3179e-02, -5.6880e-02,  1.5592e-01, -3.7101e-02,  9.7139e-02,\n",
      "         1.3911e-01,  2.0537e-01, -5.6496e-02, -1.0887e-01,  3.4721e-01,\n",
      "         4.2650e-02, -8.6676e-02, -1.6962e-01, -3.6511e-02,  6.4699e-02,\n",
      "        -4.8324e-01, -1.4406e-01, -9.8076e-01,  1.6614e-01, -2.2759e-01,\n",
      "        -8.3246e-02, -3.5047e-01, -2.7010e-01,  7.2318e-02, -1.6703e-01,\n",
      "         1.0678e-01,  1.1496e-01, -1.1064e-01,  1.4823e-01, -2.0958e-01,\n",
      "        -1.9506e-01,  2.9948e-01,  1.4842e-01,  1.0999e-01,  2.7638e-01,\n",
      "        -6.6369e-01,  3.2268e-02, -8.0317e-02, -2.3567e-01,  4.1566e-01,\n",
      "         8.8604e-02, -1.6970e-01, -6.7021e-02,  1.5551e-01,  2.0338e-01,\n",
      "         1.1561e-01,  8.1953e-02, -2.6175e-01, -6.2585e-02,  4.0077e-02,\n",
      "         1.3980e-01, -4.4829e-01, -1.0769e-02, -2.1075e-01,  1.9436e-01,\n",
      "         9.9910e-02,  1.3635e-01, -4.0162e-01,  3.8960e-02,  8.7963e-02,\n",
      "        -4.9886e-02,  1.9545e-01,  1.0337e-01, -2.3646e-02,  6.1449e-02,\n",
      "        -7.6249e-02,  1.3932e-01, -2.1416e-01,  8.6086e-02,  1.3912e-01,\n",
      "        -2.1026e+00,  2.8950e-01, -9.9585e-03,  2.3836e-01, -1.2395e-01,\n",
      "        -1.5479e-01, -3.3600e-01,  3.8285e-01, -3.3880e-01, -3.5989e-01,\n",
      "         3.5672e-04,  1.1739e-01, -2.5390e-01,  1.1560e-01,  1.4336e-01,\n",
      "        -3.4460e-01,  5.3722e-02, -4.3589e-01, -2.0581e-01, -1.9035e-01,\n",
      "        -9.7652e-02,  9.9723e-02, -3.5975e-01,  1.0309e-01, -3.2755e-01,\n",
      "         1.5254e-01, -3.9231e-02, -3.8857e-01, -6.6451e-02,  8.6742e-02,\n",
      "        -1.0071e-02, -1.6879e-01,  1.0189e-01, -6.7404e-01, -6.0975e-02,\n",
      "        -4.2740e-02,  1.3392e-01, -6.8049e-02, -9.1570e-02, -8.8889e-02,\n",
      "        -1.8429e-01, -4.2847e-02, -3.4625e-01, -1.6155e-01, -1.0652e-01,\n",
      "        -4.4709e-02, -9.1435e-02, -1.1641e-01,  5.5588e-02,  4.7454e-02,\n",
      "         2.8224e-01,  3.2870e-02, -3.5448e-01, -1.3274e-01,  1.3125e-01,\n",
      "        -1.5938e-01, -1.1239e-01, -3.8579e-01,  3.0209e-02,  2.0194e-01,\n",
      "         1.6231e-01,  1.0271e-01, -9.9821e-02, -4.5816e-01,  1.8856e-01,\n",
      "        -1.4712e-01, -5.6286e-02,  6.8785e-02,  3.2257e-01,  2.1071e-01,\n",
      "        -1.3048e-01, -2.6207e-01, -1.6313e-01, -1.9302e-01,  3.5483e-01,\n",
      "        -1.9351e-01, -1.7852e-01, -9.2966e-02, -2.8757e-01, -7.0260e-02,\n",
      "         2.2416e-01,  1.9253e-01, -4.2525e-02, -1.6779e-02,  1.5340e-01,\n",
      "         1.2170e-01, -9.2059e-02,  9.8357e-02, -2.0213e-01, -3.1156e-01,\n",
      "        -2.3629e-01, -6.2579e-02,  1.3114e-01, -1.3693e-01, -7.8851e-02,\n",
      "         2.5549e-01,  5.5127e-02, -2.8927e-01, -2.3559e-01,  4.5098e-01,\n",
      "         1.4816e-01, -8.0504e-02,  3.4333e-01,  4.3206e-02, -6.3912e-02,\n",
      "         1.0867e-01,  1.3111e-01, -2.5022e-01, -2.4781e-01,  5.0313e-01,\n",
      "         7.3038e-02, -1.0915e-01, -2.2150e-01, -1.4409e-01, -2.8491e-01,\n",
      "         2.8698e-01, -4.2820e-02, -2.0260e-02, -2.5628e-02,  7.9759e-02,\n",
      "         3.9337e-01,  2.6974e-01,  8.1124e-02,  1.4493e-01, -6.4560e-02,\n",
      "         1.6930e-02,  3.3495e-01,  1.6853e-01,  4.0839e-01,  3.7132e-01,\n",
      "         7.9057e-02, -1.2079e-01, -9.8329e-04, -2.2029e-01,  9.3896e-03,\n",
      "         6.0437e-02,  1.7829e-02, -4.1090e-02, -3.9598e-02,  3.5501e-01,\n",
      "        -1.8648e-01, -1.8263e-01, -1.8606e-02, -5.1494e-02, -1.5326e-01,\n",
      "         2.4464e-02, -5.6217e-03,  1.7035e-02, -1.0836e-01,  2.9733e-01,\n",
      "        -2.2577e-01, -1.3985e-02, -2.9499e-01, -4.3481e-02,  2.1427e-01,\n",
      "        -2.0689e-01, -4.8467e-01,  1.8402e-01,  4.5181e-01,  5.2621e-02]), tensor([-4.6131e-01,  7.8582e-01, -1.3051e-01,  2.9962e-01,  1.4882e-01,\n",
      "        -1.2660e-01,  6.2138e-03,  1.6717e-01,  1.3962e-01,  2.6747e+00,\n",
      "         6.6821e-02, -1.1656e-01, -3.2393e-01, -1.1198e-01,  3.8109e-01,\n",
      "        -1.1605e-02, -2.9280e-01,  5.9401e-01, -4.4164e-01,  8.4146e-01,\n",
      "         1.7103e-01, -1.7669e-01,  4.2094e-03, -3.8959e-01, -6.2177e-02,\n",
      "         2.2364e-01,  1.1983e-02,  8.2219e-02, -1.8641e-01, -4.7575e-01,\n",
      "        -2.7967e-01,  1.1090e-01,  1.6976e-01, -1.4370e-01,  2.2635e-01,\n",
      "         1.6212e-02,  1.5442e-01, -6.9572e-03,  1.6253e-02, -3.0153e-01,\n",
      "        -1.1867e-01, -5.4052e-01, -5.3300e-02,  3.9432e-01,  3.5486e-01,\n",
      "        -1.8898e-01, -2.1955e-01,  5.1948e-01, -2.3301e-01, -2.4687e-01,\n",
      "         7.9159e-02, -5.1176e-02,  1.4156e-01, -2.1701e-01,  2.8223e-01,\n",
      "         5.4021e-01, -3.3243e-01,  5.0801e-02,  3.5233e-02, -3.1371e-01,\n",
      "        -1.9619e-01, -1.1201e-01, -3.3515e-01, -1.6868e-01,  1.2405e-01,\n",
      "         2.7124e-01, -6.8665e-02,  3.3996e-02,  3.7444e-01,  2.7600e-01,\n",
      "         4.9600e-02, -2.0169e-02, -1.3753e-01,  4.6965e-01, -3.3222e-01,\n",
      "         3.0025e-01, -3.9775e-02, -8.1609e-02, -1.4411e-01, -1.5151e-01,\n",
      "        -1.7985e-01,  1.2866e-01,  3.1680e-01, -2.7525e-01,  4.1152e-02,\n",
      "         4.0759e-02, -3.1755e-01,  6.0422e-02,  3.3384e-01,  3.4766e-01,\n",
      "         1.6838e-01,  3.2257e-01,  1.9016e-01,  2.7254e-01, -3.1249e-01,\n",
      "        -4.8095e-01, -1.3973e-01,  4.8745e-02, -4.0803e-01, -1.0424e-01,\n",
      "         2.6400e-01,  1.6145e-01, -2.5489e-01, -1.5798e-01,  4.1880e-01,\n",
      "        -1.5705e+00,  4.3834e-01,  3.5138e-01, -8.2818e-02,  5.1683e-01,\n",
      "         8.3433e-02,  1.6907e-02,  7.9820e-02, -3.7344e-01, -2.0816e-02,\n",
      "        -1.0661e-01,  2.8525e-01, -4.2187e-01,  3.5675e-01, -5.2196e-01,\n",
      "         4.4888e-01,  2.4971e-01, -2.5353e-01,  5.8975e-01, -2.0729e-01,\n",
      "        -1.8296e-01, -2.6882e-01,  1.5491e-02, -5.0108e-01, -6.8550e-01,\n",
      "         3.0599e-01,  2.6531e-01, -5.3865e-01,  3.5029e-01,  4.0569e-01,\n",
      "         1.5409e-01,  6.4599e-01,  7.7155e-03, -2.4543e-01, -8.6257e-02,\n",
      "        -3.4823e-01,  1.0032e-01,  2.8820e-01, -1.6410e-01, -2.0670e-01,\n",
      "        -1.5966e-02,  1.9088e-01,  6.7583e-01,  2.6649e-01,  3.2667e-01,\n",
      "         1.0584e-02, -4.8589e-02,  6.2583e-01,  2.8868e-01,  1.7031e-01,\n",
      "         3.2324e-02, -1.5668e-01, -7.6200e-02, -3.7608e-01, -9.1055e-01,\n",
      "         2.4553e-01,  4.5808e-01, -1.9862e-01, -7.9184e-02,  2.8967e-01,\n",
      "        -3.1903e-01,  3.1279e-01, -4.8685e-01, -3.1850e-01, -6.5566e-01,\n",
      "         4.4883e-02, -1.0553e-01,  3.3257e-01,  1.5613e-01, -2.3510e-01,\n",
      "         1.8559e-01, -1.1368e-02, -3.2604e-01, -1.2574e-01, -8.0529e-02,\n",
      "         1.2556e-01, -2.9853e-02,  1.9039e-01, -1.4318e-01, -1.2214e-01,\n",
      "        -2.9194e-02, -2.4617e-01,  8.4501e-02, -1.3634e-02,  3.0686e-01,\n",
      "         3.3057e-01, -2.4301e-01, -5.1193e-02,  3.8225e-01,  3.7686e-02,\n",
      "         5.9346e-02, -9.5927e-02, -2.3971e-01,  3.8787e-01,  1.0956e+00,\n",
      "         2.3521e-01,  5.5300e-03,  2.4995e-02,  1.3724e-01, -1.0555e-01,\n",
      "         2.9219e-01, -2.2652e-01, -1.1632e-01, -6.8035e-02, -5.0271e-02,\n",
      "        -2.5859e-01, -6.6776e-01, -1.1638e-01, -6.6788e-02,  7.5077e-01,\n",
      "         4.5759e-01,  1.1713e-01, -3.4142e-01, -4.2837e-02,  3.1166e-01,\n",
      "         3.4673e-01,  8.2096e-04,  5.9140e-02,  1.1550e-02, -8.1745e-02,\n",
      "        -2.1471e-01, -4.4783e-01, -1.9305e-01,  1.3458e-01, -3.4378e-01,\n",
      "         1.7323e-01,  4.0581e-01, -2.1958e-01, -3.0824e-01, -2.6212e-01,\n",
      "        -1.8186e-02,  8.5733e-03,  4.6756e-01, -7.2866e-01, -3.5425e-01,\n",
      "         2.4315e-01, -4.6658e-01, -2.3068e-01, -2.1833e-01, -1.1892e-01,\n",
      "        -4.5323e-01,  2.5399e-01, -4.1920e-01, -2.1618e-01,  4.4896e-01,\n",
      "         5.9752e-01,  2.8858e-01, -2.3171e-01,  1.2888e-01, -2.5691e-01,\n",
      "         6.2590e-01,  6.6512e-01, -1.6430e-01, -1.0395e-01, -2.9178e-01,\n",
      "        -3.1203e-01,  1.8633e-01,  3.4356e-02, -2.1281e-01,  1.8474e-01,\n",
      "        -1.2030e-01,  3.4334e-01,  5.1339e-01,  4.1311e-01, -3.0373e-01,\n",
      "        -1.6400e-01,  2.6575e-01, -3.7754e-01,  9.0964e-02, -2.4246e-01,\n",
      "        -5.2035e-01,  4.5898e-01, -3.8184e-01, -1.1043e-01,  1.8668e-01,\n",
      "        -6.5613e-01, -3.4955e-01,  5.4095e-02,  5.4729e-01,  1.8832e-01,\n",
      "        -8.0310e-02, -2.4702e-01,  3.9866e-01,  2.0820e-01, -1.4827e-01,\n",
      "        -1.7420e-01,  1.4465e-01, -4.0580e-02, -1.6739e-01,  5.0442e-01,\n",
      "        -1.6202e-01,  3.7545e-02,  2.9566e-01,  1.7566e-01,  1.2015e-01]), tensor([-0.0828,  0.6720, -0.1499, -0.0650,  0.0565,  0.4023,  0.0028, -0.3311,\n",
      "        -0.3069,  2.0817,  0.0318,  0.0136,  0.3027,  0.0071, -0.5819, -0.2774,\n",
      "        -0.0623,  1.1451, -0.2423,  0.1235, -0.1224,  0.3315, -0.0062, -0.3054,\n",
      "        -0.1306, -0.0546,  0.0371, -0.0706,  0.5893, -0.3038,  0.2898, -0.1465,\n",
      "        -0.2705,  0.3716,  0.3203, -0.2912,  0.0052, -0.1321, -0.0527,  0.0873,\n",
      "        -0.2667, -0.1690,  0.0152, -0.0084, -0.1487,  0.2341, -0.2072, -0.0914,\n",
      "         0.4008, -0.1722,  0.1814,  0.3759, -0.2868,  0.3729, -0.1619,  0.1801,\n",
      "         0.3032, -0.1322,  0.1835,  0.0958,  0.0949,  0.0083,  0.1176,  0.3405,\n",
      "         0.0368, -0.2908,  0.0583, -0.0278,  0.0829,  0.1862, -0.0315,  0.2799,\n",
      "        -0.0744, -0.1376, -0.2187,  0.1814,  0.0409, -0.1130,  0.2411,  0.3657,\n",
      "        -0.2752, -0.0568,  0.3487,  0.0119,  0.1452, -0.7139,  0.4850,  0.1481,\n",
      "         0.6229,  0.2060,  0.5838, -0.1344,  0.4021,  0.1831,  0.2802, -0.4235,\n",
      "        -0.2563,  0.1771, -0.5410,  0.1660, -0.0361,  0.0850, -0.6499,  0.0755,\n",
      "        -0.2883,  0.4063, -0.2802,  0.0941,  0.3241,  0.2844, -0.2634,  0.1155,\n",
      "         0.0719, -0.4721, -0.1837, -0.3471,  0.2996, -0.6651,  0.0025, -0.4233,\n",
      "         0.2751,  0.3601,  0.1631,  0.2396, -0.0592,  0.3261,  0.2056,  0.0387,\n",
      "        -0.0458,  0.0898,  0.4315, -0.1595,  0.0853, -0.2657, -0.1500,  0.0843,\n",
      "        -0.1671, -0.4300,  0.0608,  0.1312, -0.2411,  0.6655,  0.4453, -0.1802,\n",
      "        -0.1392,  0.5625,  0.2146, -0.4644, -0.0122,  0.0300, -0.0511, -0.2014,\n",
      "         0.8079,  0.4738, -0.0576,  0.4622,  0.1608, -0.2095, -0.0545,  0.1557,\n",
      "        -0.1371,  0.1297, -0.0119, -0.0034, -0.1359, -0.0807,  0.2007,  0.0541,\n",
      "         0.0468,  0.0595,  0.0463,  0.1775, -0.3109,  0.2812, -0.2436,  0.0853,\n",
      "        -0.2101, -0.1947,  0.0027, -0.4634,  0.1479, -0.3152, -0.0659,  0.0361,\n",
      "         0.4290, -0.3376,  0.1643,  0.3257, -0.0504, -0.0543,  0.2407,  0.4192,\n",
      "         0.1301, -0.1717, -0.3781, -0.2309, -0.0195, -0.2929, -0.3082,  0.3030,\n",
      "        -0.2266,  0.0816, -0.1852, -0.2141,  0.4062, -0.2897,  0.0742, -0.1779,\n",
      "         0.2860, -0.0396, -0.2339, -0.3605, -0.0675, -0.0911,  0.2344, -0.0041,\n",
      "         0.0032,  0.0072,  0.0087,  0.2161,  0.0499,  0.3558,  0.1375,  0.0734,\n",
      "         0.1417,  0.2412, -0.0133,  0.1561,  0.0834,  0.0881, -0.0194,  0.4379,\n",
      "         0.0840,  0.4531, -0.5049, -0.1086, -0.2527, -0.1825,  0.2044,  0.1332,\n",
      "         0.1294,  0.0506, -0.1561, -0.3954,  0.1254,  0.2488, -0.1927, -0.3185,\n",
      "        -0.1272,  0.4341,  0.3118, -0.0041, -0.2094, -0.0800,  0.1161, -0.0508,\n",
      "         0.0153, -0.2803, -0.1249,  0.2359,  0.2339, -0.1402,  0.0285,  0.5692,\n",
      "        -0.1649, -0.0364,  0.0101, -0.1711, -0.0426,  0.0450, -0.4393, -0.2614,\n",
      "         0.3009, -0.0608, -0.4531, -0.1908, -0.2029,  0.2769, -0.0609,  0.1194,\n",
      "         0.6221, -0.1934,  0.4785, -0.3011,  0.0594,  0.0749,  0.0611, -0.4662,\n",
      "         0.4005, -0.1910, -0.1433,  0.0183, -0.1864,  0.2071, -0.3560,  0.0534,\n",
      "        -0.0508, -0.1918, -0.3785, -0.0659]), tensor([ 3.6543e-01,  5.5095e-01, -4.0379e-01, -5.0771e-02,  3.7162e-01,\n",
      "        -3.0855e-01, -1.4400e-01,  1.9787e-01, -1.6267e-01,  1.2310e+00,\n",
      "         5.0484e-02,  2.3953e-01,  1.0718e-01,  3.8246e-01, -9.2243e-02,\n",
      "         2.4477e-01, -3.1808e-01,  1.5828e+00, -8.4883e-02,  3.8503e-01,\n",
      "        -6.4054e-01, -4.4708e-01,  1.9114e-01, -2.5698e-01, -2.4396e-01,\n",
      "         2.0437e-02, -1.9949e-01,  2.4816e-02,  1.8100e-02,  3.6957e-01,\n",
      "        -3.0839e-01, -2.5819e-02, -1.1251e-01,  7.6486e-02,  4.8527e-01,\n",
      "        -4.0079e-01,  2.4187e-01, -4.2864e-02, -5.2087e-01, -1.1432e-01,\n",
      "        -3.0997e-01,  5.5828e-01, -5.9670e-01,  1.9106e-01, -5.5607e-02,\n",
      "        -2.9006e-01,  1.0544e-03,  1.9453e-01, -2.3314e-01,  5.3140e-01,\n",
      "        -2.8473e-01, -8.8731e-02,  1.3123e-02, -4.7092e-01,  2.6797e-02,\n",
      "         2.1324e-01,  1.4992e-01, -1.1645e-02,  4.2508e-01,  3.6863e-01,\n",
      "         1.6478e-01, -4.6158e-01,  5.2113e-01,  3.7348e-01,  2.5037e-01,\n",
      "        -6.7398e-01, -6.9621e-01,  7.2251e-02,  1.3154e-01, -6.1720e-02,\n",
      "         1.0005e-01, -1.6675e-01,  5.7557e-01,  2.2487e-01,  2.2498e-01,\n",
      "         1.2792e-01, -4.0714e-02, -1.5359e-01, -8.1758e-02,  8.5617e-02,\n",
      "        -3.5831e-01,  2.1706e-01, -1.7152e-01, -1.4771e-01,  8.7921e-04,\n",
      "         1.3135e-02,  1.1659e-01,  6.1579e-01,  7.8606e-01,  1.6219e-01,\n",
      "         1.0251e-02, -5.1272e-02, -6.2842e-02,  4.5019e-01,  1.8495e-01,\n",
      "        -5.6263e-01, -4.0471e-02, -3.4816e-01,  4.7871e-02, -3.6336e-01,\n",
      "         1.6967e-01, -3.9198e-02,  1.0271e-01,  5.1333e-02,  2.1447e-01,\n",
      "        -1.0581e+00,  4.5812e-02, -4.1456e-02,  1.2553e-01,  4.7564e-02,\n",
      "         1.4848e-01, -5.5545e-01,  1.5987e-01,  3.1896e-02, -1.1721e-01,\n",
      "        -2.7880e-02,  2.4887e-02, -2.6555e-01, -1.1635e-01,  2.2594e-01,\n",
      "         2.2188e-01, -1.5466e-01,  1.8121e-02,  2.5341e-01,  3.5706e-01,\n",
      "         3.7840e-01, -3.6770e-01, -1.7822e-01, -1.8217e-01, -1.5542e-01,\n",
      "         3.5278e-01,  2.5356e-01, -2.7396e-01, -3.3055e-01,  1.2768e-01,\n",
      "         4.3922e-01, -4.6853e-01, -2.9993e-01, -4.8818e-01, -4.6162e-02,\n",
      "        -1.5685e+00,  4.1888e-03,  1.5059e-01,  1.0792e-01,  3.3302e-01,\n",
      "        -5.0792e-01, -3.7926e-02, -3.0128e-01,  1.4865e-01, -1.5677e-01,\n",
      "        -2.6570e-01, -2.2434e-01, -9.5009e-02, -1.4002e-01,  2.3956e-01,\n",
      "        -5.5878e-03, -4.5299e-01, -2.7024e-01, -3.6527e-02, -1.3099e-01,\n",
      "         1.1671e-01,  4.2412e-01, -5.8935e-03, -3.1758e-01,  1.9886e-01,\n",
      "        -4.3556e-01,  2.7481e-01,  1.0586e-02,  1.3877e-01, -5.3109e-01,\n",
      "        -1.3880e-01, -1.8162e-01,  1.5206e-01,  2.1345e-02, -1.2439e-01,\n",
      "         1.5255e-01,  1.1441e-01,  3.0539e-01,  2.7155e-01,  3.6287e-01,\n",
      "         2.8980e-02, -3.7655e-01, -1.8576e-01,  5.2141e-02, -4.0817e-02,\n",
      "         7.5677e-02, -6.3099e-01,  3.1674e-01,  2.0430e-01,  6.9775e-01,\n",
      "        -2.4525e-01, -6.5142e-02, -4.7614e-02, -1.8296e-01, -1.3334e-01,\n",
      "        -1.3570e-01, -2.0510e-01, -1.8072e-01, -1.1400e-01,  6.0291e-01,\n",
      "         1.4042e-01,  5.4365e-02,  1.9543e-01, -2.1341e-01, -1.8683e-03,\n",
      "         4.7352e-01, -4.7161e-01, -1.3509e-01, -4.6998e-01,  2.9793e-01,\n",
      "        -2.7231e-01,  1.2220e-01, -2.0806e-01, -5.5684e-01,  8.8069e-01,\n",
      "         6.9476e-01, -6.9789e-02,  1.7740e-01, -4.7160e-01, -4.3974e-02,\n",
      "         1.4271e-01,  7.1921e-02, -2.0323e-01, -1.7560e-01,  3.5629e-01,\n",
      "         4.0510e-01, -2.6012e-01,  1.0438e-01,  4.9353e-02,  1.3056e-01,\n",
      "        -4.9237e-01, -8.2125e-02, -2.6766e-01,  1.3223e-01,  4.8383e-01,\n",
      "         1.5956e-01,  2.0963e-01, -2.0568e-01, -1.7114e-01,  3.3406e-02,\n",
      "        -1.4070e-01,  1.9308e-01, -1.7077e-01,  3.1799e-01,  1.2192e-01,\n",
      "         1.5081e-01,  4.6368e-02, -2.2876e-01, -1.9532e-01,  8.6878e-01,\n",
      "        -8.2950e-02, -7.0700e-02, -5.8561e-01, -9.4562e-02,  2.0130e-02,\n",
      "         2.1347e-01,  3.1104e-01,  5.4269e-01, -1.5636e-01, -6.3356e-02,\n",
      "        -2.8333e-01,  4.6250e-01,  1.1101e-01, -4.7578e-01,  8.2647e-02,\n",
      "         2.6392e-01, -2.6796e-01,  8.3825e-01, -4.5499e-01,  4.7725e-01,\n",
      "         2.5913e-01, -8.1818e-02,  9.1081e-02,  3.6973e-02, -5.6833e-01,\n",
      "        -1.0926e-01,  4.5515e-01,  3.2217e-01, -1.4206e-01,  1.9815e-01,\n",
      "         1.9010e-01,  4.4677e-01,  8.1049e-02,  9.3791e-02, -7.7474e-01,\n",
      "        -3.7462e-01, -1.7055e-02,  1.4309e-01,  1.7660e-01, -2.2894e-01,\n",
      "        -1.2883e-01, -7.3651e-03,  1.8110e-01, -5.3798e-02,  2.9787e-02,\n",
      "        -3.2560e-01, -2.4342e-01,  4.4982e-02,  2.0953e-01, -4.8776e-02]), tensor([-1.2486e-01,  6.9180e-02, -3.1364e-01, -3.1354e-01,  1.4388e-01,\n",
      "         1.6573e-01, -4.0073e-02, -3.4590e-01, -1.7483e-01,  2.6147e+00,\n",
      "         9.1120e-03,  1.8054e-02,  8.3494e-02, -9.3186e-02, -1.0852e-01,\n",
      "        -1.4856e-01,  1.4402e-01,  1.1995e+00, -5.1814e-01, -4.3844e-02,\n",
      "        -2.8039e-01,  1.3527e-01, -3.6054e-02, -1.3734e-01,  3.1807e-02,\n",
      "         1.7668e-02,  4.7540e-02, -3.0738e-02,  1.7169e-01, -1.0349e-01,\n",
      "         1.0784e-01,  1.9757e-02,  6.9675e-02, -1.5200e-01, -1.9508e-01,\n",
      "        -1.7867e-01,  1.1583e-01,  4.7459e-02, -4.5048e-02, -1.0148e-02,\n",
      "        -6.7003e-02,  3.0717e-02, -9.5259e-02, -2.2538e-02,  8.2868e-02,\n",
      "         1.9983e-01, -1.2923e-01, -1.3680e-01,  2.9010e-02,  1.8272e-01,\n",
      "         2.2101e-02,  1.5804e-01,  3.7986e-02,  3.1765e-02, -3.0443e-03,\n",
      "         3.1779e-02, -9.1168e-02,  3.6951e-02,  4.4161e-02,  1.0407e-01,\n",
      "         1.5687e-02, -9.7470e-02,  4.2405e-02,  2.6701e-01, -1.0596e-01,\n",
      "        -1.4289e-01, -6.7763e-02,  1.7992e-01,  2.6175e-01,  4.5349e-02,\n",
      "         2.5674e-01,  1.2484e-01,  3.6875e-01,  7.5486e-02, -1.4867e-01,\n",
      "         8.2897e-03,  8.9685e-02, -1.3242e-01, -2.4698e-01,  2.3017e-01,\n",
      "        -2.4372e-03,  1.8298e-01, -2.2386e-01,  1.7260e-01, -2.6223e-02,\n",
      "        -3.0136e-01, -1.8803e-01,  1.0426e-01, -4.1197e-02,  6.9884e-02,\n",
      "        -3.3139e-03, -1.4249e-01,  4.4817e-02,  3.6930e-01,  5.2759e-01,\n",
      "        -1.4461e-01,  2.2260e-01, -2.1296e-01, -2.1575e-01, -2.1324e-02,\n",
      "        -2.3094e-01, -9.1427e-02, -1.3952e-01, -6.5416e-02,  9.9365e-02,\n",
      "        -1.1914e+00, -1.0889e-01, -3.6120e-01, -6.4289e-02, -1.4312e-01,\n",
      "         9.1272e-03, -1.6777e-01,  2.1744e-01, -4.6958e-02,  7.1629e-03,\n",
      "        -8.1238e-03,  4.3175e-02, -5.4813e-02, -1.1981e-01,  4.2927e-02,\n",
      "         2.3405e-01,  1.0804e-01,  1.9480e-01, -5.6464e-02,  1.2108e-01,\n",
      "         1.0770e-01, -9.7876e-02, -2.4924e-01,  2.4288e-01, -2.4311e-02,\n",
      "        -8.8623e-02, -3.1197e-01, -1.8214e-01,  2.1236e-01,  2.4771e-01,\n",
      "         3.9045e-01,  1.9372e-01, -4.0742e-01,  1.3977e-01,  1.5621e-01,\n",
      "        -1.2266e+00,  2.0881e-01,  4.3454e-01, -1.0045e-01, -1.3093e-01,\n",
      "        -2.2994e-01, -2.5303e-01, -5.7255e-02,  4.4188e-02,  3.9772e-03,\n",
      "        -2.1284e-01,  2.0268e-01,  1.5135e-01, -8.1819e-03, -1.3508e-01,\n",
      "        -6.2223e-02,  1.2250e-01, -7.0757e-02, -5.4248e-02, -4.5870e-01,\n",
      "         2.6266e-01,  1.4630e-01,  4.0067e-02, -1.7087e-01, -2.3487e-02,\n",
      "        -2.6435e-01,  5.8678e-02, -7.8438e-02,  3.0261e-01, -1.4065e-01,\n",
      "        -5.5911e-02,  1.8330e-01, -1.0979e-01, -7.1047e-02, -1.7407e-01,\n",
      "        -1.4674e-01, -2.8062e-01,  1.3984e-01,  1.1339e-01,  1.0495e-01,\n",
      "        -1.4357e-01, -1.2663e-01, -3.4565e-01, -1.4041e-01, -1.2706e-01,\n",
      "        -2.8720e-01, -2.9107e-02,  5.2271e-02,  1.9180e-01, -5.9188e-02,\n",
      "         1.1118e-02, -3.6953e-02, -4.6103e-02, -5.5561e-02, -4.2408e-02,\n",
      "        -5.4556e-02, -8.5381e-02, -2.5072e-01,  1.3272e-01,  8.9385e-02,\n",
      "         5.0679e-02, -1.4402e-01,  1.5704e-02,  8.2595e-02,  2.8950e-01,\n",
      "         1.1995e-01,  8.2218e-03,  8.6943e-02, -1.4487e-01, -6.4140e-02,\n",
      "        -2.8995e-01, -4.3396e-02,  1.0147e-01, -3.6916e-01,  1.3197e-01,\n",
      "         2.2112e-01,  2.2586e-01, -1.3024e-01,  3.4924e-02,  1.7595e-01,\n",
      "        -5.5850e-04,  1.4002e-01,  7.2031e-02,  9.4518e-02,  2.5377e-01,\n",
      "         1.5240e-01, -9.7878e-02,  8.5805e-02,  3.9108e-02,  1.6801e-01,\n",
      "        -2.7371e-01, -8.4246e-02, -1.9891e-01,  1.9488e-01,  1.0244e-01,\n",
      "        -2.1371e-01,  1.9158e-01, -4.9702e-01, -7.6887e-02,  1.3054e-01,\n",
      "         1.4384e-01,  9.2271e-02, -2.4776e-01,  2.9863e-01,  4.5713e-01,\n",
      "         6.3761e-02, -2.8826e-01, -1.8834e-01, -6.4870e-02,  2.0241e-01,\n",
      "         2.9338e-01, -1.1416e-01, -2.9192e-01, -1.3655e-01,  5.2752e-02,\n",
      "         2.9894e-02,  3.6916e-01,  1.2743e-02, -2.2503e-01,  8.0966e-02,\n",
      "         3.2966e-01,  1.3930e-01, -7.8549e-02,  1.1004e-01, -9.0624e-02,\n",
      "        -1.9984e-02,  2.2853e-02,  3.1763e-03,  6.1005e-01,  2.6677e-01,\n",
      "         4.9331e-02, -2.5631e-01, -2.4592e-01, -3.0870e-01, -4.1584e-01,\n",
      "         3.6741e-01,  1.0777e-01, -1.3235e-02, -8.0141e-02,  4.4847e-01,\n",
      "         2.7414e-01,  1.1039e-01, -8.1114e-02, -1.6639e-01,  1.8136e-02,\n",
      "         7.6002e-02,  2.0605e-01, -1.8203e-01,  2.9575e-01,  5.4778e-02,\n",
      "        -4.6968e-01,  1.5817e-02, -2.2619e-01,  1.1062e-02,  1.8545e-01,\n",
      "        -1.1914e-01,  2.1583e-01, -4.0342e-01,  1.7759e-01,  8.9240e-02]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350])], [tensor([-2.1162e-01,  5.0881e-01, -3.5808e-01, -1.5994e-01,  5.9729e-02,\n",
      "         2.2136e-01,  1.9899e-01, -3.9954e-01, -8.6186e-02,  2.6236e+00,\n",
      "        -1.0163e-01, -2.1537e-01,  2.6020e-01,  7.9075e-02, -2.5419e-01,\n",
      "        -3.3137e-01, -3.6385e-01,  8.1525e-01, -3.6913e-01,  1.4787e-02,\n",
      "         1.6898e-01,  9.8759e-03,  2.3869e-01, -2.2735e-01, -1.2765e-01,\n",
      "         2.1699e-01,  3.4972e-02, -3.8552e-01,  1.4101e-01, -5.0045e-01,\n",
      "        -2.4900e-01,  1.2618e-01,  7.3550e-03, -4.5983e-02,  3.1962e-02,\n",
      "        -1.0545e-02,  2.0792e-01,  2.6317e-02, -3.0236e-01, -2.9727e-01,\n",
      "         9.4869e-02,  1.6581e-01,  7.0606e-03,  1.0952e-01,  3.7427e-01,\n",
      "         2.6568e-01, -3.0874e-01, -5.6778e-02, -2.6985e-01,  1.2846e-01,\n",
      "        -2.6186e-01,  2.1721e-01,  1.1465e-01,  6.7392e-02,  2.9040e-01,\n",
      "        -1.7979e-02,  4.0659e-02, -1.4315e-01,  2.5252e-01, -3.5092e-02,\n",
      "        -8.0121e-02, -4.7234e-01, -1.4830e-01,  1.8080e-01,  6.4688e-02,\n",
      "        -4.7125e-01, -8.0467e-02,  2.3041e-01,  2.1326e-01,  2.8665e-02,\n",
      "         2.2869e-01,  2.1337e-01,  1.7050e-01, -1.5646e-01,  6.2154e-02,\n",
      "         2.3399e-01,  2.2204e-01, -1.3310e-01, -3.8379e-01,  5.5284e-01,\n",
      "         2.3494e-01, -7.7698e-02,  6.6819e-02,  1.1081e-01,  2.0652e-01,\n",
      "        -2.9248e-01,  1.1336e-01, -4.1267e-01,  3.5172e-01, -1.3167e-01,\n",
      "        -1.6240e-01,  3.9837e-02, -5.5408e-01,  3.6173e-01,  4.2629e-01,\n",
      "         1.1339e-01,  1.5311e-01, -1.0740e-01, -1.0369e-01,  1.3735e-01,\n",
      "         6.2479e-02, -2.5904e-02,  3.1948e-02, -2.1249e-01,  4.1564e-01,\n",
      "        -8.1525e-01, -6.6405e-02, -2.8722e-01, -2.0501e-01,  1.4789e-01,\n",
      "         1.3831e-01, -3.6992e-01, -3.2382e-02, -2.1142e-01,  1.6848e-01,\n",
      "        -1.5239e-01, -8.7082e-02, -2.7300e-01, -9.3260e-02, -1.0557e-01,\n",
      "         7.0218e-03, -6.3407e-02, -4.0372e-02, -1.3123e-01,  2.9762e-01,\n",
      "         3.2887e-01, -8.6946e-02, -6.5168e-01,  1.2756e-01, -3.0596e-02,\n",
      "        -1.3320e-01, -5.1302e-02, -3.2022e-02,  3.1231e-01,  1.8967e-01,\n",
      "        -2.2370e-02, -3.0631e-01, -1.6681e-01, -3.4920e-02, -1.1048e-01,\n",
      "        -2.4287e+00,  3.8319e-01,  5.5375e-01,  1.8495e-01,  2.9125e-02,\n",
      "        -4.4547e-01, -3.6594e-01,  8.4499e-02,  1.4609e-01, -6.8328e-02,\n",
      "        -4.7732e-02,  1.1936e-01,  8.2683e-02,  1.0352e-01, -2.6974e-02,\n",
      "        -1.4117e-01, -6.2270e-02, -2.9982e-01, -9.8701e-02, -1.4337e-01,\n",
      "        -1.0086e-01,  2.5501e-01, -1.7155e-01, -6.2695e-02,  9.7862e-03,\n",
      "        -1.3468e-01,  7.7785e-02, -2.6158e-01,  2.2987e-01, -1.7863e-01,\n",
      "        -1.6546e-01, -8.9204e-02,  1.4125e-01, -2.7061e-01, -1.9121e-02,\n",
      "        -2.8581e-02, -1.5477e-01,  7.3543e-02,  1.6266e-01,  3.3421e-02,\n",
      "         1.1785e-01, -3.7671e-02, -5.0069e-01, -1.2004e-01, -8.5786e-02,\n",
      "        -1.9464e-01, -8.1361e-02, -2.0206e-01,  6.0587e-02,  3.1071e-01,\n",
      "         5.0247e-02,  1.7608e-01, -2.6993e-01, -6.5798e-02,  1.1258e-01,\n",
      "        -1.1704e-01, -5.0114e-03, -3.6337e-01,  2.6455e-01,  3.2269e-01,\n",
      "        -5.7463e-04, -1.5509e-01, -1.3281e-02, -6.1445e-02, -8.2547e-02,\n",
      "         1.6154e-01, -2.2263e-01,  2.9541e-02,  1.5252e-01,  1.3295e-01,\n",
      "         4.8895e-03, -9.9044e-02,  6.2165e-02, -7.0527e-01,  8.0859e-02,\n",
      "         1.9518e-01,  1.4025e-01, -1.4835e-01, -2.6878e-01, -2.1656e-01,\n",
      "         3.4479e-02,  2.1995e-01,  2.0640e-02,  2.4746e-01,  1.9632e-01,\n",
      "         5.2419e-02, -8.8832e-02,  1.4882e-01,  3.5510e-02, -2.7067e-02,\n",
      "        -1.9427e-01, -4.5764e-02,  4.9282e-03,  8.6165e-02,  3.5842e-02,\n",
      "        -1.9710e-01,  1.4003e-01, -3.6654e-01, -4.6045e-02,  4.2191e-01,\n",
      "         3.3336e-02, -1.2316e-02, -3.2700e-01,  4.0499e-01,  2.7818e-03,\n",
      "        -3.4689e-01, -4.4000e-01, -3.5775e-01,  1.0659e-01,  4.8608e-01,\n",
      "         5.9130e-02, -4.4669e-01, -6.4812e-02, -1.4253e-01, -1.5782e-01,\n",
      "        -2.9314e-01,  3.4164e-02, -3.8257e-02, -8.5940e-02,  1.6267e-01,\n",
      "         2.8070e-01,  2.2366e-01,  1.3294e-01,  2.2032e-01,  3.3182e-01,\n",
      "         2.5158e-01,  1.7301e-02,  1.9628e-01,  4.9331e-01,  6.5459e-01,\n",
      "        -3.2229e-01, -4.5424e-03, -4.5894e-01, -6.1516e-01, -3.0112e-01,\n",
      "        -5.9158e-02,  2.0531e-01, -3.1144e-01,  1.6657e-01,  6.3802e-01,\n",
      "         1.3024e-01, -8.3963e-02, -5.0962e-02, -9.8549e-02, -1.3692e-01,\n",
      "         9.3582e-02,  2.8602e-01, -1.3044e-01,  1.9261e-01, -2.0482e-01,\n",
      "        -2.4262e-01,  6.9892e-02, -2.0594e-01, -4.5210e-02,  4.4274e-01,\n",
      "         1.6654e-01, -3.9991e-02, -1.8072e-01,  2.8116e-01,  1.6978e-01]), tensor([-8.6864e-02,  1.9161e-01,  1.0915e-01, -3.4321e-01,  2.0368e-01,\n",
      "        -2.4777e-01,  4.6046e-01, -3.6570e-01, -1.9804e-01,  1.7379e+00,\n",
      "        -4.3507e-01,  9.6135e-02,  1.5601e-01,  2.3903e-01, -4.1931e-01,\n",
      "        -9.5131e-02,  4.4342e-02,  1.2392e+00,  1.1157e-02, -2.2522e-01,\n",
      "         3.8411e-01, -1.1606e-01, -3.9036e-02,  3.6106e-02, -5.2676e-04,\n",
      "        -1.2154e-01, -5.6884e-02,  4.1425e-01,  3.8248e-01,  2.3590e-01,\n",
      "        -8.5550e-02,  8.5120e-02, -3.7976e-02, -1.6109e-01,  4.6274e-01,\n",
      "         4.5681e-01,  1.5099e-01,  1.1551e-01, -5.9356e-03, -1.4960e-01,\n",
      "         1.1590e-01, -1.1414e-01, -1.9262e-01, -2.5766e-02,  1.6849e-01,\n",
      "         4.7380e-02, -4.7483e-01, -1.6071e-01, -9.6243e-02,  1.8192e-01,\n",
      "         1.4954e-01,  1.2130e-01,  9.3597e-04, -5.7363e-01, -1.7880e-01,\n",
      "        -1.4485e-01,  1.1158e-01, -1.8386e-01,  3.4030e-01,  2.1795e-01,\n",
      "        -2.6490e-01, -1.1665e-01,  6.4359e-01,  9.5316e-03,  5.4370e-02,\n",
      "        -2.7008e-01, -4.2555e-01,  1.8764e-02, -3.0406e-01, -3.5391e-02,\n",
      "         1.6890e-01, -9.6122e-02,  4.8576e-01,  2.2636e-01,  8.6754e-02,\n",
      "         3.2521e-01,  1.0200e-01, -2.1386e-01,  1.6353e-01,  5.7040e-01,\n",
      "        -4.8834e-01, -2.9669e-02, -1.2532e-01,  1.5784e-01, -1.6349e-01,\n",
      "         1.0762e-01,  6.4525e-01, -8.3646e-01,  1.3500e-01,  2.1632e-01,\n",
      "        -3.0822e-01, -1.5673e-01,  2.7079e-02, -4.6443e-02, -4.0391e-02,\n",
      "        -3.1256e-01, -4.4964e-01, -4.7512e-01,  4.7597e-02, -1.2785e-01,\n",
      "        -1.2521e-01,  5.1054e-01, -8.2481e-02, -2.9605e-01,  6.6536e-02,\n",
      "         3.9705e-01, -1.6395e-02,  1.8592e-01, -1.1063e-02,  1.3644e-01,\n",
      "         1.4628e-01, -7.0372e-01,  4.9209e-01,  3.8754e-03,  6.8155e-02,\n",
      "         4.2250e-01,  1.2923e-01, -3.2346e-01, -2.0351e-01, -1.1109e-01,\n",
      "         1.0363e-01,  4.8225e-02,  1.2263e-01, -2.7850e-02, -1.6093e-01,\n",
      "         1.3469e-01, -7.8230e-02, -1.1730e-01,  3.5181e-01, -2.8887e-01,\n",
      "         3.4357e-01, -2.6096e-01,  1.2608e-01,  2.7807e-01,  1.5766e-01,\n",
      "         1.8333e-02,  1.5407e-01,  7.3841e-02, -5.7197e-01,  1.7403e-01,\n",
      "        -1.4982e+00,  2.2341e-01,  2.7361e-01,  9.2857e-03,  6.7072e-02,\n",
      "         2.4006e-02, -1.1183e-01,  3.8380e-01, -4.3853e-01,  1.5147e-01,\n",
      "         2.1548e-01,  4.5302e-01, -1.8521e-01, -2.0169e-02,  2.4229e-01,\n",
      "        -2.9120e-01, -3.4095e-02, -2.3276e-01,  2.1502e-01, -2.2064e-02,\n",
      "        -4.5589e-02, -1.2733e-01, -9.7544e-02, -9.7579e-02, -7.0610e-02,\n",
      "         1.7009e-01, -3.5061e-01, -2.4645e-01,  3.0984e-01,  7.3659e-01,\n",
      "        -8.6049e-02, -2.4189e-01, -1.6846e-01,  2.2105e-01, -6.1358e-02,\n",
      "         1.6661e-01,  2.2734e-01,  1.1214e-01,  1.3455e-01, -3.4864e-01,\n",
      "        -8.4708e-02, -1.0605e-01, -1.1327e-01, -4.7898e-01, -2.2993e-01,\n",
      "        -7.0329e-02, -3.3025e-01, -5.4552e-02,  1.7280e-01, -7.2809e-02,\n",
      "         1.4718e-01,  3.1015e-01, -1.7731e-01, -2.6494e-01,  8.8670e-02,\n",
      "         9.0799e-02, -2.7828e-01, -1.7866e-02,  6.5535e-01,  4.6306e-01,\n",
      "        -9.4648e-02,  2.4050e-01,  2.2981e-01, -1.0659e-01, -1.3292e-01,\n",
      "        -1.5076e-01,  3.0420e-01, -8.7631e-02, -4.9375e-02, -2.0011e-01,\n",
      "        -2.3972e-01, -1.8101e-01, -1.2819e-01, -1.0902e-01,  1.3651e-01,\n",
      "        -2.7016e-01, -2.5798e-02,  3.1209e-01, -5.6491e-01, -1.2271e-01,\n",
      "         1.5309e-01,  1.0768e-01, -4.9543e-01, -9.4164e-03,  2.3867e-01,\n",
      "         3.7198e-02, -6.6242e-02,  1.4924e-01, -1.6148e-01, -2.5135e-01,\n",
      "        -4.1731e-01, -5.2517e-01,  5.8631e-01,  1.9534e-02, -1.2889e-01,\n",
      "        -1.4278e-01,  2.5435e-01, -1.2348e-01, -1.6830e-01, -7.7178e-02,\n",
      "        -4.5393e-02, -1.6850e-01, -1.1748e-01, -2.0589e-01,  1.0368e-01,\n",
      "        -5.2111e-01,  6.4614e-01,  7.2337e-02, -2.3209e-01,  2.9604e-01,\n",
      "         4.1656e-01, -6.7341e-02, -2.6587e-01,  4.0931e-02, -3.2838e-01,\n",
      "         1.7573e-01, -1.1610e-01,  4.5733e-02,  4.3051e-02, -3.7436e-02,\n",
      "        -2.8593e-01, -4.9150e-01,  1.6184e-01, -1.5258e-02, -1.7994e-01,\n",
      "        -6.8346e-02, -6.7421e-02,  6.4331e-02,  6.7300e-01,  3.1727e-01,\n",
      "        -9.0806e-02,  7.1224e-02,  2.6468e-02, -1.1935e-01, -5.9743e-01,\n",
      "         1.5141e-01,  1.9130e-01, -3.9930e-01,  1.7107e-01,  5.4200e-01,\n",
      "         3.8492e-01,  1.9350e-01, -3.4072e-02, -3.0936e-01,  9.9719e-02,\n",
      "         3.7634e-03,  1.6417e-01, -1.2316e-02,  2.2114e-02,  9.3504e-03,\n",
      "        -1.6615e-01, -2.6295e-01, -4.4568e-02, -1.3297e-01,  4.2561e-01,\n",
      "         7.1100e-02, -1.2816e-01, -1.5160e-02,  1.1108e-01,  2.0650e-01]), tensor([-2.6554e-01,  3.3531e-01,  2.1860e-01, -3.0100e-01, -5.5470e-02,\n",
      "        -2.4236e-01,  1.7236e-01, -1.6334e-01, -1.0900e-01,  1.2671e+00,\n",
      "        -3.3449e-01,  2.0911e-01, -1.0205e-02,  2.7530e-01, -1.8455e-01,\n",
      "         1.7111e-02, -3.7401e-02,  1.3706e+00, -1.7785e-01, -1.5351e-01,\n",
      "         9.9583e-02, -3.1839e-01,  7.7433e-02,  4.9495e-02, -5.3451e-02,\n",
      "        -3.4892e-02,  1.6875e-01,  2.8741e-02,  2.0523e-01, -1.0273e-01,\n",
      "         1.2935e-01,  3.5585e-01,  4.0188e-03,  7.9254e-02,  2.4425e-01,\n",
      "         2.7667e-01,  8.0892e-02,  3.0308e-01, -8.5076e-02,  1.0352e-03,\n",
      "         1.2730e-01,  1.1868e-01,  2.0868e-01, -1.4019e-01,  2.4865e-01,\n",
      "         3.1383e-01, -5.5654e-01,  8.6916e-02,  4.0284e-01,  3.6714e-02,\n",
      "         1.4341e-01,  3.0447e-01,  1.7679e-01, -2.0325e-01, -8.6745e-02,\n",
      "        -5.9375e-02,  1.0775e-01,  2.6919e-01,  3.6491e-02,  1.2037e-01,\n",
      "        -1.8979e-01,  1.9414e-01, -1.8552e-02, -4.5914e-01,  1.2681e-01,\n",
      "        -5.4521e-02, -2.2054e-01,  1.1147e-01,  8.4313e-03,  2.0667e-01,\n",
      "         3.1060e-01, -9.2659e-02,  3.1766e-01,  1.6209e-01,  4.5862e-01,\n",
      "         1.1182e-04, -8.8286e-02, -3.7030e-01,  5.3689e-02,  7.9508e-01,\n",
      "        -2.4994e-01,  4.3256e-01,  8.8471e-02,  4.1864e-01,  1.1771e-01,\n",
      "         4.6896e-02,  5.3549e-01, -8.6838e-01,  1.5809e-01,  4.9917e-01,\n",
      "         2.6179e-01,  5.2140e-01,  3.5645e-01,  1.4372e-01, -3.6987e-01,\n",
      "        -1.4000e-01, -6.2828e-01, -3.1675e-01, -1.9247e-02, -7.4357e-02,\n",
      "         2.0714e-01, -1.5843e-01, -2.9743e-01, -2.1549e-01,  8.0076e-02,\n",
      "         1.1832e+00,  4.8673e-01,  1.4721e-01,  1.2630e-01,  2.6231e-02,\n",
      "         3.6053e-01, -6.8196e-01,  5.5184e-01,  6.1528e-02,  3.3425e-03,\n",
      "         4.8489e-02,  1.3825e-01, -1.5156e-01, -6.9840e-02, -9.9947e-02,\n",
      "         2.3865e-01,  1.3611e-01,  2.6055e-01, -4.4013e-02,  2.5868e-02,\n",
      "        -2.7526e-01, -8.4552e-02,  4.6746e-02,  8.6153e-02, -1.8508e-01,\n",
      "        -9.3114e-02, -5.9787e-01, -2.5463e-01,  8.2126e-02, -1.4104e-01,\n",
      "         2.4358e-01, -2.4225e-01,  2.9690e-01, -1.6202e-01,  6.0339e-01,\n",
      "        -2.0813e+00,  5.5412e-01,  7.6675e-01, -1.9920e-01,  3.2305e-01,\n",
      "        -1.7755e-01, -1.6761e-01,  3.8451e-01, -3.4128e-01,  3.8295e-02,\n",
      "        -2.0701e-01,  8.7338e-01, -2.2934e-01, -1.4054e-01,  4.9033e-01,\n",
      "        -3.6845e-01,  2.6926e-01, -4.0554e-01,  3.4307e-01, -1.7314e-01,\n",
      "         1.8955e-01, -1.5305e-01, -7.7203e-02, -3.4467e-01,  9.9602e-02,\n",
      "         2.4910e-01, -1.5662e-01, -1.4328e-01,  3.2020e-02,  5.7149e-01,\n",
      "        -9.7738e-03, -8.4682e-02, -3.1799e-01,  1.0101e-01, -1.6099e-01,\n",
      "         6.6370e-02,  2.5543e-01,  1.5427e-01, -3.7382e-01, -1.0029e-01,\n",
      "        -2.4851e-01, -9.9441e-02, -1.6696e-01, -2.5520e-01, -2.6483e-01,\n",
      "        -5.4984e-01, -4.7636e-01, -3.0128e-01,  1.9842e-01,  6.2700e-02,\n",
      "        -1.1024e-01, -2.1813e-01,  3.3200e-01,  2.7030e-01,  2.4467e-02,\n",
      "         2.2990e-01,  2.9060e-03, -3.2990e-01,  7.4210e-01,  1.7305e-01,\n",
      "        -3.4286e-01,  1.0717e-01,  2.5081e-01, -5.1652e-02,  2.1430e-01,\n",
      "         5.6340e-02, -5.5078e-02,  2.3547e-01,  9.8905e-02, -4.9870e-01,\n",
      "        -4.0825e-02, -4.3741e-01, -1.5599e-01,  1.2596e-01, -5.2259e-03,\n",
      "         4.2925e-01,  3.7281e-01, -5.4302e-02, -5.4095e-01,  3.6250e-01,\n",
      "        -3.0536e-01,  1.4411e-01, -2.7903e-01,  4.5630e-02,  2.7276e-01,\n",
      "        -4.9394e-02, -3.0396e-01,  5.3267e-01, -6.6274e-03, -1.0888e-01,\n",
      "         1.2579e-01, -3.4876e-01, -1.7502e-01, -2.6133e-02,  2.5876e-02,\n",
      "         4.6289e-01, -1.1516e-01, -1.9461e-01, -1.7781e-01, -1.8374e-01,\n",
      "         2.0147e-01, -2.1280e-01, -1.5289e-01,  1.7298e-01,  2.2503e-01,\n",
      "        -9.5777e-02, -7.4261e-02,  5.2321e-02,  1.6853e-01,  5.8565e-01,\n",
      "         2.7345e-02,  1.2770e-01, -4.0630e-01, -1.3299e-01, -2.1093e-01,\n",
      "         5.9611e-01,  1.7409e-01,  1.2483e-01, -1.5014e-01, -4.6455e-02,\n",
      "        -1.0728e-02, -1.4175e-01, -3.8314e-01,  4.1410e-02, -2.5619e-01,\n",
      "        -4.2536e-02,  3.5050e-01, -2.4369e-01,  5.3533e-01,  2.5372e-01,\n",
      "        -5.9328e-01, -1.6591e-02, -7.2031e-01,  9.2813e-02, -4.5688e-01,\n",
      "        -1.0833e-01, -3.8946e-02, -3.5834e-02,  2.0215e-01,  4.0055e-01,\n",
      "         3.7802e-01, -1.2920e-01, -9.1766e-03, -1.0482e-02,  4.3290e-02,\n",
      "         1.3123e-01,  3.3219e-01,  1.5346e-01,  3.5997e-02, -8.3019e-03,\n",
      "        -3.8645e-01, -1.5056e-01, -3.2827e-02, -1.0529e-01,  2.8397e-01,\n",
      "        -2.5500e-01,  1.5195e-01, -1.7859e-01, -6.2878e-02,  1.6232e-01])], [tensor([-1.3561e-01,  5.0011e-01, -4.0467e-01,  1.9862e-01, -1.2949e-01,\n",
      "         3.7039e-02, -1.9340e-02, -3.5233e-01, -1.3637e-01,  2.3351e+00,\n",
      "         3.5024e-01,  4.2662e-01, -7.3964e-02,  3.7088e-01, -5.1053e-02,\n",
      "        -3.9193e-01, -6.8317e-01,  9.5270e-01, -2.4322e-01,  3.2828e-01,\n",
      "         5.6712e-03, -4.3538e-01,  1.4077e-01, -2.0855e-01, -2.3642e-01,\n",
      "         8.6975e-02,  1.6943e-01, -2.1793e-01,  3.6667e-02, -5.8947e-01,\n",
      "        -3.2603e-01,  3.2876e-01,  1.1630e-01,  5.1828e-01, -3.5740e-01,\n",
      "        -2.8228e-01,  3.1259e-02, -8.5298e-02, -2.6039e-01,  6.9104e-02,\n",
      "         4.3026e-01,  1.3537e-01,  1.6914e-01,  2.6715e-01,  3.4579e-01,\n",
      "         2.2965e-01, -2.9904e-01,  4.2301e-01,  7.6672e-02,  9.4290e-02,\n",
      "        -5.7210e-02,  1.7852e-01, -1.3134e-01, -2.1819e-01,  4.7994e-01,\n",
      "        -3.4609e-02, -1.4316e-01, -1.2127e-01, -4.8330e-02, -9.8859e-03,\n",
      "         2.6164e-01,  3.5099e-02, -3.5821e-01, -3.7684e-01, -3.6696e-02,\n",
      "         8.6596e-02,  2.1074e-01, -1.4565e-01,  3.8752e-01, -8.6894e-02,\n",
      "        -1.0630e-01, -1.5630e-01,  6.8244e-02, -1.9448e-01,  1.1354e-01,\n",
      "         1.4555e-01,  6.5586e-02, -9.3856e-02, -7.2906e-01,  4.5393e-01,\n",
      "         2.2079e-02, -1.9766e-01,  3.6385e-01, -1.4504e-01,  1.7915e-01,\n",
      "        -2.5320e-01,  5.8145e-02, -1.7650e-02,  3.4197e-01, -2.7880e-01,\n",
      "        -2.5505e-02,  6.3748e-01, -4.7615e-01,  4.5634e-01,  5.8048e-01,\n",
      "         1.4979e-01, -2.9207e-01, -1.8567e-01, -7.2124e-02,  1.3121e-01,\n",
      "         1.2864e-01,  5.9016e-02, -3.4993e-04, -4.3186e-02,  2.9359e-01,\n",
      "        -8.8790e-01, -1.7411e-01, -2.7130e-01, -1.7787e-01, -2.6277e-01,\n",
      "         2.1658e-01,  5.0357e-02,  4.4545e-02, -1.3621e-01,  1.9605e-01,\n",
      "        -1.3170e-02, -1.7416e-01, -1.0152e-01, -1.5711e-01, -1.6991e-01,\n",
      "        -1.0005e-01,  4.5085e-01, -2.7073e-02, -2.2737e-01,  6.3839e-02,\n",
      "         3.2387e-01, -1.7910e-01, -4.6096e-01, -7.3706e-02, -3.7901e-01,\n",
      "         7.2975e-02, -1.4270e-01, -1.7785e-01,  1.7200e-01,  1.0955e-02,\n",
      "         2.2473e-01, -3.5244e-01, -1.5834e-02,  2.2077e-01, -2.7985e-02,\n",
      "        -1.9058e+00,  4.6034e-01,  6.7626e-01,  2.7090e-01,  1.9143e-01,\n",
      "        -8.1950e-01, -1.7835e-01, -9.6217e-02,  2.6160e-01,  4.7321e-02,\n",
      "        -2.6473e-02,  1.9286e-01,  1.8716e-01, -5.3752e-02,  7.5192e-02,\n",
      "         2.2245e-01, -1.4748e-01, -3.9721e-01, -3.0508e-01,  2.2256e-02,\n",
      "        -1.3880e-01,  1.1294e-01,  2.8670e-01, -2.3954e-01, -1.7773e-01,\n",
      "        -7.0645e-02,  1.2437e-01, -2.1457e-01, -1.9318e-01, -1.2921e-01,\n",
      "        -2.7066e-01,  7.2695e-02,  5.7782e-01, -5.6719e-01, -5.4586e-02,\n",
      "        -1.6858e-01, -1.4063e-01, -1.1841e-01,  1.2606e-02,  3.4211e-01,\n",
      "         4.8860e-02,  1.0368e-01, -1.8183e-01,  9.4453e-02, -1.3061e-01,\n",
      "        -4.8674e-01,  1.7719e-01, -6.0557e-01,  3.4687e-01,  5.5452e-01,\n",
      "         1.4037e-01,  1.6444e-01, -1.0890e-01,  3.5583e-01, -1.0259e-01,\n",
      "        -3.1508e-01, -4.3201e-01, -1.0003e-01,  3.0534e-01,  4.1013e-01,\n",
      "        -3.2035e-01, -3.6687e-02,  1.7514e-01, -1.4304e-01,  1.2715e-02,\n",
      "         5.5948e-02, -2.5580e-01,  2.2512e-01,  5.1881e-01,  1.4922e-01,\n",
      "         3.3456e-01,  4.6138e-02,  1.8465e-01, -2.4472e-01,  5.5969e-02,\n",
      "         2.9145e-01,  2.1866e-01, -1.4427e-01, -1.4104e-01, -8.0787e-02,\n",
      "        -2.8841e-01,  3.1380e-01, -1.6802e-01,  3.1420e-01,  1.0245e-01,\n",
      "        -1.7315e-01, -2.9880e-01,  1.3143e-01, -2.0890e-01, -2.8545e-01,\n",
      "        -3.2781e-02, -2.5588e-01, -2.3621e-01,  2.8791e-01, -9.5515e-02,\n",
      "        -1.5484e-01,  2.9081e-01, -6.3252e-01, -2.7906e-02,  1.9413e-01,\n",
      "         1.1122e-01,  2.9086e-01, -2.3754e-01,  6.5538e-02, -3.0981e-01,\n",
      "        -4.8834e-02, -2.7604e-01, -3.3369e-01,  3.6598e-02,  5.1939e-01,\n",
      "        -1.5584e-01, -1.7925e-01,  2.7779e-01, -3.9673e-01, -3.7333e-01,\n",
      "         1.1158e-01, -6.0377e-02,  1.9337e-01,  4.1512e-02,  2.0875e-01,\n",
      "         4.9199e-01,  6.9998e-02, -3.1373e-02, -1.2746e-01,  1.1933e-01,\n",
      "         3.5848e-01,  2.3171e-01, -6.5316e-02,  3.7056e-01,  3.5154e-01,\n",
      "        -6.2473e-01,  7.1834e-03, -1.4811e-01, -3.2034e-01, -4.3327e-02,\n",
      "        -2.6567e-01,  3.2889e-02, -1.5403e-01,  2.5344e-01,  4.0908e-01,\n",
      "         3.0302e-01, -7.3014e-02, -9.2522e-02,  1.0747e-01, -3.6087e-01,\n",
      "         2.1130e-01,  3.8714e-02,  2.4155e-01,  3.6830e-03, -8.7142e-02,\n",
      "         7.4780e-02,  3.0573e-01, -1.3266e-01,  3.2253e-02,  3.0160e-01,\n",
      "         2.8452e-01,  8.6467e-03, -3.1438e-01,  2.4499e-01, -1.6272e-01]), tensor([ 0.0120,  0.2075, -0.1258, -0.5932,  0.1252,  0.1597,  0.1375, -0.3316,\n",
      "        -0.1369,  1.7893, -0.4709,  0.7043,  0.2667, -0.0900, -0.1817,  0.0672,\n",
      "         0.0533,  1.5595, -0.2541,  0.0384, -0.0141,  0.0568,  0.0234,  0.0240,\n",
      "         0.3170,  0.1902, -0.3751,  0.0356,  0.1181,  0.0120, -0.0376, -0.5046,\n",
      "        -0.0493,  0.0924,  0.1103, -0.0731,  0.3399,  0.2824,  0.1341,  0.0701,\n",
      "        -0.0221, -0.2810,  0.4961, -0.4869, -0.0910, -0.1538, -0.3801, -0.0142,\n",
      "        -0.1939, -0.1107, -0.0141, -0.1791,  0.2451, -0.1688, -0.1535, -0.1381,\n",
      "         0.0215,  0.1370,  0.0068, -0.1491, -0.3817,  0.1273,  0.4401,  0.3268,\n",
      "        -0.4612,  0.0687,  0.3475,  0.1883, -0.3184,  0.4447, -0.2095, -0.2699,\n",
      "         0.4895,  0.1539,  0.0529, -0.0498,  0.1121,  0.1488, -0.3700,  0.3078,\n",
      "        -0.3386,  0.0451, -0.1899,  0.2663, -0.2640, -0.4756,  0.6838, -0.3065,\n",
      "         0.2461,  0.3161, -0.0711,  0.0304,  0.0881,  0.0450,  0.2013, -0.2162,\n",
      "        -0.3637, -0.2595, -0.4240, -0.1431, -0.1021,  0.2150, -0.2192, -0.1794,\n",
      "         0.2155,  0.1380,  0.2450, -0.2559,  0.0548,  0.2131,  0.2564, -0.2567,\n",
      "         0.1796, -0.4764, -0.2518, -0.0091, -0.0544, -0.2101,  0.1260, -0.4080,\n",
      "        -0.0212,  0.2059,  0.1893, -0.0052, -0.5139,  0.2886, -0.0777, -0.2768,\n",
      "         0.4657, -0.1423, -0.1788, -0.4357, -0.3248,  0.1503, -0.0584,  0.4965,\n",
      "         0.2047,  0.0199,  0.1333,  0.1282, -1.0177,  0.2901,  0.2900,  0.0300,\n",
      "        -0.1076,  0.2867, -0.2439,  0.2290, -0.2625, -0.0693, -0.1789,  0.2194,\n",
      "         0.1515,  0.0457, -0.0505,  0.0715, -0.1027, -0.0807,  0.3030,  0.0313,\n",
      "         0.2661, -0.0061,  0.1031, -0.3999, -0.0439, -0.0576,  0.0870, -0.0982,\n",
      "         0.2283, -0.0052,  0.0381,  0.0159, -0.2062,  0.0219,  0.0040, -0.0431,\n",
      "        -0.0023, -0.2610, -0.2580, -0.2816, -0.2312, -0.0104, -0.3010, -0.4042,\n",
      "         0.0147, -0.1045,  0.3038, -0.2096,  0.3119,  0.0683,  0.1008,  0.0104,\n",
      "         0.5401,  0.2986,  0.1265,  0.0138,  0.2174, -0.3952,  0.0666,  0.5033,\n",
      "         0.1491, -0.1155,  0.0100,  0.0957,  0.1661, -0.1881,  0.0550,  0.0267,\n",
      "        -0.3164, -0.0466, -0.0516,  0.0235, -0.1101,  0.0856,  0.2839,  0.0405,\n",
      "         0.0720,  0.1416, -0.0212,  0.4472,  0.2009, -0.1296, -0.0672,  0.4761,\n",
      "         0.1339, -0.1729, -0.3732, -0.1728,  0.0268, -0.1316,  0.0912, -0.4649,\n",
      "         0.1274, -0.0902, -0.1055,  0.0680, -0.1338,  0.1706,  0.0895, -0.2313,\n",
      "        -0.2757,  0.0615, -0.0516,  0.2838,  0.2529, -0.2414, -0.1990,  0.1205,\n",
      "        -0.1011,  0.2739,  0.2784,  0.2645, -0.1829, -0.0490,  0.1920,  0.1719,\n",
      "         0.3366, -0.2018, -0.3431, -0.2455, -0.1540,  0.3945,  0.2284, -0.2575,\n",
      "        -0.2567, -0.3733, -0.2388, -0.0488,  0.7832,  0.1885, -0.2648,  0.0966,\n",
      "         0.0627, -0.3067, -0.4333,  0.1001,  0.2114,  0.0395, -0.1108,  0.2442,\n",
      "         0.6094, -0.4665,  0.0864, -0.3970, -0.2336,  0.0213, -0.1078, -0.2281,\n",
      "         0.5080,  0.1157,  0.1617, -0.0667, -0.2956,  0.0226, -0.2813,  0.0635,\n",
      "         0.1402,  0.1387, -0.3605, -0.0350]), tensor([ 9.4607e-01, -1.5228e-01, -4.6115e-01, -1.3206e-01,  4.1729e-02,\n",
      "        -1.3926e-01, -2.3501e-01, -3.9422e-01, -1.7922e-01,  1.9820e+00,\n",
      "         2.3770e-03,  4.8853e-02, -1.8109e-01,  2.8606e-02,  4.4947e-01,\n",
      "        -6.7650e-01, -1.2114e-01,  1.0546e+00, -3.4321e-01, -2.9968e-02,\n",
      "        -2.8705e-01,  3.1914e-01, -5.4364e-02, -4.0163e-01, -4.7658e-01,\n",
      "        -1.2789e-02,  2.2657e-01, -2.7972e-01, -1.1348e-01, -1.3357e-01,\n",
      "        -1.4377e-01, -2.0573e-01, -5.2922e-01, -2.6100e-01,  5.2414e-01,\n",
      "        -2.0539e-02,  1.0325e+00,  2.5925e-01, -4.5562e-01, -5.0095e-01,\n",
      "        -8.8946e-02, -5.2239e-01, -1.6149e-01, -1.8445e-01, -3.2272e-01,\n",
      "         3.1445e-01,  2.4781e-01,  7.7457e-02, -2.1292e-01,  3.5135e-01,\n",
      "        -9.5116e-02, -4.3533e-01,  1.2824e-01,  4.5473e-01,  8.1184e-02,\n",
      "        -1.3553e-02, -9.2962e-02, -9.2269e-02,  1.6729e-01,  5.3780e-01,\n",
      "         2.1343e-01,  3.6064e-01,  6.4227e-02,  6.4555e-02, -3.1379e-01,\n",
      "        -2.7387e-02,  1.7904e-03,  1.5203e-01,  3.4676e-01,  9.8691e-02,\n",
      "         1.2561e-01,  4.7404e-02,  1.5454e-01, -7.8147e-02,  4.0381e-01,\n",
      "        -1.2373e-01, -2.0051e-01,  1.8437e-01, -4.7280e-01, -5.8630e-01,\n",
      "         6.4576e-01, -1.3302e-01, -3.0113e-01,  1.9070e-01, -3.5717e-01,\n",
      "         8.3481e-03,  1.8916e-01,  9.2049e-01,  5.0168e-01,  1.5867e-01,\n",
      "         3.9325e-02,  1.3259e-02,  1.7580e-01,  5.3745e-01, -1.4562e-02,\n",
      "         4.3730e-01, -7.5497e-01, -2.7752e-01, -3.4189e-01,  2.5502e-01,\n",
      "        -2.3798e-01,  1.7175e-01, -6.8398e-02,  1.9711e-01,  6.4967e-01,\n",
      "        -1.0558e+00,  1.2427e+00, -1.2518e-01, -9.3477e-02,  3.0603e-01,\n",
      "         8.1913e-01, -4.8383e-02,  8.1543e-02,  2.7803e-01,  4.2272e-02,\n",
      "        -8.0828e-01,  2.7275e-01, -2.3946e-02, -1.5298e-01,  9.9753e-02,\n",
      "         5.7527e-01, -1.9728e-01, -4.1947e-01,  3.2091e-01,  5.4650e-02,\n",
      "        -8.0781e-02, -4.6527e-01,  2.3818e-02,  5.6298e-01,  2.4781e-01,\n",
      "        -3.7136e-02, -4.6406e-01, -3.7856e-01,  4.1188e-01,  6.1941e-01,\n",
      "         2.0321e-01,  2.6222e-01, -1.7190e-01, -3.0906e-01,  1.4420e-01,\n",
      "        -1.6660e+00,  2.0577e-01, -5.6204e-01, -2.0227e-01,  3.2666e-01,\n",
      "         1.0831e-01,  1.3458e-01,  1.7543e-01,  1.6501e-01, -6.5708e-01,\n",
      "         2.9460e-01,  6.0016e-01,  4.0846e-01,  2.2726e-02,  5.8363e-03,\n",
      "         3.2335e-01,  5.8931e-01,  1.0090e-01, -1.4483e-01,  1.7716e-01,\n",
      "        -2.0589e-01, -5.8076e-02, -1.2004e-01, -2.7390e-01,  8.2114e-01,\n",
      "        -2.5931e-01,  1.2284e-01,  1.4022e-01, -3.9273e-01, -1.7211e-01,\n",
      "         2.5629e-01, -3.8756e-01,  1.6477e-02, -1.5262e-01,  2.6272e-01,\n",
      "         4.0664e-02, -2.4606e-01, -4.1240e-01, -7.5556e-03,  5.8663e-02,\n",
      "        -6.3202e-01, -3.2463e-01, -1.8818e-01,  1.1814e-01,  6.4106e-01,\n",
      "        -3.1318e-01,  5.5911e-02,  3.4825e-01,  1.5799e-01,  1.2746e-01,\n",
      "        -3.8165e-01, -6.1291e-01, -5.0640e-01, -4.9423e-01,  1.3829e-01,\n",
      "        -4.6076e-01,  1.7468e-02, -4.2897e-01,  3.0520e-01,  8.4057e-02,\n",
      "        -3.1936e-01,  5.4952e-01,  1.0054e-01, -8.6979e-02,  6.4296e-02,\n",
      "         1.6120e-01,  1.6211e-01,  3.6324e-01,  1.0717e-01, -6.1196e-01,\n",
      "        -5.8058e-01, -4.9528e-01,  4.8408e-01, -3.8047e-02,  2.4019e-01,\n",
      "         2.2157e-02,  5.2218e-01, -1.7303e-01, -4.4424e-01,  8.6908e-02,\n",
      "         2.0690e-01,  5.9460e-02, -1.4925e-01, -6.6860e-03,  5.4043e-02,\n",
      "        -4.5091e-01, -5.1127e-01,  3.3464e-01,  1.4885e-01, -1.8441e-01,\n",
      "         8.4700e-02,  7.2065e-02,  1.5320e-01,  3.7754e-01,  8.8207e-02,\n",
      "         9.6019e-02,  3.7848e-01, -8.4795e-01, -4.7182e-01,  4.0873e-02,\n",
      "         1.2854e-01, -3.2211e-01, -2.0117e-01, -8.4662e-02, -3.7825e-01,\n",
      "         2.1649e-01, -9.7241e-01, -6.0402e-02, -9.1531e-01,  2.0981e-01,\n",
      "         1.9131e-01, -3.7584e-02, -1.8500e-01,  5.1945e-01, -1.8894e-01,\n",
      "         1.0679e+00,  3.5225e-01, -3.0878e-01,  1.5717e-01, -6.7713e-03,\n",
      "        -2.9003e-01,  2.2739e-02, -3.3467e-02,  2.1465e-01,  7.5688e-02,\n",
      "        -4.8104e-01, -6.0835e-01, -7.5413e-02, -5.3958e-01,  4.6415e-01,\n",
      "        -3.3561e-01, -4.9292e-01, -3.5910e-01,  5.3127e-01,  3.2139e-01,\n",
      "         2.5102e-01, -1.0789e-01, -4.3818e-02,  1.3447e-01,  7.0870e-01,\n",
      "         3.6424e-01, -9.5775e-01, -2.0456e-01,  4.5443e-01,  3.8900e-01,\n",
      "        -7.4596e-02,  3.6633e-01, -7.9528e-02,  3.4132e-01,  5.9423e-01,\n",
      "         6.3514e-01, -3.4862e-01, -2.0509e-01, -4.5206e-01,  5.5693e-01,\n",
      "         1.5943e-01,  5.3592e-01,  5.7265e-01, -2.5105e-02, -7.0946e-02])]]\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # test\n",
    "    inputs_embeddings = dataset_embedding(inputs_old, glove)\n",
    "    print(inputs_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the embedding of the data (Train, dev, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings obtained.\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # get the embedding of the data (Train, dev, test)\n",
    "    train_embeddings = dataset_embedding(train_data, glove)\n",
    "    dev_embeddings = dataset_embedding(dev_data, glove)\n",
    "\n",
    "test_embeddings = dataset_embedding(test_data, glove)\n",
    "print(\"Embeddings obtained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDCDataset(Dataset):\n",
    "    def __init__(self, inputs: list, targets: list):\n",
    "        '''\n",
    "        Initialize the EDCDataset.\n",
    "\n",
    "        :param inputs: List of conversations, where each conversation is a list of sentences,\n",
    "                       and each sentence is a list of words.\n",
    "        :type inputs: list\n",
    "        :param targets: List of labels for each conversation.\n",
    "        :type targets: list\n",
    "        '''\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple:\n",
    "        '''\n",
    "        Get an item from the dataset.\n",
    "\n",
    "        :param index: Index of the item to retrieve.\n",
    "        :type index: int\n",
    "        :return: A tuple containing input data, target data, and the length of the target sequence.\n",
    "        :rtype: tuple\n",
    "        '''\n",
    "        selected_inputs = []\n",
    "        for sentence in self.inputs[index]:\n",
    "            # the use of stack here to put the vectors of the whole converstation in a sequence\n",
    "            selected_inputs.append(torch.stack(sentence).to(DEVICE))\n",
    "\n",
    "        selected_inputs = pack_sequence(selected_inputs, enforce_sorted=False)\n",
    "        target = torch.LongTensor(self.targets[index]).to(DEVICE)\n",
    "\n",
    "        return (selected_inputs, target, target.size(0))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        '''\n",
    "        Get the length of the dataset.\n",
    "\n",
    "        :return: The number of samples in the dataset.\n",
    "        :rtype: int\n",
    "        '''\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: PackedSequence(data=tensor([2, 0, 3, 1, 4], device='cuda:0'), batch_sizes=tensor([2, 2, 1]), sorted_indices=tensor([1, 0], device='cuda:0'), unsorted_indices=tensor([1, 0], device='cuda:0'))\n",
      "Target: tensor([1, 2], device='cuda:0')\n",
      "Length: 2\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # test\n",
    "    conversations = [\n",
    "        [[torch.tensor(0), torch.tensor(1)], [torch.tensor(2), torch.tensor(3), torch.tensor(4)]],\n",
    "        [[torch.tensor(5), torch.tensor(6), torch.tensor(7)], [torch.tensor(8), torch.tensor(9)]]\n",
    "    ]\n",
    "\n",
    "    labels = [\n",
    "        [1, 2],\n",
    "        [3, 4]\n",
    "    ]\n",
    "\n",
    "    dataset = EDCDataset(conversations, labels)\n",
    "\n",
    "    inputs, target, length = dataset[0]\n",
    "\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Length:\", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_data(data: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[List[torch.Tensor], torch.Tensor, torch.Tensor]:\n",
    "    '''\n",
    "    Collate function to be used in the DataLoader.\n",
    "    :param data: The data to collate.\n",
    "        - inputs (torch.Tensor): The input data.\n",
    "        - targets (torch.Tensor): The target data.\n",
    "        - lengths (int): The length of the sequence.\n",
    "    :type data: list\n",
    "    :return: A tuple containing the inputs, targets, and masks.\n",
    "    :rtype: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
    "    '''\n",
    "    # unpack data\n",
    "    inputs, targets, lengths = zip(*data)\n",
    "    # convert to lists\n",
    "    inputs = list(inputs)\n",
    "    targets = list(targets)\n",
    "    lengths = list(lengths)\n",
    "\n",
    "    # pad the targets with -1\n",
    "    # didn't use zeros as it is a class in the dataset\n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=-1)\n",
    "    # create mask for the loss calculating\n",
    "    masks = torch.zeros(targets.size(), dtype=torch.bool).to(DEVICE)\n",
    "    # set mask values to True for valid data\n",
    "    for i, length in enumerate(lengths):\n",
    "        masks[i][:length] = 1\n",
    "\n",
    "    return (inputs, targets, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [['I', 'am', 'happy'], ['You', 'are', 'sad']]\n",
      "Targets: tensor([[ 1,  2,  3, -1],\n",
      "        [ 4,  5,  6,  7]])\n",
      "Masks: tensor([[ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]], device='cuda:0')\n",
      "--------------------------\n",
      "Inputs: [['I', 'am', 'happy', 'sad', 'sad', 'sad'], ['You', 'are', 'sad']]\n",
      "Targets: tensor([[ 1,  2,  3, -1],\n",
      "        [ 4,  5,  6,  7]])\n",
      "Masks: tensor([[ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # test collate\n",
    "    data = [\n",
    "    (['I', 'am', 'happy'], torch.tensor([1, 2, 3]), 3),\n",
    "    (['You', 'are', 'sad'], torch.tensor([4, 5, 6, 7]), 4)\n",
    "    ]\n",
    "\n",
    "    inputs, targets, masks = collate_data(data)\n",
    "\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    print(\"Masks:\", masks)\n",
    "\n",
    "    print('--------------------------')\n",
    "\n",
    "    data = [\n",
    "    (['I', 'am', 'happy', 'sad', 'sad', 'sad'], torch.tensor([1, 2, 3]), 3),\n",
    "    (['You', 'are', 'sad'], torch.tensor([4, 5, 6, 7]), 4)\n",
    "    ]\n",
    "\n",
    "    inputs, targets, masks = collate_data(data)\n",
    "\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    print(\"Masks:\", masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction(nn.Module):\n",
    "    '''\n",
    "    FeatureExtraction module to extract features from the input data.\n",
    "    '''\n",
    "    def __init__(self, embedding_size: int, hidden_layer_size: int):\n",
    "        '''\n",
    "        Initialize the FeatureExtraction module.\n",
    "        :param embedding_size: The size of the word embeddings.\n",
    "        :type embedding_size: int\n",
    "        :param hidden_layer_size: The size of the hidden layer.\n",
    "        :type hidden_layer_size: int\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.bilstm = nn.LSTM(embedding_size, hidden_layer_size,\n",
    "                              batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass of the FeatureExtraction module.\n",
    "        :param inputs: The input data.\n",
    "        :type inputs: torch.Tensor\n",
    "        :return: The output of the FeatureExtraction module.\n",
    "        :rtype: torch.Tensor\n",
    "        '''\n",
    "        outputs = []\n",
    "        for input in inputs:\n",
    "            # LSTM output: (N, max(L), D) -> (N, max(L), 2*H)\n",
    "            output, _ = self.bilstm(input)\n",
    "            # Unpack the PackedSequence to get the output and lengths: (N, max(L), 2*H)\n",
    "            output, lengths = pad_packed_sequence(\n",
    "                output, batch_first=True)\n",
    "            # Reshape to separate bidirectional outputs: (N, max(L), 2, H)\n",
    "            output = output.view(output.size(0), output.size(1), 2, -1)\n",
    "            # Extract last forward and first backward outputs: (N, max(L), 2*H) -> (N, 2*H)\n",
    "            output = torch.stack([torch.cat([output[i, length-1, 0], output[i, 0, 1]])\n",
    "                                  for i, length in enumerate(lengths)])\n",
    "            outputs.append(output)\n",
    "        # Pad the sequences: (B, max(N), U)\n",
    "        outputs = pad_sequence(outputs, batch_first=True)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDetection(nn.Module):\n",
    "    '''\n",
    "    Emotion Detection model.\n",
    "    '''\n",
    "    def __init__(self, utterance_embedding_size: int, hidden_layer_size: int):\n",
    "        '''\n",
    "        Initialize the EmotionDetection module.\n",
    "        :param utterance_embedding_size: The size of the utterance embeddings.\n",
    "        :type utterance_embedding_size: int\n",
    "        :param hidden_layer_size: The size of the hidden layer.\n",
    "        :type hidden_layer_size: int\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.utterance_embedding_size = utterance_embedding_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        # Create the layers\n",
    "        self.global_state_gru = nn.GRUCell(self.utterance_embedding_size, self.utterance_embedding_size)\n",
    "        self.global_state_weight = nn.Parameter(torch.randn(self.utterance_embedding_size, self.utterance_embedding_size))\n",
    "        self.party_state_gru = nn.GRUCell(self.utterance_embedding_size, self.utterance_embedding_size)\n",
    "        self.emotion_state_gru = nn.GRUCell(self.utterance_embedding_size, self.hidden_layer_size)\n",
    "\n",
    "    def forward(self, utterance_inputs: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass of the EmotionDetection module.\n",
    "        :param inputs: The input data.\n",
    "        :type inputs: torch.Tensor\n",
    "        :return: The output of the EmotionDetection module.\n",
    "        :rtype: torch.Tensor\n",
    "        '''\n",
    "        # Transpose inputs to shape (N, B, U)\n",
    "        utterance_inputs = utterance_inputs.transpose(0, 1)\n",
    "\n",
    "        # Initialize states\n",
    "        global_state = [torch.zeros(utterance_inputs.size(1), self.utterance_embedding_size).to(DEVICE)]\n",
    "        party_state = [torch.zeros(utterance_inputs.size(1), self.utterance_embedding_size).to(DEVICE) for _ in range(2)]\n",
    "        emotion_state = torch.zeros(utterance_inputs.size(1), self.hidden_layer_size).to(DEVICE)\n",
    "\n",
    "        emotion_outputs = []\n",
    "        for i in range(utterance_inputs.size(0)):\n",
    "            current_utterance = utterance_inputs[i]  # (B, U)\n",
    "            current_party = i % 2\n",
    "\n",
    "            # Update global state\n",
    "            global_state.append(self.global_state_gru(current_utterance + party_state[current_party], global_state[i]))\n",
    "\n",
    "            # Calculate attention scores\n",
    "            global_state_history = torch.stack(global_state[:i+1])  # (1+n, B, U)\n",
    "            attention_score = (current_utterance.unsqueeze(1) @ self.global_state_weight @ global_state_history.unsqueeze(-1)).squeeze(-1)\n",
    "            attention_weights = F.softmax(attention_score, dim=0)  # (1+n, B, 1)\n",
    "\n",
    "            # Calculate context vector\n",
    "            context_vector = torch.sum(global_state_history * attention_weights, dim=0)  # (B, U)\n",
    "\n",
    "            # Update party and emotion states\n",
    "            party_state[current_party] = self.party_state_gru(current_utterance + context_vector, party_state[current_party])\n",
    "            emotion_state = self.emotion_state_gru(party_state[current_party], emotion_state)\n",
    "\n",
    "            emotion_outputs.append(emotion_state)\n",
    "\n",
    "        # Transpose outputs to shape (B, N, H)\n",
    "        emotion_outputs = torch.stack(emotion_outputs).transpose(0, 1)\n",
    "\n",
    "        return emotion_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    '''\n",
    "    Model class for the Emotion Detection and Classification model.\n",
    "    '''\n",
    "    def __init__(self, word_embedding_size: int, lstm_hidden_size, hidden_layer_size: int, output_classes: int = 7):\n",
    "        '''\n",
    "        Initialize the Model.\n",
    "        :param word_embedding_size: The size of the word embeddings.\n",
    "        :type word_embedding_size: int\n",
    "        :param lstm_hidden_size: The size of the LSTM hidden layer.\n",
    "        :type lstm_hidden_size: int\n",
    "        :param hidden_layer_size: The size of the hidden layer.\n",
    "        :type hidden_layer_size: int\n",
    "        :param output_classes: The size of the output layer.\n",
    "        :type output_classes: int\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = FeatureExtraction(word_embedding_size, lstm_hidden_size)\n",
    "        self.emotion_detector = EmotionDetection(2 * lstm_hidden_size, hidden_layer_size)\n",
    "        self.classifier = nn.Linear(hidden_layer_size, output_classes)\n",
    "\n",
    "    def forward(self, input_data: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass of the Model.\n",
    "        :param inputs: The input data.\n",
    "        :type inputs: torch.Tensor\n",
    "        :return: The output of the Model.\n",
    "        :rtype: torch.Tensor\n",
    "        '''\n",
    "        # Extract features from input data\n",
    "        feature_output = self.feature_extractor(input_data)  # (B, pack(N, L, D)) -> (B, N, U)\n",
    "\n",
    "        # Detect emotions from feature output\n",
    "        emotion_output = self.emotion_detector(feature_output)  # (B, N, U) -> (B, N, H)\n",
    "\n",
    "        # Classify emotions\n",
    "        classification_output = self.classifier(emotion_output)  # (B, N, H) -> (B, N, C)\n",
    "\n",
    "        # Use CrossEntropyLoss for classification\n",
    "        return classification_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_scores(y_true: List[int], y_pred: List[int]) -> Tuple[float, float, float, float, str]:\n",
    "    '''\n",
    "    Evaluate the model using accuracy, precision, recall, and F1 score. NOTE -->  (Macro averaging)\n",
    "    :param y_true: The true labels.\n",
    "    :type y_true: list\n",
    "    :param y_pred: The predicted labels.\n",
    "    :type y_pred: list\n",
    "    :return: A tuple containing the accuracy, precision, recall, F1 score , and a string describing the metrics.\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    percision = precision_score(y_true, y_pred, average=\"macro\", zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=1)\n",
    "    report = classification_report(y_true, y_pred, zero_division=1)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    # format confusion matrix for printing\n",
    "    matrix_str = \"Confusion Matrix:\\n\"\n",
    "    matrix_str += \"      Predicted\\n\"\n",
    "    matrix_str += \"       \" + \" \".join([str(i) for i in range(len(matrix))]) + \"\\n\"\n",
    "    matrix_str += \"True\\n\"\n",
    "    matrix_str += \"\\n\".join([f\"{i:<6} {row}\" for i, row in enumerate(matrix)])\n",
    "\n",
    "    # Append confusion matrix to the report\n",
    "    report_with_matrix = report + \"\\n\\n\" + matrix_str\n",
    "\n",
    "    return (accuracy, percision, recall, f1, report_with_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "Precision: 0.2222222222222222\n",
      "Recall: 0.3333333333333333\n",
      "F1 Score: 0.26666666666666666\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.22      0.33      0.27         6\n",
      "weighted avg       0.22      0.33      0.27         6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "      Predicted\n",
      "       0 1 2\n",
      "True\n",
      "0      [2 0 0]\n",
      "1      [1 0 1]\n",
      "2      [0 2 0]\n"
     ]
    }
   ],
   "source": [
    "if isTrain:\n",
    "    # test\n",
    "    y_true = [0, 1, 2, 0, 1, 2]\n",
    "    y_pred = [0, 2, 1, 0, 0, 1]\n",
    "    accuracy, precision, recall, f1, report = calculate_evaluation_scores(y_true, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Report:\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_data_loader: DataLoader, loss_criterion: nn.Module, optimizer: torch.optim.Optimizer ) -> Tuple[float, float, float, float, float, str]:\n",
    "    '''\n",
    "    Train the model using the training data.\n",
    "    :param model: The model to train.\n",
    "    :type model: nn.Module\n",
    "    :param train_data_loader: The DataLoader for the training data.\n",
    "    :type train_data_loader: DataLoader\n",
    "    :param loss_criterion: The loss criterion.\n",
    "    :type loss_criterion: nn.Module\n",
    "    :param optimizer: The optimizer.\n",
    "    :type optimizer: torch.optim.Optimizer\n",
    "    :return: A tuple containing the loss, accuracy, precision, recall, F1 score, and the report.\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    model.train()\n",
    "    loss_values = []\n",
    "    predicted_labels_list = []\n",
    "    true_labels_list = []\n",
    "\n",
    "    for input_data, target_labels, masks in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(input_data)\n",
    "\n",
    "        # Flatten model_output and target_labels while considering masks\n",
    "        model_output_flat = model_output[masks].view(-1, model_output.size(-1))\n",
    "        target_labels_flat = target_labels[masks].view(-1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_criterion(model_output_flat, target_labels_flat)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_values.append(loss.item())\n",
    "        predicted_labels_list.append(torch.argmax(model_output_flat, dim=-1).cpu().numpy())\n",
    "        true_labels_list.append(target_labels_flat.cpu().numpy())\n",
    "\n",
    "    predicted_labels = np.concatenate(predicted_labels_list)\n",
    "    true_labels = np.concatenate(true_labels_list)\n",
    "\n",
    "    average_loss = np.mean(loss_values)\n",
    "    evaluation_scores = calculate_evaluation_scores(true_labels, predicted_labels)\n",
    "\n",
    "    return (average_loss, *evaluation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, eval_data_loader: DataLoader, loss_criterion: nn.Module) -> Tuple[float, float, float, float, float, str]:\n",
    "    '''\n",
    "    Evaluate the model using the evaluation data.\n",
    "    :param model: The model to evaluate.\n",
    "    :type model: nn.Module\n",
    "    :param eval_data_loader: The DataLoader for the evaluation data.\n",
    "    :type eval_data_loader: DataLoader\n",
    "    :param loss_criterion: The loss criterion.\n",
    "    :type loss_criterion: nn.Module\n",
    "    :return: A tuple containing the loss, accuracy, precision, recall, F1 score, and the report.\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    model.eval()\n",
    "    loss_values = []\n",
    "    predicted_labels_list = []\n",
    "    true_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_labels, masks in eval_data_loader:\n",
    "            model_output = model(input_data)\n",
    "\n",
    "            class_count = model_output.size(-1)\n",
    "            model_output = torch.masked_select(model_output, masks.unsqueeze(-1)).view(-1, class_count)\n",
    "            target_labels = torch.masked_select(target_labels, masks)\n",
    "\n",
    "            loss = loss_criterion(model_output, target_labels)\n",
    "\n",
    "            loss_values.append(loss.item())\n",
    "            predicted_labels_list.append(torch.argmax(model_output, dim=-1).cpu().numpy())\n",
    "            true_labels_list.append(target_labels.cpu().numpy())\n",
    "\n",
    "    predicted_labels = np.concatenate(predicted_labels_list)\n",
    "    true_labels = np.concatenate(true_labels_list)\n",
    "\n",
    "    average_loss = np.mean(loss_values)\n",
    "    evaluation_scores = calculate_evaluation_scores(true_labels, predicted_labels)\n",
    "\n",
    "    return (average_loss, *evaluation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(targets: List[List[int]]) -> List[float]:\n",
    "    '''\n",
    "    Calculate the class weights for the dataset.\n",
    "    :param target_labels: The target labels.\n",
    "    :type target_labels: list\n",
    "    :return: The class weights.\n",
    "    :rtype: list\n",
    "    '''\n",
    "    # Flatten the list of lists\n",
    "    flat_targets = [label for sublist in targets for label in sublist]\n",
    "\n",
    "    # Count the frequency of each class\n",
    "    class_counts = {}\n",
    "    for label in flat_targets:\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    # Calculate the total number of samples\n",
    "    total_samples = len(flat_targets)\n",
    "\n",
    "    print(class_counts)\n",
    "    # Calculate class weights\n",
    "    class_weights = []\n",
    "    for label, count in class_counts.items():\n",
    "        weight = total_samples / (len(class_counts) * count)\n",
    "        class_weights.append(weight)\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4710, 6: 1205, 3: 268, 5: 683, 4: 1743, 2: 271, 1: 1109}\n"
     ]
    }
   ],
   "source": [
    "# Define the class weights\n",
    "class_weights = torch.tensor(calculate_class_weights(train_label)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3030, 1.1842, 5.3246, 2.0893, 0.8187, 5.2657, 1.2867],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 1.7770 Acc: 0.1422 F1: 0.1217(0.2546/0.1963)\n",
      "Dev   Loss: 1.6421 Acc: 0.2137 F1: 0.1696(0.5803/0.2493)\n",
      "--------------------------------------------\n",
      "Epoch: 1\n",
      "Train Loss: 1.6253 Acc: 0.2819 F1: 0.2244(0.2942/0.2847)\n",
      "Dev   Loss: 1.6191 Acc: 0.3300 F1: 0.2491(0.4488/0.2887)\n",
      "--------------------------------------------\n",
      "Epoch: 2\n",
      "Train Loss: 1.5208 Acc: 0.3628 F1: 0.2769(0.3280/0.3291)\n",
      "Dev   Loss: 1.5941 Acc: 0.3922 F1: 0.2949(0.4708/0.3431)\n",
      "--------------------------------------------\n",
      "Epoch: 3\n",
      "Train Loss: 1.4162 Acc: 0.4072 F1: 0.3199(0.3499/0.3842)\n",
      "Dev   Loss: 1.6174 Acc: 0.3679 F1: 0.2529(0.3517/0.3114)\n",
      "--------------------------------------------\n",
      "Epoch: 4\n",
      "Train Loss: 1.7146 Acc: 0.2272 F1: 0.1922(0.2938/0.2635)\n",
      "Dev   Loss: 1.7030 Acc: 0.1731 F1: 0.1146(0.6694/0.1927)\n",
      "--------------------------------------------\n",
      "Epoch: 5\n",
      "Train Loss: 1.6855 Acc: 0.2183 F1: 0.1824(0.4200/0.2478)\n",
      "Dev   Loss: 1.8137 Acc: 0.2624 F1: 0.1640(0.4038/0.2462)\n",
      "--------------------------------------------\n",
      "Epoch: 6\n",
      "Train Loss: 1.6496 Acc: 0.2832 F1: 0.2241(0.2886/0.2862)\n",
      "Dev   Loss: 1.6363 Acc: 0.2913 F1: 0.2138(0.5403/0.2780)\n",
      "--------------------------------------------\n",
      "Epoch: 7\n",
      "Train Loss: 1.4885 Acc: 0.3743 F1: 0.2930(0.3308/0.3544)\n",
      "Dev   Loss: 1.7109 Acc: 0.3859 F1: 0.2816(0.4866/0.3488)\n",
      "--------------------------------------------\n",
      "Epoch: 8\n",
      "Train Loss: 1.3516 Acc: 0.4316 F1: 0.3355(0.3696/0.4178)\n",
      "Dev   Loss: 1.6322 Acc: 0.3363 F1: 0.2672(0.4752/0.3206)\n",
      "--------------------------------------------\n",
      "Epoch: 9\n",
      "Train Loss: 1.1701 Acc: 0.4813 F1: 0.3875(0.4176/0.4889)\n",
      "Dev   Loss: 1.6253 Acc: 0.4193 F1: 0.3157(0.3377/0.3637)\n",
      "--------------------------------------------\n",
      "Epoch: 10\n",
      "Train Loss: 0.9500 Acc: 0.5595 F1: 0.4761(0.4744/0.5792)\n",
      "Dev   Loss: 1.8720 Acc: 0.4058 F1: 0.3121(0.3376/0.3378)\n",
      "--------------------------------------------\n",
      "Epoch: 11\n",
      "Train Loss: 0.7643 Acc: 0.6173 F1: 0.5563(0.5326/0.6527)\n",
      "Dev   Loss: 2.0565 Acc: 0.4337 F1: 0.3423(0.3545/0.3700)\n",
      "--------------------------------------------\n",
      "Epoch: 12\n",
      "Train Loss: 0.6035 Acc: 0.6804 F1: 0.6425(0.6011/0.7354)\n",
      "Dev   Loss: 2.2370 Acc: 0.4337 F1: 0.3371(0.3392/0.3578)\n",
      "--------------------------------------------\n",
      "Epoch: 13\n",
      "Train Loss: 0.4663 Acc: 0.7388 F1: 0.7224(0.6747/0.8087)\n",
      "Dev   Loss: 2.6183 Acc: 0.4689 F1: 0.3605(0.3556/0.3744)\n",
      "--------------------------------------------\n",
      "Epoch: 14\n",
      "Train Loss: 0.3239 Acc: 0.8132 F1: 0.8063(0.7592/0.8752)\n",
      "Dev   Loss: 2.9404 Acc: 0.4806 F1: 0.3410(0.3391/0.3549)\n",
      "--------------------------------------------\n",
      "Epoch: 15\n",
      "Train Loss: 0.3247 Acc: 0.8205 F1: 0.8056(0.7600/0.8735)\n",
      "Dev   Loss: 2.9983 Acc: 0.4887 F1: 0.3506(0.3490/0.3558)\n",
      "--------------------------------------------\n",
      "Epoch: 16\n",
      "Train Loss: 0.2717 Acc: 0.8442 F1: 0.8267(0.7808/0.8920)\n",
      "Dev   Loss: 3.2126 Acc: 0.4680 F1: 0.3234(0.3238/0.3264)\n",
      "--------------------------------------------\n",
      "Epoch: 17\n",
      "Train Loss: 0.1931 Acc: 0.8905 F1: 0.8826(0.8414/0.9360)\n",
      "Dev   Loss: 3.2117 Acc: 0.5095 F1: 0.3498(0.3500/0.3545)\n",
      "--------------------------------------------\n",
      "Epoch: 18\n",
      "Train Loss: 0.1095 Acc: 0.9393 F1: 0.9405(0.9166/0.9679)\n",
      "Dev   Loss: 3.7750 Acc: 0.5023 F1: 0.3359(0.3341/0.3426)\n",
      "--------------------------------------------\n",
      "Epoch: 19\n",
      "Train Loss: 0.0696 Acc: 0.9654 F1: 0.9654(0.9510/0.9808)\n",
      "Dev   Loss: 3.9437 Acc: 0.5266 F1: 0.3417(0.3510/0.3384)\n",
      "--------------------------------------------\n",
      "Epoch: 20\n",
      "Train Loss: 0.0479 Acc: 0.9790 F1: 0.9788(0.9693/0.9887)\n",
      "Dev   Loss: 4.2262 Acc: 0.5149 F1: 0.3336(0.3407/0.3353)\n",
      "--------------------------------------------\n",
      "Epoch: 21\n",
      "Train Loss: 0.0348 Acc: 0.9842 F1: 0.9834(0.9756/0.9915)\n",
      "Dev   Loss: 4.3220 Acc: 0.5122 F1: 0.3299(0.3341/0.3320)\n",
      "--------------------------------------------\n",
      "Epoch: 22\n",
      "Train Loss: 0.0285 Acc: 0.9872 F1: 0.9870(0.9818/0.9924)\n",
      "Dev   Loss: 4.5265 Acc: 0.5131 F1: 0.3304(0.3379/0.3313)\n",
      "--------------------------------------------\n",
      "Epoch: 23\n",
      "Train Loss: 0.0232 Acc: 0.9898 F1: 0.9886(0.9829/0.9944)\n",
      "Dev   Loss: 4.7183 Acc: 0.5077 F1: 0.3265(0.3478/0.3253)\n",
      "--------------------------------------------\n",
      "Epoch: 24\n",
      "Train Loss: 0.0194 Acc: 0.9903 F1: 0.9899(0.9854/0.9945)\n",
      "Dev   Loss: 4.6799 Acc: 0.5095 F1: 0.3278(0.3338/0.3279)\n",
      "--------------------------------------------\n",
      "Epoch: 25\n",
      "Train Loss: 0.0177 Acc: 0.9918 F1: 0.9913(0.9878/0.9949)\n",
      "Dev   Loss: 4.9256 Acc: 0.5095 F1: 0.3221(0.3291/0.3237)\n",
      "--------------------------------------------\n",
      "Epoch: 26\n",
      "Train Loss: 0.0160 Acc: 0.9928 F1: 0.9925(0.9893/0.9957)\n",
      "Dev   Loss: 4.9577 Acc: 0.5068 F1: 0.3215(0.3293/0.3222)\n",
      "--------------------------------------------\n",
      "Epoch: 27\n",
      "Train Loss: 0.0152 Acc: 0.9925 F1: 0.9920(0.9883/0.9957)\n",
      "Dev   Loss: 5.0699 Acc: 0.5068 F1: 0.3206(0.3282/0.3208)\n",
      "--------------------------------------------\n",
      "Epoch: 28\n",
      "Train Loss: 0.0128 Acc: 0.9934 F1: 0.9927(0.9900/0.9955)\n",
      "Dev   Loss: 5.2603 Acc: 0.5203 F1: 0.3279(0.3419/0.3254)\n",
      "--------------------------------------------\n",
      "Epoch: 29\n",
      "Train Loss: 0.0136 Acc: 0.9937 F1: 0.9935(0.9919/0.9951)\n",
      "Dev   Loss: 4.9200 Acc: 0.5086 F1: 0.3230(0.3260/0.3248)\n",
      "--------------------------------------------\n",
      "Epoch: 30\n",
      "Train Loss: 0.0131 Acc: 0.9940 F1: 0.9928(0.9891/0.9967)\n",
      "Dev   Loss: 5.0303 Acc: 0.4995 F1: 0.3266(0.3372/0.3275)\n",
      "--------------------------------------------\n",
      "Epoch: 31\n",
      "Train Loss: 0.0113 Acc: 0.9936 F1: 0.9925(0.9886/0.9965)\n",
      "Dev   Loss: 5.1887 Acc: 0.4986 F1: 0.3200(0.3242/0.3232)\n",
      "--------------------------------------------\n",
      "Epoch: 32\n",
      "Train Loss: 0.0106 Acc: 0.9932 F1: 0.9919(0.9886/0.9953)\n",
      "Dev   Loss: 5.2746 Acc: 0.5023 F1: 0.3200(0.3232/0.3230)\n",
      "--------------------------------------------\n",
      "Epoch: 33\n",
      "Train Loss: 0.0119 Acc: 0.9940 F1: 0.9944(0.9925/0.9963)\n",
      "Dev   Loss: 5.3754 Acc: 0.5122 F1: 0.3229(0.3289/0.3239)\n",
      "--------------------------------------------\n",
      "Epoch: 34\n",
      "Train Loss: 0.0101 Acc: 0.9942 F1: 0.9931(0.9901/0.9962)\n",
      "Dev   Loss: 5.5092 Acc: 0.5023 F1: 0.3166(0.3215/0.3182)\n",
      "--------------------------------------------\n",
      "Epoch: 35\n",
      "Train Loss: 0.0098 Acc: 0.9942 F1: 0.9927(0.9890/0.9966)\n",
      "Dev   Loss: 5.4818 Acc: 0.5077 F1: 0.3242(0.3419/0.3228)\n",
      "--------------------------------------------\n",
      "Epoch: 36\n",
      "Train Loss: 0.0101 Acc: 0.9948 F1: 0.9946(0.9931/0.9961)\n",
      "Dev   Loss: 5.6215 Acc: 0.5104 F1: 0.3200(0.3293/0.3211)\n",
      "--------------------------------------------\n",
      "Epoch: 37\n",
      "Train Loss: 0.0100 Acc: 0.9941 F1: 0.9932(0.9904/0.9962)\n",
      "Dev   Loss: 5.5963 Acc: 0.5140 F1: 0.3255(0.3320/0.3255)\n",
      "--------------------------------------------\n",
      "Epoch: 38\n",
      "Train Loss: 0.0096 Acc: 0.9944 F1: 0.9931(0.9897/0.9966)\n",
      "Dev   Loss: 5.5915 Acc: 0.5068 F1: 0.3282(0.3492/0.3287)\n",
      "--------------------------------------------\n",
      "Epoch: 39\n",
      "Train Loss: 0.0097 Acc: 0.9945 F1: 0.9946(0.9928/0.9963)\n",
      "Dev   Loss: 5.6502 Acc: 0.5032 F1: 0.3167(0.3223/0.3191)\n",
      "--------------------------------------------\n",
      "Epoch: 40\n",
      "Train Loss: 0.0087 Acc: 0.9943 F1: 0.9931(0.9899/0.9963)\n",
      "Dev   Loss: 5.7137 Acc: 0.5113 F1: 0.3267(0.3454/0.3249)\n",
      "--------------------------------------------\n",
      "Epoch: 41\n",
      "Train Loss: 0.0087 Acc: 0.9944 F1: 0.9933(0.9903/0.9963)\n",
      "Dev   Loss: 5.8344 Acc: 0.5104 F1: 0.3214(0.3442/0.3196)\n",
      "--------------------------------------------\n",
      "Epoch: 42\n",
      "Train Loss: 0.0080 Acc: 0.9942 F1: 0.9930(0.9899/0.9962)\n",
      "Dev   Loss: 5.8698 Acc: 0.5140 F1: 0.3266(0.3339/0.3264)\n",
      "--------------------------------------------\n",
      "Epoch: 43\n",
      "Train Loss: 0.0079 Acc: 0.9939 F1: 0.9940(0.9925/0.9956)\n",
      "Dev   Loss: 5.6665 Acc: 0.5023 F1: 0.3226(0.3307/0.3232)\n",
      "--------------------------------------------\n",
      "Epoch: 44\n",
      "Train Loss: 0.0088 Acc: 0.9945 F1: 0.9932(0.9899/0.9966)\n",
      "Dev   Loss: 5.8796 Acc: 0.5113 F1: 0.3246(0.3461/0.3233)\n",
      "--------------------------------------------\n",
      "Epoch: 45\n",
      "Train Loss: 0.0083 Acc: 0.9942 F1: 0.9927(0.9894/0.9960)\n",
      "Dev   Loss: 5.9152 Acc: 0.5176 F1: 0.3265(0.3344/0.3261)\n",
      "--------------------------------------------\n",
      "Epoch: 46\n",
      "Train Loss: 0.0085 Acc: 0.9945 F1: 0.9932(0.9895/0.9969)\n",
      "Dev   Loss: 5.8599 Acc: 0.5050 F1: 0.3283(0.3381/0.3295)\n",
      "--------------------------------------------\n",
      "Epoch: 47\n",
      "Train Loss: 0.0079 Acc: 0.9948 F1: 0.9934(0.9900/0.9969)\n",
      "Dev   Loss: 5.9250 Acc: 0.5149 F1: 0.3271(0.3338/0.3272)\n",
      "--------------------------------------------\n",
      "Epoch: 48\n",
      "Train Loss: 0.0080 Acc: 0.9944 F1: 0.9930(0.9897/0.9964)\n",
      "Dev   Loss: 5.8901 Acc: 0.5104 F1: 0.3300(0.3455/0.3295)\n",
      "--------------------------------------------\n",
      "Epoch: 49\n",
      "Train Loss: 0.0079 Acc: 0.9945 F1: 0.9930(0.9897/0.9963)\n",
      "Dev   Loss: 6.1034 Acc: 0.5077 F1: 0.3135(0.3196/0.3159)\n",
      "--------------------------------------------\n",
      "Epoch: 50\n",
      "Train Loss: 0.0074 Acc: 0.9949 F1: 0.9941(0.9913/0.9968)\n",
      "Dev   Loss: 6.0706 Acc: 0.5113 F1: 0.3161(0.3228/0.3164)\n",
      "--------------------------------------------\n",
      "Epoch: 51\n",
      "Train Loss: 0.0077 Acc: 0.9946 F1: 0.9932(0.9900/0.9965)\n",
      "Dev   Loss: 6.1785 Acc: 0.5158 F1: 0.3186(0.3275/0.3187)\n",
      "--------------------------------------------\n",
      "Epoch: 52\n",
      "Train Loss: 0.0076 Acc: 0.9948 F1: 0.9934(0.9897/0.9972)\n",
      "Dev   Loss: 6.1324 Acc: 0.5077 F1: 0.3122(0.3181/0.3132)\n",
      "--------------------------------------------\n",
      "Epoch: 53\n",
      "Train Loss: 0.0079 Acc: 0.9945 F1: 0.9939(0.9915/0.9963)\n",
      "Dev   Loss: 6.1143 Acc: 0.5050 F1: 0.3169(0.3322/0.3152)\n",
      "--------------------------------------------\n",
      "Epoch: 54\n",
      "Train Loss: 0.0074 Acc: 0.9946 F1: 0.9930(0.9897/0.9965)\n",
      "Dev   Loss: 6.1968 Acc: 0.5086 F1: 0.3202(0.3362/0.3205)\n",
      "--------------------------------------------\n",
      "Epoch: 55\n",
      "Train Loss: 0.0075 Acc: 0.9948 F1: 0.9932(0.9899/0.9966)\n",
      "Dev   Loss: 6.1607 Acc: 0.4995 F1: 0.3225(0.3427/0.3225)\n",
      "--------------------------------------------\n",
      "Epoch: 56\n",
      "Train Loss: 0.0076 Acc: 0.9945 F1: 0.9938(0.9911/0.9966)\n",
      "Dev   Loss: 6.0832 Acc: 0.5041 F1: 0.3248(0.3340/0.3259)\n",
      "--------------------------------------------\n",
      "Epoch: 57\n",
      "Train Loss: 0.0075 Acc: 0.9944 F1: 0.9930(0.9896/0.9966)\n",
      "Dev   Loss: 6.2350 Acc: 0.4986 F1: 0.3122(0.3174/0.3141)\n",
      "--------------------------------------------\n",
      "Epoch: 58\n",
      "Train Loss: 0.0071 Acc: 0.9949 F1: 0.9935(0.9899/0.9971)\n",
      "Dev   Loss: 6.2529 Acc: 0.5077 F1: 0.3172(0.3337/0.3173)\n",
      "--------------------------------------------\n",
      "Epoch: 59\n",
      "Train Loss: 0.0070 Acc: 0.9947 F1: 0.9933(0.9902/0.9965)\n",
      "Dev   Loss: 6.4362 Acc: 0.5095 F1: 0.3145(0.3209/0.3151)\n",
      "--------------------------------------------\n",
      "Epoch: 60\n",
      "Train Loss: 0.0076 Acc: 0.9942 F1: 0.9936(0.9912/0.9961)\n",
      "Dev   Loss: 6.0847 Acc: 0.5050 F1: 0.3188(0.3217/0.3211)\n",
      "--------------------------------------------\n",
      "Epoch: 61\n",
      "Train Loss: 0.0074 Acc: 0.9949 F1: 0.9934(0.9898/0.9971)\n",
      "Dev   Loss: 6.4750 Acc: 0.5086 F1: 0.3095(0.3203/0.3102)\n",
      "--------------------------------------------\n",
      "Epoch: 62\n",
      "Train Loss: 0.0075 Acc: 0.9947 F1: 0.9933(0.9896/0.9970)\n",
      "Dev   Loss: 6.5898 Acc: 0.5077 F1: 0.3133(0.3420/0.3118)\n",
      "--------------------------------------------\n",
      "Epoch: 63\n",
      "Train Loss: 0.0076 Acc: 0.9946 F1: 0.9931(0.9901/0.9963)\n",
      "Dev   Loss: 6.4020 Acc: 0.5113 F1: 0.3203(0.3396/0.3198)\n",
      "--------------------------------------------\n",
      "Epoch: 64\n",
      "Train Loss: 0.0075 Acc: 0.9947 F1: 0.9933(0.9897/0.9970)\n",
      "Dev   Loss: 6.4594 Acc: 0.5104 F1: 0.3137(0.3192/0.3149)\n",
      "--------------------------------------------\n",
      "Epoch: 65\n",
      "Train Loss: 0.0076 Acc: 0.9947 F1: 0.9933(0.9897/0.9970)\n",
      "Dev   Loss: 6.5902 Acc: 0.5122 F1: 0.3135(0.3243/0.3123)\n",
      "--------------------------------------------\n",
      "Epoch: 66\n",
      "Train Loss: 0.0080 Acc: 0.9946 F1: 0.9940(0.9918/0.9963)\n",
      "Dev   Loss: 6.4880 Acc: 0.4995 F1: 0.3098(0.3148/0.3109)\n",
      "--------------------------------------------\n",
      "Epoch: 67\n",
      "Train Loss: 0.1526 Acc: 0.9344 F1: 0.9201(0.8964/0.9474)\n",
      "Dev   Loss: 3.3603 Acc: 0.3832 F1: 0.2834(0.3012/0.3161)\n",
      "--------------------------------------------\n",
      "Epoch: 68\n",
      "Train Loss: 1.2959 Acc: 0.4884 F1: 0.4231(0.4209/0.5156)\n",
      "Dev   Loss: 1.9284 Acc: 0.3327 F1: 0.2782(0.3200/0.3204)\n",
      "--------------------------------------------\n",
      "Epoch: 69\n",
      "Train Loss: 0.8255 Acc: 0.6107 F1: 0.5604(0.5325/0.6646)\n",
      "Dev   Loss: 2.3350 Acc: 0.3859 F1: 0.2917(0.3017/0.3205)\n",
      "--------------------------------------------\n",
      "Epoch: 70\n",
      "Train Loss: 0.4022 Acc: 0.7669 F1: 0.7521(0.7048/0.8371)\n",
      "Dev   Loss: 2.7928 Acc: 0.4391 F1: 0.3345(0.3317/0.3528)\n",
      "--------------------------------------------\n",
      "Epoch: 71\n",
      "Train Loss: 0.1995 Acc: 0.8746 F1: 0.8742(0.8347/0.9265)\n",
      "Dev   Loss: 3.4114 Acc: 0.5041 F1: 0.3530(0.3615/0.3515)\n",
      "--------------------------------------------\n",
      "Epoch: 72\n",
      "Train Loss: 0.0881 Acc: 0.9534 F1: 0.9526(0.9324/0.9756)\n",
      "Dev   Loss: 3.9701 Acc: 0.5176 F1: 0.3526(0.3733/0.3475)\n",
      "--------------------------------------------\n",
      "Epoch: 73\n",
      "Train Loss: 0.0470 Acc: 0.9782 F1: 0.9790(0.9693/0.9892)\n",
      "Dev   Loss: 4.2495 Acc: 0.5023 F1: 0.3332(0.3528/0.3307)\n",
      "--------------------------------------------\n",
      "Epoch: 74\n",
      "Train Loss: 0.0344 Acc: 0.9847 F1: 0.9843(0.9780/0.9908)\n",
      "Dev   Loss: 4.4664 Acc: 0.5158 F1: 0.3386(0.3679/0.3329)\n",
      "--------------------------------------------\n",
      "Epoch: 75\n",
      "Train Loss: 0.0794 Acc: 0.9579 F1: 0.9523(0.9345/0.9722)\n",
      "Dev   Loss: 3.9081 Acc: 0.4698 F1: 0.3327(0.3402/0.3340)\n",
      "--------------------------------------------\n",
      "Epoch: 76\n",
      "Train Loss: 0.0787 Acc: 0.9556 F1: 0.9513(0.9285/0.9770)\n",
      "Dev   Loss: 4.1756 Acc: 0.4932 F1: 0.3233(0.3355/0.3199)\n",
      "--------------------------------------------\n",
      "Epoch: 77\n",
      "Train Loss: 0.0376 Acc: 0.9837 F1: 0.9828(0.9752/0.9907)\n",
      "Dev   Loss: 4.5335 Acc: 0.5194 F1: 0.3441(0.3648/0.3367)\n",
      "--------------------------------------------\n",
      "Epoch: 78\n",
      "Train Loss: 0.0210 Acc: 0.9915 F1: 0.9906(0.9866/0.9947)\n",
      "Dev   Loss: 4.6379 Acc: 0.5095 F1: 0.3314(0.3513/0.3275)\n",
      "--------------------------------------------\n",
      "Epoch: 79\n",
      "Train Loss: 0.0145 Acc: 0.9928 F1: 0.9914(0.9872/0.9956)\n",
      "Dev   Loss: 4.7899 Acc: 0.5140 F1: 0.3364(0.3578/0.3312)\n",
      "--------------------------------------------\n",
      "Epoch: 80\n",
      "Train Loss: 0.0132 Acc: 0.9940 F1: 0.9943(0.9923/0.9964)\n",
      "Dev   Loss: 4.9160 Acc: 0.5131 F1: 0.3301(0.3553/0.3240)\n",
      "--------------------------------------------\n",
      "Epoch: 81\n",
      "Train Loss: 0.0122 Acc: 0.9936 F1: 0.9924(0.9885/0.9963)\n",
      "Dev   Loss: 4.9733 Acc: 0.5095 F1: 0.3302(0.3499/0.3260)\n",
      "--------------------------------------------\n",
      "Epoch: 82\n",
      "Train Loss: 0.0106 Acc: 0.9944 F1: 0.9930(0.9890/0.9971)\n",
      "Dev   Loss: 5.0122 Acc: 0.5104 F1: 0.3321(0.3527/0.3279)\n",
      "--------------------------------------------\n",
      "Epoch: 83\n",
      "Train Loss: 0.0097 Acc: 0.9944 F1: 0.9929(0.9897/0.9963)\n",
      "Dev   Loss: 5.0883 Acc: 0.5104 F1: 0.3307(0.3516/0.3267)\n",
      "--------------------------------------------\n",
      "Epoch: 84\n",
      "Train Loss: 0.0093 Acc: 0.9942 F1: 0.9929(0.9895/0.9964)\n",
      "Dev   Loss: 5.1741 Acc: 0.5095 F1: 0.3251(0.3471/0.3200)\n",
      "--------------------------------------------\n",
      "Epoch: 85\n",
      "Train Loss: 0.0092 Acc: 0.9945 F1: 0.9937(0.9910/0.9965)\n",
      "Dev   Loss: 5.1893 Acc: 0.5104 F1: 0.3230(0.3450/0.3184)\n",
      "--------------------------------------------\n",
      "Epoch: 86\n",
      "Train Loss: 0.0088 Acc: 0.9940 F1: 0.9927(0.9891/0.9964)\n",
      "Dev   Loss: 5.2049 Acc: 0.5122 F1: 0.3272(0.3459/0.3224)\n",
      "--------------------------------------------\n",
      "Epoch: 87\n",
      "Train Loss: 0.0090 Acc: 0.9947 F1: 0.9930(0.9896/0.9966)\n",
      "Dev   Loss: 5.2901 Acc: 0.5149 F1: 0.3264(0.3494/0.3201)\n",
      "--------------------------------------------\n",
      "Epoch: 88\n",
      "Train Loss: 0.0089 Acc: 0.9942 F1: 0.9936(0.9911/0.9962)\n",
      "Dev   Loss: 5.3187 Acc: 0.5050 F1: 0.3182(0.3420/0.3136)\n",
      "--------------------------------------------\n",
      "Epoch: 89\n",
      "Train Loss: 0.0088 Acc: 0.9945 F1: 0.9931(0.9897/0.9967)\n",
      "Dev   Loss: 5.3169 Acc: 0.5077 F1: 0.3258(0.3451/0.3224)\n",
      "--------------------------------------------\n",
      "Epoch: 90\n",
      "Train Loss: 0.0090 Acc: 0.9945 F1: 0.9932(0.9896/0.9969)\n",
      "Dev   Loss: 5.3673 Acc: 0.5095 F1: 0.3233(0.3469/0.3178)\n",
      "--------------------------------------------\n",
      "Epoch: 91\n",
      "Train Loss: 0.0080 Acc: 0.9946 F1: 0.9940(0.9914/0.9966)\n",
      "Dev   Loss: 5.4186 Acc: 0.5077 F1: 0.3215(0.3449/0.3168)\n",
      "--------------------------------------------\n",
      "Epoch: 92\n",
      "Train Loss: 0.0087 Acc: 0.9947 F1: 0.9933(0.9896/0.9970)\n",
      "Dev   Loss: 5.4693 Acc: 0.5131 F1: 0.3218(0.3472/0.3164)\n",
      "--------------------------------------------\n",
      "Epoch: 93\n",
      "Train Loss: 0.0085 Acc: 0.9943 F1: 0.9931(0.9901/0.9961)\n",
      "Dev   Loss: 5.4571 Acc: 0.5095 F1: 0.3257(0.3493/0.3204)\n",
      "--------------------------------------------\n",
      "Epoch: 94\n",
      "Train Loss: 0.0078 Acc: 0.9947 F1: 0.9931(0.9897/0.9967)\n",
      "Dev   Loss: 5.5092 Acc: 0.5086 F1: 0.3220(0.3439/0.3169)\n",
      "--------------------------------------------\n",
      "Epoch: 95\n",
      "Train Loss: 0.0072 Acc: 0.9947 F1: 0.9933(0.9898/0.9969)\n",
      "Dev   Loss: 5.4990 Acc: 0.5059 F1: 0.3234(0.3425/0.3198)\n",
      "--------------------------------------------\n",
      "Epoch: 96\n",
      "Train Loss: 0.0079 Acc: 0.9947 F1: 0.9933(0.9896/0.9971)\n",
      "Dev   Loss: 5.6045 Acc: 0.5086 F1: 0.3197(0.3412/0.3159)\n",
      "--------------------------------------------\n",
      "Epoch: 97\n",
      "Train Loss: 0.0074 Acc: 0.9945 F1: 0.9929(0.9895/0.9965)\n",
      "Dev   Loss: 5.6672 Acc: 0.5140 F1: 0.3244(0.3479/0.3189)\n",
      "--------------------------------------------\n",
      "Epoch: 98\n",
      "Train Loss: 0.0079 Acc: 0.9944 F1: 0.9934(0.9907/0.9962)\n",
      "Dev   Loss: 5.6114 Acc: 0.5068 F1: 0.3221(0.3405/0.3189)\n",
      "--------------------------------------------\n",
      "Epoch: 99\n",
      "Train Loss: 0.0079 Acc: 0.9948 F1: 0.9944(0.9920/0.9968)\n",
      "Dev   Loss: 5.6439 Acc: 0.5122 F1: 0.3235(0.3440/0.3186)\n",
      "--------------------------------------------\n",
      "Test   Loss: 2.5963 Acc: 0.4785 F1: 0.3286(0.3238/0.3482)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66      1256\n",
      "           1       0.31      0.32      0.32       345\n",
      "           2       0.13      0.16      0.15        68\n",
      "           3       0.06      0.14      0.08        50\n",
      "           4       0.47      0.46      0.46       402\n",
      "           5       0.19      0.21      0.20       208\n",
      "           6       0.36      0.56      0.44       281\n",
      "\n",
      "    accuracy                           0.48      2610\n",
      "   macro avg       0.32      0.35      0.33      2610\n",
      "weighted avg       0.53      0.48      0.50      2610\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "      Predicted\n",
      "       0 1 2 3 4 5 6\n",
      "True\n",
      "0      [735  94  32  51  86 122 136]\n",
      "1      [ 58 112  18  22  56  25  54]\n",
      "2      [16 12 11  9  1  9 10]\n",
      "3      [13  8  2  7  6  5  9]\n",
      "4      [ 74  63   7   6 183  23  46]\n",
      "5      [60 27  9 22 24 44 22]\n",
      "6      [ 28  44   4   9  32   7 157]\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "if isTrain:\n",
    "    # train and dev data set\n",
    "    train_dataset = EDCDataset(train_embeddings, train_label)\n",
    "    dev_dataset = EDCDataset(dev_embeddings, dev_label)\n",
    "    # train and dev data loader\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn=collate_data, shuffle=True)\n",
    "    dev_data_loader = DataLoader(dataset=dev_dataset, batch_size=batch_size, collate_fn=collate_data, shuffle=False)\n",
    "\n",
    "# test data set and data loader\n",
    "test_dataset = EDCDataset(test_embeddings, test_label)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=collate_data, shuffle=False)\n",
    "\n",
    "# build model\n",
    "model = Model(embedding_size, lstm_hidden_size, hidden_layer_size).to(DEVICE)\n",
    "\n",
    "# Use weighted cross-entropy loss\n",
    "loss_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "if isTrain:\n",
    "    best_f1 = 0\n",
    "    for i in range(epochs):\n",
    "        print(f'Epoch: {i}')\n",
    "        train_loss, train_acc, train_p, train_r, train_f1, _ = train_model(model, train_data_loader, loss_criterion, optimizer)\n",
    "        dev_loss, dev_acc, dev_p, dev_r, dev_f1, _ = evaluate_model(model, dev_data_loader, loss_criterion)\n",
    "        print(\"Train Loss: {:.4f} Acc: {:.4f} F1: {:.4f}({:.4f}/{:.4f})\".format(train_loss, train_acc, train_f1, train_p, train_r))\n",
    "        print(\"Dev   Loss: {:.4f} Acc: {:.4f} F1: {:.4f}({:.4f}/{:.4f})\".format(dev_loss, dev_acc, dev_f1, dev_p, dev_r))\n",
    "        if dev_f1 > best_f1:\n",
    "            best_f1 = dev_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "        print('--------------------------------------------')\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "test_loss, test_accuracy, test_percision, test_recall, test_f1, result_report = evaluate_model(model, test_data_loader, loss_criterion)\n",
    "print(\"Test   Loss: {:.4f} Acc: {:.4f} F1: {:.4f}({:.4f}/{:.4f})\".format(test_loss, test_accuracy, test_f1, test_percision, test_recall))\n",
    "print(result_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (feature_extractor): FeatureExtraction(\n",
       "    (bilstm): LSTM(300, 500, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (emotion_detector): EmotionDetection(\n",
       "    (global_state_gru): GRUCell(1000, 1000)\n",
       "    (party_state_gru): GRUCell(1000, 1000)\n",
       "    (emotion_state_gru): GRUCell(1000, 512)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = Model(embedding_size, lstm_hidden_size, hidden_layer_size)\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=DEVICE))\n",
    "model.eval()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotions: [4 6 0]\n"
     ]
    }
   ],
   "source": [
    "def predict_emotions(conversation):\n",
    "    # Tokenize the conversation\n",
    "    conversation_tokens = []\n",
    "    for sent in conversation:\n",
    "        tokens = [pretrained_wv[word] for word in sent]\n",
    "        conversation_tokens.append(torch.stack(tokens).to(DEVICE))\n",
    "\n",
    "    # Convert to the required format for input to the model\n",
    "    packed_input = pack_sequence(conversation_tokens, enforce_sorted=False)\n",
    "\n",
    "    # Pass the input through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model([packed_input])\n",
    "\n",
    "    # Get the predicted emotions\n",
    "    predicted_emotions = torch.argmax(outputs, dim=-1).cpu().numpy()[0]\n",
    "    return predicted_emotions\n",
    "\n",
    "\n",
    "# Example conversation\n",
    "conversation = [\n",
    "    [\"I\", \"am\", \"happy\", \".\"],\n",
    "    [\"Why\", \"are\", \"you\", \"happy\", \"?\"],\n",
    "    [\"Because\", \"I\", \"got\", \"a\", \"promotion\", \".\"]\n",
    "]\n",
    "\n",
    "predicted_emotions = predict_emotions(conversation)\n",
    "print(\"Predicted Emotions:\", predicted_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotions: [4 6 5]\n"
     ]
    }
   ],
   "source": [
    "def predict_emotions(sentences):\n",
    "\n",
    "    # Tokenize each sentence into words and convert to embeddings\n",
    "    conversation_tokens = []\n",
    "    for sent in sentences:\n",
    "        words = sent.split()\n",
    "        tokens = [pretrained_wv[word] for word in words]\n",
    "        conversation_tokens.append(torch.stack(tokens).to(DEVICE))\n",
    "\n",
    "    # Convert to the required format for input to the model\n",
    "    packed_input = pack_sequence(conversation_tokens, enforce_sorted=False)\n",
    "\n",
    "    # Pass the input through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model([packed_input])\n",
    "\n",
    "    # Get the predicted emotions\n",
    "    predicted_emotions = torch.argmax(outputs, dim=-1).cpu().numpy()[0]\n",
    "    return predicted_emotions\n",
    "\n",
    "\n",
    "# Example conversation string\n",
    "sentences = [\n",
    "    'I am happy .',\n",
    "    'Why are you happy ?',\n",
    "    'Why are you happy ?'\n",
    "]\n",
    "# conversation_str = \"I am happy. Why are you happy? Because I got a promotion.\"\n",
    "\n",
    "predicted_emotions = predict_emotions(sentences)\n",
    "print(\"Predicted Emotions:\", predicted_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping of classes to emotions\n",
    "emotion_map = {\n",
    "    0: 'neutral',\n",
    "    1: 'anger',\n",
    "    2: 'disgust',\n",
    "    3: 'fear',\n",
    "    4: 'joy',\n",
    "    5: 'sadness',\n",
    "    6: 'surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.2617, -0.0664, -2.4318, -1.4148,  2.6280,  1.6258, -2.2537],\n",
      "         [ 0.1416,  0.8855, -5.5360,  0.2731,  0.5914,  0.5944,  3.1816],\n",
      "         [ 0.6228,  0.3405, -4.0734, -0.7919,  0.8926,  3.3468, -0.7187]]],\n",
      "       device='cuda:0')\n",
      "Predicted Emotions: ['joy', 'surprise', 'sadness']\n",
      "Predicted Class Probabilities:\n",
      "neutral: 0.3211 0.0313 0.0029 0.0081 0.4631 0.1700 0.0035 \n",
      "anger: 0.0353 0.0744 0.0001 0.0403 0.0554 0.0556 0.7389 \n",
      "disgust: 0.0531 0.0401 0.0005 0.0129 0.0696 0.8099 0.0139 \n",
      "tensor([[[-0.6197,  1.5060, -2.9851,  1.5994, -0.6188,  2.0616, -0.6065],\n",
      "         [-0.9184,  3.0051, -3.2529,  2.6730,  0.3632,  0.3536, -0.8351],\n",
      "         [ 1.4061,  3.2483, -3.1160,  0.8702,  1.4056,  0.1369, -3.4581],\n",
      "         [ 0.7864,  2.8315, -0.8985,  1.1344,  1.1374, -1.0997, -3.0764],\n",
      "         [ 0.9730, -0.5880,  3.8287, -1.4239, -1.3285, -2.2773, -0.9447],\n",
      "         [ 1.2681, -1.4404, -0.3274, -3.0682, -0.2527,  3.3148, -1.2271],\n",
      "         [ 1.4988,  0.7727, -0.7095, -2.5467,  2.1383, -2.4353,  0.8481],\n",
      "         [ 1.6780, -0.2133, -1.1374, -2.5588,  0.6968,  1.2874, -2.1038],\n",
      "         [-0.4351,  0.8572,  2.7445, -0.9747, -0.0624, -0.8174, -3.5126],\n",
      "         [ 0.3252,  0.8776, -0.6235, -1.2249,  0.5839,  0.3709, -1.8708],\n",
      "         [-0.0430,  2.2613, -3.4842, -1.0098,  1.9962,  3.0002, -3.1916]]],\n",
      "       device='cuda:0')\n",
      "Predicted Emotions: ['sadness', 'anger', 'anger', 'anger', 'disgust', 'sadness', 'joy', 'neutral', 'disgust', 'anger', 'sadness']\n"
     ]
    }
   ],
   "source": [
    "def predict_emotions(sentences):\n",
    "    # Tokenize each sentence into words and convert to embeddings\n",
    "    conversation_tokens = []\n",
    "    for sent in sentences:\n",
    "        words = sent.split()\n",
    "        tokens = [pretrained_wv[word] for word in words]\n",
    "        conversation_tokens.append(torch.stack(tokens).to(DEVICE))\n",
    "\n",
    "    # Convert to the required format for input to the model\n",
    "    packed_input = pack_sequence(conversation_tokens, enforce_sorted=False)\n",
    "\n",
    "    # Pass the input through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model([packed_input])\n",
    "        print(outputs)\n",
    "\n",
    "    # Get the predicted class probabilities\n",
    "    predicted_probs = torch.softmax(outputs, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "    # Get the predicted classes\n",
    "    predicted_classes = torch.argmax(outputs, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "    # Map predicted classes to emotions\n",
    "    predicted_emotions = [emotion_map[class_] for class_ in predicted_classes]\n",
    "\n",
    "    return predicted_emotions, predicted_probs\n",
    "\n",
    "\n",
    "# Example conversation sentences\n",
    "sentences = [\n",
    "    'I am happy .',\n",
    "    'Why are you happy ?',\n",
    "    'Why are you happy ?'\n",
    "]\n",
    "\n",
    "# Predict emotions and get class probabilities\n",
    "predicted_emotions, predicted_probs = predict_emotions(sentences)\n",
    "\n",
    "print(\"Predicted Emotions:\", predicted_emotions)\n",
    "print(\"Predicted Class Probabilities:\")\n",
    "for class_, prob in enumerate(predicted_probs):\n",
    "    print(f\"{emotion_map[class_]}:\", end=\" \")\n",
    "    for p in prob:\n",
    "        print(f\"{p:.4f}\", end=\" \")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Example conversation sentences\n",
    "sentences = [\n",
    "    \"So, can you think of another case you're working on another family different than the one that we've initially talked about? Where you've made a decision that seemed like was fairly clear caught like one you would have made before and yet you're, you're thinking about it replaying it?\",\n",
    "    \"Yeah, I have this case. You know recently where it's a single dad, the mom passed away and I go in and check on him and his son, you You know, things are going well, but, you know, I think the dad has a hard time so it's not like it was before when the mom was there. Not that I wasn't there before that but you can just tell that like, things are a little different. But you know, obviously, my decision is that things are going well for the kid, you know, they're gonna he's gonna stay there. Dad is stable, but I just worried like, is the dad under too much stress? Is he really taking care of the kid as good as you know, what if he's just cleaning up the house and doing the right things on there while I'm not there? You know, does he have the energy to take care of his kid? Or is everything really the way I it appears? Or is there more going on? I just don't know.\",\n",
    "    \"Right. So you're handling it to the best of your ability. But there's still these these thoughts that are coming out. Kind of encouraging you to second guess your judgment?\",\n",
    "    \"Yeah. And it's like, I can't let it go. Like, I saw him like two weeks ago. And I still wonder if I have other cases like that. It's like, they're all running through my head. And I have these thoughts like, Did I do the right thing? Can I do the right thing?\",\n",
    "    \"Maybe what if, what if the worst happens?\",\n",
    "    \"And I didn't see it. Like, what if something terrible happens? And I should have known better.\",\n",
    "    \"So it speaks back to your competency as a professional again. So that's, that seems to be court this. I think Here are several things you talk about seem to connect back to. Are you capable to be in this field? And should you be trusted?\",\n",
    "    \"Yeah, definitely.\",\n",
    "    \"So coming back to thinking there are errors and thinking that all people make. And when these errors become repetitive and you can kind of see them applied in more than one areas of his life. We refer to that as a cognitive distortion. Okay? It's not bad or good. It's just how people think. It's just patterns that people fall into. And there are several different cognitive distortions, there's several patterns that we kind of see. come up often in this work, right as a counselor, wondering, in the situation where you're thinking, the worst possible outcome is unbearable, or likely or both. If you may be really focusing and emphasizing on that, to the exclusion of other evidence that suggests you've made a good decision. I see you're really focused on the negative outcome, the worst possible and maybe even unlikely outcome. And maybe not weighing all the evidence with the same weight, like you're putting more weight on the negative pay, that kind of makes sense.\",\n",
    "    \"Yeah. I mean, I think that that's probably true. Because before I felt fine, and now I just feel like everything's falling apart and not that much has changed. And so it kind of makes me think that that's probably what's going on, but I don't know how to change that.\",\n",
    "    \"This is frustrating for you. Yeah. The self doubt is worrying.\"\n",
    "]\n",
    "\n",
    "# Predict emotions and get class probabilities\n",
    "predicted_emotions, predicted_probs = predict_emotions(sentences)\n",
    "\n",
    "print(\"Predicted Emotions:\", predicted_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess single dialogue\n",
    "def preprocess(dialogue: List[str], clean: Callable[[str], List[str]], word2vec: Callable[[str], torch.Tensor]) -> torch.Tensor:\n",
    "    '''\n",
    "    Preprocess a single dialogue.\n",
    "    :param dialogue: The dialogue to preprocess.\n",
    "    :type dialogue: List[str]\n",
    "    :param clean: The cleaning function.\n",
    "    :type clean: Callable[[str], List[str]]\n",
    "    :param word2vec: The word to vector function.\n",
    "    :type word2vec: Callable[[str], torch.Tensor]\n",
    "    :return: The preprocessed dialogue.\n",
    "    :rtype: torch.Tensor\n",
    "    '''\n",
    "    # Tokenize each sentence into words and convert to embeddings\n",
    "    conversation_tokens = []\n",
    "    for sentence in dialogue:\n",
    "        words = clean(sentence)\n",
    "        tokens = [word2vec(word) for word in words]\n",
    "        conversation_tokens.append(torch.stack(tokens).to(DEVICE))\n",
    "\n",
    "    # Convert to the required format for input to the model\n",
    "    packed_input = pack_sequence(conversation_tokens, enforce_sorted=False)\n",
    "    return packed_input\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_detection(dialogue: List[str], model: nn.Module) -> Tuple[List[str], List[Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Predict the class of the dialogue using the model.\n",
    "\n",
    "    Args:\n",
    "        dialogue (List[str]): The dialogue, represented as a list of sentences.\n",
    "        model (nn.Module): The model.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[Dict[str, float]]]: The names of the classes with the highest probability for each sentence and a list of dictionaries mapping class names to probabilities for each sentence.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Preprocess the dialogue to get the input data\n",
    "    input_data =preprocess(dialogue, clean, glove)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model([input_data])\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=-1)\n",
    "\n",
    "    # Get the class with the highest probability for each sentence\n",
    "    predicted_classes = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "    # Flatten the list of lists to a single list\n",
    "    predicted_classes_flat = [i for sublist in predicted_classes.tolist() for i in sublist]\n",
    "\n",
    "    # Map the class indices to the class names\n",
    "    predicted_class_names = [emotion_map[i] for i in predicted_classes_flat]\n",
    "\n",
    "    # Flatten the list of lists to a single list\n",
    "    probabilities_flat = [prob for sublist in probabilities.tolist() for prob in sublist]\n",
    "\n",
    "    # Map the probabilities to the class names for each sentence\n",
    "    class_probabilities = [{emotion_map[i]: round((prob * 100), 3) for i, prob in enumerate(sentence)} for sentence in probabilities_flat]\n",
    "\n",
    "\n",
    "    return predicted_class_names, class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hello, how are you?\n",
      "Predicted class: neutral\n",
      "\n",
      "Class probabilities:\n",
      "neutral: 65.168\n",
      "anger: 4.154\n",
      "disgust: 0.318\n",
      "fear: 2.19\n",
      "joy: 2.723\n",
      "sadness: 2.265\n",
      "surprise: 23.182\n",
      "----------------------------------------------\n",
      "Sentence: I'm good, thanks! How about you?\n",
      "Predicted class: joy\n",
      "\n",
      "Class probabilities:\n",
      "neutral: 9.584\n",
      "anger: 4.515\n",
      "disgust: 0.015\n",
      "fear: 0.063\n",
      "joy: 82.788\n",
      "sadness: 0.031\n",
      "surprise: 3.005\n",
      "----------------------------------------------\n",
      "Sentence: I'm doing well, thank you.\n",
      "Predicted class: neutral\n",
      "\n",
      "Class probabilities:\n",
      "neutral: 54.997\n",
      "anger: 1.758\n",
      "disgust: 0.068\n",
      "fear: 0.099\n",
      "joy: 42.338\n",
      "sadness: 0.693\n",
      "surprise: 0.047\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dialogue = [\"Hello, how are you?\", \"I'm good, thanks! How about you?\", \"I'm doing well, thank you.\"]\n",
    "predicted_class_names, class_probabilities = emotion_detection(dialogue, model)\n",
    "for sentence, predicted_class_name, probs in zip(dialogue, predicted_class_names, class_probabilities):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted class: {predicted_class_name}\")\n",
    "    print()\n",
    "    print(\"Class probabilities:\")\n",
    "    for class_name, probability in probs.items():\n",
    "        print(f\"{class_name}: {probability}\")\n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
