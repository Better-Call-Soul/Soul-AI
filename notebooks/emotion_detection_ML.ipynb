{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emans\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Download NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MELDDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Utterance']\n",
    "        emotion = self.data.iloc[idx]['Emotion']\n",
    "        \n",
    "        sample = {'text': text, 'emotion': emotion}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        text = sample['text']\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        # Lowercasing\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        # Removing punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        # Removing stopwords\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        # Lemmatization\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        # Removing special characters and numbers\n",
    "        tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens if token]\n",
    "        # Join tokens back into a string\n",
    "        preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "        return {'text': preprocessed_text, 'emotion': sample['emotion']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r'D:\\College\\Fourth Year\\GP\\Meld\\train_sent_emo.csv'\n",
    "meld_dataset = MELDDataset(csv_file=csv_file_path, transform=TextPreprocessor())\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(meld_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader instances for training and validation sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids for grid search\n",
    "param_grids = {\n",
    "    \"linear_svm\": {\n",
    "        'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    \"svm\": {\n",
    "        'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'classifier__kernel': ['linear', 'rbf'],\n",
    "        'classifier__gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    \"decision_tree\": {\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    \"logistic_regression\": {\n",
    "        'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    \"gradient_boosting\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.5],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a TF-IDF vectorizer\n",
    "def get_tfidf_vectorizer(k=10000):\n",
    "    return TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True,lowercase=False, max_features=k)\n",
    "\n",
    "# Define a preprocessing pipeline with feature selection\n",
    "def get_preprocessing_pipeline(vectorizer, feature_selector=None):\n",
    "    if feature_selector:\n",
    "        return Pipeline([\n",
    "            ('features', FeatureUnion([\n",
    "                ('vectorizer', vectorizer),\n",
    "                ('feature_selector', feature_selector)\n",
    "            ]))\n",
    "        ])\n",
    "    else:\n",
    "        return Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "        ])\n",
    "\n",
    "# Function to get a feature selector based on feature importances\n",
    "def get_feature_selector(k=10000):\n",
    "    return SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
    "\n",
    "# Functions to get different classifiers with specified k and class weights\n",
    "def get_linear_svm_classifier(k, class_weight=None):\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(get_tfidf_vectorizer(k))\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', LinearSVC(C=1.0, penalty='l1', max_iter=3000, dual=False, class_weight=class_weight))\n",
    "    ])\n",
    "\n",
    "def get_svm_classifier(k, class_weight=None):\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(get_tfidf_vectorizer(k))\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', SVC(kernel='rbf', probability=True, class_weight=class_weight))\n",
    "    ])\n",
    "\n",
    "def get_decision_tree_classifier(k, class_weight=None):\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(get_tfidf_vectorizer(k), get_feature_selector(k))\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=0, class_weight=class_weight))\n",
    "    ])\n",
    "\n",
    "def get_logistic_regression_classifier(k, class_weight=None):\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(get_tfidf_vectorizer(k), get_feature_selector(k))\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', LogisticRegression(random_state=0, max_iter=50, penalty='l2', class_weight=class_weight))\n",
    "    ])\n",
    "\n",
    "def get_random_forest_classifier():\n",
    "    return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "def get_gradient_boosting_classifier():\n",
    "    return GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Function to create ensemble classifier with specified k and class weights\n",
    "def ensemble_classifiers(k, class_weight=None):\n",
    "    linear_svm_classifier = get_linear_svm_classifier(k, class_weight=class_weight)\n",
    "    svm_classifier = get_svm_classifier(k, class_weight=class_weight)\n",
    "    decision_tree_classifier = get_decision_tree_classifier(k, class_weight=class_weight)\n",
    "    logistic_regression_classifier = get_logistic_regression_classifier(k, class_weight=class_weight)\n",
    "\n",
    "    return VotingClassifier(estimators=[\n",
    "        (\"linear_svm_classifier\", linear_svm_classifier),\n",
    "        (\"svm_classifier\", svm_classifier),\n",
    "        (\"decision_tree_classifier\", decision_tree_classifier),\n",
    "        (\"logistic_regression_classifier\", logistic_regression_classifier)\n",
    "    ])\n",
    "\n",
    "# Function for k-fold cross-validation\n",
    "def cross_validation(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import issparse\n",
    "# Function for grid search\n",
    "def grid_search(classifier, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Function to train and evaluate the ensemble model\n",
    "def train_and_evaluate_model2(X_train, y_train, X_val, y_val,class_weight,len_features):\n",
    "    # Define TF-IDF vectorizer and preprocessing pipeline\n",
    "    vectorizer = get_tfidf_vectorizer()\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(vectorizer)\n",
    "\n",
    "    # Preprocess the data\n",
    "    if issparse(X_train):\n",
    "        X_train_processed = X_train if isinstance(X_train, np.ndarray) else X_train.toarray()\n",
    "    else:\n",
    "        X_train_processed = preprocessing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "    if issparse(X_val):\n",
    "        X_val_processed = X_val if isinstance(X_val, np.ndarray) else X_val.toarray()\n",
    "    else:\n",
    "        X_val_processed = preprocessing_pipeline.transform(X_val)\n",
    "    # Get feature names\n",
    "    # feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        \"linear_svm\": get_linear_svm_classifier(len_features,class_weight),\n",
    "        \"svm\": get_svm_classifier(len_features,class_weight),\n",
    "        \"decision_tree\": get_decision_tree_classifier(len_features,class_weight),\n",
    "        \"logistic_regression\": get_logistic_regression_classifier(len_features,class_weight),\n",
    "        \"random_forest\": get_random_forest_classifier(),\n",
    "        \"gradient_boosting\": get_gradient_boosting_classifier()\n",
    "    }\n",
    "\n",
    "    # Train and evaluate each classifier\n",
    "    best_models = {}\n",
    "    for name, classifier in classifiers.items():\n",
    "        # Grid search for hyperparameter tuning\n",
    "        best_model = grid_search(classifier, param_grids[name], X_train_processed, y_train)\n",
    "        best_models[name] = best_model\n",
    "\n",
    "        # Evaluate model using k-fold cross-validation\n",
    "        cv_score = cross_validation(best_model, X_train_processed, y_train)\n",
    "        cv_scores[name] = cv_score\n",
    "        print(f\"{name} CV Score: {cv_score:.4f}\")\n",
    "\n",
    "    # Select the best model based on cross-validation scores\n",
    "    best_model_name = max(best_models, key=lambda k: cv_scores[k])\n",
    "    best_model = best_models[best_model_name]\n",
    "\n",
    "    # Train the best model on the entire training set\n",
    "    best_model.fit(X_train_processed, y_train)\n",
    "\n",
    "    # Evaluate the best model on the validation set\n",
    "    val_score = best_model.score(X_val_processed, y_val)\n",
    "    print(f\"Best Model Validation Score: {val_score:.4f}\")\n",
    "\n",
    "    # Feature importance analysis for interpretability\n",
    "    # if best_model_name in ['random_forest', 'gradient_boosting']:\n",
    "    #     print(f\"Feature Importance Analysis for {best_model_name}:\")\n",
    "    #     feature_importance_analysis(best_model, X_train_processed, feature_names)\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(train_dataloader, val_dataloader,class_weight,len_features):\n",
    "    # Define TF-IDF vectorizer and preprocessing pipeline\n",
    "    vectorizer = get_tfidf_vectorizer()\n",
    "    preprocessing_pipeline = get_preprocessing_pipeline(vectorizer)\n",
    "\n",
    "    # Initialize lists to store batch-wise data\n",
    "    X_train_texts = []\n",
    "    y_train_emotions = []\n",
    "    X_val_texts = []\n",
    "    y_val_emotions = []\n",
    "\n",
    "    # Iterate through training DataLoader to collect data\n",
    "    for batch in train_dataloader:\n",
    "        X_train_texts.extend(batch['text'])\n",
    "        y_train_emotions.extend(batch['emotion'])\n",
    "\n",
    "    # Iterate through validation DataLoader to collect data\n",
    "    for batch in val_dataloader:\n",
    "        X_val_texts.extend(batch['text'])\n",
    "        y_val_emotions.extend(batch['emotion'])\n",
    "\n",
    "    # Convert None values to empty strings\n",
    "    X_train_texts = [str(text) if text is not None else '' for text in X_train_texts]\n",
    "    X_val_texts = [str(text) if text is not None else '' for text in X_val_texts]\n",
    "    y_train_emotions = [str(emotion) if emotion is not None else '' for emotion in y_train_emotions]\n",
    "    y_val_emotions = [str(emotion) if emotion is not None else '' for emotion in y_val_emotions]\n",
    "\n",
    "    # Inspect the content\n",
    "    print(\"X_train_texts:\", X_train_texts[:5])\n",
    "    print(\"y_train_emotions:\", y_train_emotions[:5])\n",
    "    X_train_processed = preprocessing_pipeline.fit_transform(X_train_texts)\n",
    "    X_val_processed = preprocessing_pipeline.transform(X_val_texts)\n",
    "\n",
    "    # Call the train_and_evaluate_model function with collected data\n",
    "    best_model = train_and_evaluate_model2(X_train_texts, y_train_emotions, X_val_texts, y_val_emotions,class_weight,len_features)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_texts: ['yes uh yes friend eddie moskowitz yeah like reaffirms faith', 'ahh yes', 'hmmmm', 'forget british chippy ', 'yeah']\n",
      "y_train_emotions: ['neutral', 'neutral', 'neutral', 'sadness', 'surprise']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 445, in fit_transform\n    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2133, in fit_transform\n    X = super().fit_transform(raw_documents)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1388, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1275, in _count_vocab\n    for feature in analyze(doc):\n                   ^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 113, in _analyze\n    doc = tokenizer(doc)\n          ^^^^^^^^^^^^^^\nTypeError: expected string or bytes-like object, got 'csr_matrix'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m     29\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_features, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[84], line 40\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(train_dataloader, val_dataloader, class_weight, len_features)\u001b[0m\n\u001b[0;32m     37\u001b[0m X_val_processed \u001b[38;5;241m=\u001b[39m preprocessing_pipeline\u001b[38;5;241m.\u001b[39mtransform(X_val_texts)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Call the train_and_evaluate_model function with collected data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlen_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_model\n",
      "Cell \u001b[1;32mIn[88], line 130\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model2\u001b[1;34m(X_train, y_train, X_val, y_val, class_weight, len_features)\u001b[0m\n\u001b[0;32m    127\u001b[0m best_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, classifier \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# Grid search for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     best_models[name] \u001b[38;5;241m=\u001b[39m best_model\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Evaluate model using k-fold cross-validation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[88], line 94\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(classifier, param_grid, X_train, y_train)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrid_search\u001b[39m(classifier, param_grid, X_train, y_train):\n\u001b[0;32m     93\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(classifier, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\pipeline.py\", line 445, in fit_transform\n    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2133, in fit_transform\n    X = super().fit_transform(raw_documents)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1388, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1275, in _count_vocab\n    for feature in analyze(doc):\n                   ^^^^^^^^^^^^\n  File \"d:\\Python\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 113, in _analyze\n    doc = tokenizer(doc)\n          ^^^^^^^^^^^^^^\nTypeError: expected string or bytes-like object, got 'csr_matrix'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "num_features = len(train_dataset[0]['text'].split())\n",
    "k = min(num_features, 10000)\n",
    "\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['neutral', 'joy', 'surprise', 'anger', 'sadness', 'disgust', 'fear']\n",
    "\n",
    "# Map class labels to their corresponding indices\n",
    "class_indices = {label: index for index, label in enumerate(class_labels)}\n",
    "\n",
    "# Extract target emotions from the train_dataset\n",
    "emotions = [item['emotion'] for item in train_dataset]\n",
    "\n",
    "# Convert emotions to class indices\n",
    "class_indices_array = np.array([class_indices[emotion] for emotion in emotions])\n",
    "\n",
    "# Calculate class weights based on the inverse of class frequencies\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(class_indices_array), y=class_indices_array)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(emotions)\n",
    "\n",
    "# class_weight_dict = {class_labels[i]: weight for i, weight in enumerate(class_weights)}\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "num_features = len(train_dataset[0]['text'].split())\n",
    "k = min(num_features, 10000)\n",
    "model = train_and_evaluate_model(train_dataloader, val_dataloader,class_weight_dict,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.3064621284755513, 1: 0.8090513313759239, 2: 1.1672509494595384, 3: 1.2928328749393303, 4: 2.060598246518824, 5: 5.28505291005291, 6: 5.096301020408164}\n",
      "Validation Accuracy: 0.4850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "num_features = len(train_dataset[0]['text'].split())\n",
    "k = min(num_features, 10000)\n",
    "\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['neutral', 'joy', 'surprise', 'anger', 'sadness', 'disgust', 'fear']\n",
    "\n",
    "# Map class labels to their corresponding indices\n",
    "class_indices = {label: index for index, label in enumerate(class_labels)}\n",
    "\n",
    "# Extract target emotions from the train_dataset\n",
    "emotions = [item['emotion'] for item in train_dataset]\n",
    "\n",
    "# Convert emotions to class indices\n",
    "class_indices_array = np.array([class_indices[emotion] for emotion in emotions])\n",
    "\n",
    "# Calculate class weights based on the inverse of class frequencies\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(class_indices_array), y=class_indices_array)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(emotions)\n",
    "\n",
    "# class_weight_dict = {class_labels[i]: weight for i, weight in enumerate(class_weights)}\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "# Create a dictionary mapping class labels to class weights\n",
    "# class_weight_dict = dict(zip(class_labels, class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "\n",
    "model = ensemble_classifiers(k,class_weight = class_weight_dict)\n",
    "# Training loop\n",
    "for batch in train_dataloader:\n",
    "    texts = batch['text']\n",
    "    emotions = batch['emotion']\n",
    "    model.fit(texts, emotions)\n",
    "\n",
    "# Validation loop\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        texts = batch['text']\n",
    "        emotions = batch['emotion']\n",
    "        predicted_emotions = model.predict(texts)\n",
    "        correct += (predicted_emotions == emotions).sum().item()\n",
    "        total += len(emotions)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(msgs):\n",
    "    emotion_label = model.predict(msgs)\n",
    "    return emotion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm feeling happy today\", \"sad\"]\n",
    "predicted_emotions = predict_emotion(msgs)\n",
    "print(predicted_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
