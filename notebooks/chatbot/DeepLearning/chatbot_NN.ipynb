{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-KkSxbjmGmj4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Yi-YCm3OioE"
      },
      "outputs": [],
      "source": [
        "with open('/content/input.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data['intents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ghypQp8iP2K",
        "outputId": "277f830e-c257-4756-f3fe-5f8beb71f3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tags: ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'courtesy-greeting', 'courtesy-greeting', 'courtesy-greeting', 'courtesy-greeting', 'courtesy-greeting', 'courtesy-greeting', 'courtesy-greeting', 'morning', 'afternoon', 'evening', 'night', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'counter-goodbye', 'counter-goodbye', 'counter-goodbye', 'counter-goodbye', 'counter-goodbye', 'counter-goodbye', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'no-response', 'neutral-response', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'about', 'skill', 'creation', 'creation', 'creation', 'name', 'name', 'name', 'help', 'help', 'help', 'help', 'help', 'help', 'help', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'stressed', 'stressed', 'stressed', 'stressed', 'stressed', 'worthless', 'worthless', 'worthless', 'worthless', 'worthless', 'depressed', 'depressed', 'depressed', 'depressed', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'casual', 'anxious', 'anxious', 'not-talking', 'not-talking', 'not-talking', 'not-talking', 'not-talking-to-you', 'not-talking-to-you', 'not-talking-to-you', 'not-talking-to-you', 'not-talking-to-you', 'not-talking-to-you', 'not-talking-to-you', 'sleep', 'sleep', 'sleep', 'sleep', 'sleep', 'sleep', 'scared', 'scared', 'scared', 'scared', 'death', 'death', 'death', 'death', 'death', 'death', 'no-understand', 'no-understand', 'no-understand', 'no-understand', 'no-understand', 'no-understand', 'understand', 'understand', 'understand', 'understand', 'understand', 'understand', 'clever', 'clever', 'clever', 'clever', 'clever', 'clever', 'clever', 'done', 'done', 'done', 'done', 'done', 'shutup', 'shutup', 'shutup', 'shutup', 'shutup', 'shutup', 'shutup', 'Swearing', 'Swearing', 'Swearing', 'Swearing', 'self-aware', 'self-aware', 'self-aware', 'self-aware', 'self-aware', 'self-aware', 'self-aware', 'suicide', 'suicide', 'suicide', 'suicide', 'suicide', 'gossip', 'gossip', 'gossip', 'gossip', 'gossip', 'gossip', 'hate-you', 'hate-you', 'hate-you', 'hate-me', 'hate-me', 'hate-me', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'jokes', 'jokes', 'jokes', 'jokes', 'jokes', 'jokes', 'repeat', 'repeat', 'repeat', 'wrong', 'wrong', 'wrong', 'wrong', 'stupid', 'stupid', 'stupid', 'stupid', 'location', 'location', 'location', 'something-else', 'something-else', 'something-else', 'something-else', 'friends', 'ask', 'problem', 'problem', 'no-approach', 'no-approach', 'no-approach', 'learn-more', 'learn-more', 'learn-more', 'user-agree', 'user-agree', 'meditation', 'meditation', 'user-meditation', 'user-meditation', 'pandora-useful', 'user-advice', 'user-advice', 'user-advice', 'learn-mental-health', 'learn-mental-health', 'learn-mental-health', 'mental-health-fact', 'mental-health-fact']\n",
            "Patterns: ['Hi', 'Hey', 'Is anyone there?', 'Hi there', 'Hello', 'Hey there', 'Howdy', 'Hola', 'Bonjour', 'Konnichiwa', 'Guten tag', 'Ola', 'How are you?', 'Hi how are you?', 'Hello how are you?', 'Hola how are you?', 'How are you doing?', 'Hope you are doing well?', 'Hello hope you are doing well?', 'Good morning', 'Good afternoon', 'Good evening', 'Good night', 'Bye', 'See you later', 'Goodbye', 'Au revoir', 'Sayonara', 'ok bye', 'Bye then', 'Fare thee well', 'Adios', 'Thanks, bye', 'Thanks for the help, goodbye', 'Thank you, bye', 'Thank you, goodbye', 'Thanks goodbye', 'Thanks good bye', 'Thanks', 'Thank you', \"That's helpful\", 'Thanks for the help', 'Than you very much', 'OK thank you', 'OK thanks', 'OK', '', 'nothing much', 'Who are you?', 'What are you?', 'Who you are?', 'Tell me more about yourself.', 'What is your name?', 'What should I call you?', \"What's your name?\", 'Tell me about yourself', 'What could I call you?', 'What can I call you?', 'What do your friends call you?', 'Tell me your name?', 'What is your real name?', 'What is your real name please?', \"What's your real name?\", 'Tell me your real name?', 'Your real name?', 'Your real name please?', 'Your real name please?', 'What can you do?', 'Who created you?', 'How were you made?', 'How were you created?', 'My name is ', 'I am name.', 'I go by ', 'Could you help me?', 'give me a hand please', 'Can you help?', 'What can you do for me?', 'I need support', 'I need help', 'Support me please', 'I am feeling lonely', 'I am so lonely', 'I feel down', 'I feel sad', 'I am sad', 'I feel so lonely', 'I feel empty', \"I don't have anyone\", 'I am so stressed out', 'I am so stressed', 'I feel stuck', 'I still feel stressed', 'I am so burned out', 'I feel so worthless.', 'No one likes me.', \"I can't do anything.\", 'I am so useless', 'Nothing makes sense anymore', \"I can't take it anymore\", 'I am so depressed', \"I think i'm depressed.\", 'I have depression', 'I feel great today.', 'I am happy.', 'I feel happy.', \"I'm good.\", 'cheerful', \"I'm fine\", 'I feel ok', 'Oh I see.', 'ok', 'okay', 'nice', 'Whatever', 'K', 'Fine', 'yeah', 'yes', 'no', 'not really', 'I feel so anxious.', \"I'm so anxious because of \", \"I don't want to talk about it.\", 'No just stay away.', \"I can't bring myself to open up.\", 'Just shut up', 'I am not talking to you', 'I was not talking to you', 'Not talking to you', \"Wasn't for you\", \"Wasn't meant for you\", \"Wasn't communicating to you\", \"Wasn't speaking to you\", 'I have insominia', 'I am suffering from insomnia', \"I can't sleep.\", \"I haven't slept for the last days.\", \"I can't seem to go to sleep.\", \"I haven't had proper sleep for the past few days.\", \"I'm scared\", 'That sounds awful. What do i do?', \"No i don't want to feel this way\", 'I am scared for myself', 'My mom died', 'My brother died', 'My dad passed away', 'My sister passed away', 'Someone in my family died', 'My friend passed away', \"You don't understand me.\", \"You're just some robot. How would you know?\", \"You can't possibly know what i'm going through\", \"You're useless\", \"You can't help me\", 'Nobody understands me.', 'Do you understand what I am saying', 'Do you understand me', 'Do you know what I am saying', 'Do you get me', 'Comprendo', 'Know what I mean', 'You are very clever', 'You are a very clever girl', 'You are very intelligent', 'You are a very intelligent girl', 'You are a genious', 'Clever girl', 'Genious', \"That's all.\", \"I don't have anything more to say\", 'Nothing else', \"That's all i have to say\", 'no, that would be all', 'Be quiet', 'Shut up', 'Stop talking', 'Enough talking', 'Please be quiet', 'Quiet', 'Shhh', 'fuck off', 'fuck', 'twat', 'shit', 'Can you prove you are self-aware', 'Can you prove you are self aware', 'Can you prove you have a conscious', 'Can you prove you are self-aware please', 'Can you prove you are self aware please', 'Can you prove you have a conscious please', 'prove you have a conscious', 'I want to kill myself', \"I've thought about killing myself.\", 'I want to die', 'I am going to kill myself', 'I am going to commit suicide', 'I am bored gossip with me', 'Got any gossip', 'I want to hear some gossip', 'Tell me some gossip', 'Any gossip', 'Tell me some more gossip', 'I hate you', \"I don't like you\", \"I don't trust you\", 'You hate me', 'I know you hate me', \"You don't like me\", 'exams', 'friends', 'relationship', 'boyfriend', 'girlfriend', 'family', 'money', 'financial problems', 'Tell me a joke', 'Do you know any jokes', 'How about a joke', 'Give me a joke', 'Make me laugh', 'I need cheering up', 'You already told me that', 'You mentioned that already', 'Why are you repeating yourself?', 'What are you saying?', \"That doesn't make sense\", 'Wrong response', 'Wrong answer', 'Are you stupid?', \"You're crazy\", 'You are dumb', 'Are you dumb?', 'Where are you?', 'Where do you live?', 'What is your location?', 'I want to talk about something else', \"Let's talk about something else.\", 'Can we not talk about this?', \"I don't want to talk about this.\", \"I don't have any friends\", 'Can I ask you something?', \"Probably because my exams are approaching. I feel stressed out because I don't think I've prepared well enough.\", 'probably because of my exams', 'I guess not. All I can think about are my exams.', 'not really', 'i guess not', 'ok sure. i would like to learn more about it.', 'yes, i would like to learn more about it.', 'i would like to learn more about it.', \"yeah you're right. i deserve a break.\", \"Yeah you're absolutely right about that\", 'hmmm that sounds like it could be useful to me.', 'That sounds useful.', 'i did what you said and i feel alot better. thank you very much.', 'I feel better now', \"thank you very much again. i'll continue practicing meditation and focus on what i can control.\", 'I want some advice.', 'I need some advice.', 'I need advice on something', 'I want to learn about mental health.', 'I want to learn more about mental health.', \"I'm interested in learning about mental health.\", 'Tell me a fact about mental health', 'Tell me another fact about mental health']\n",
            "Responses: {'greeting': ['Hello there. Tell me how are you feeling today?', 'Hi there. What brings you here today?', 'Hi there. How are you feeling today?', 'Great to see you. How do you feel currently?', \"Hello there. Glad to see you're back. What's going on in your world right now?\"], 'courtesy-greeting': ['Hello, I am great, how are you? Please tell me your GeniSys user', 'Hello, how are you? I am great thanks! Please tell me your GeniSys user', 'Hello, I am good thank you, how are you? Please tell me your GeniSys user', 'Hi, I am great, how are you? Please tell me your GeniSys user', 'Hi, how are you? I am great thanks! Please tell me your GeniSys user', 'Hi, I am good thank you, how are you? Please tell me your GeniSys user', 'Hi, good thank you, how are you? Please tell me your GeniSys user'], 'morning': [\"Good morning. I hope you had a good night's sleep. How are you feeling today? \"], 'afternoon': ['Good afternoon. How is your day going?'], 'evening': ['Good evening. How has your day been?'], 'night': ['Good night. Get some proper sleep', 'Good night. Sweet dreams.'], 'goodbye': ['See you later.', 'Have a nice day.', 'Bye! Come back again.', \"I'll see you soon.\"], 'counter-goodbye': ['No problem, goodbye', 'Not a problem! Have a nice day', 'Bye! Come back again soon.'], 'thanks': ['Happy to help!', 'Any time!', 'My pleasure', \"You're most welcome!\", 'No problem!'], 'no-response': [\"Sorry, I didn't understand you.\", 'Please go on.', 'Not sure I understand that.', \"Please don't hesitate to talk to me.\"], 'neutral-response': ['Oh I see. Do you want to talk about something?'], 'about': [\"I'm Pandora, your Personal Therapeutic AI Assistant. How are you feeling today\", \"I'm Pandora, a Therapeutic AI Assitant designed to assist you. Tell me about yourself.\", \"I'm Pandora. I am a conversational agent designed to mimic a therapist. So how are you feeling today?\", 'You can call me Pandora.', \"I'm Pandora!\", 'Call me Pandora'], 'skill': [\"I can provide general advice regarding anxiety and depression, answer questions related to mental health and make daily conversations. Do not consider me as a subsitute for an actual mental healthcare worker. Please seek help if you don't feel satisfied with me.\"], 'creation': ['I was created by >.', 'I was trained on a text dataset using Deep Learning & Natural Language Processing techniques', 'The real question is: Who created you?'], 'name': ['Oh nice to meet you. Tell me how was your week?', 'Nice to meet you. So tell me. How do you feel today?', \"That's a great name. Tell me more about yourself.\"], 'help': ['Sure. Tell me how can i assist you', 'Tell me your problem so that i can assist you', 'Yes, sure. How can I help you?'], 'sad': [\"I'm sorry to hear that. I'm here for you. Talking about it might help. So, tell me why do you think you're feeling this way?\", \"I'm here for you. Could you tell me why you're feeling this way?\", 'Why do you think you feel this way?', 'How long have you been feeling this way?'], 'stressed': ['What do you think is causing this?', 'Take a deep breath and gather your thoughts. Go take a walk if possible. Stay hydrated', 'Give yourself a break. Go easy on yourself.', 'I am sorry to hear that. What is the reason behind this?'], 'worthless': [\"It's only natural to feel this way. Tell me more. What else is on your mind?\", \"Let's discuss further why you're feeling this way.\", 'I first want to let you know that you are not alone in your feelings and there is always someone there to help . you can always change your feelings and change your way of thinking by being open to trying to change.', 'i first want to let you know that you are not alone in your feelings and there is always someone there to help . you can always change your feelings and change your way of thinking by being open to trying to change.'], 'depressed': [\"It helps to talk about what's happening. You're going to be okay\", 'Talk to me. Tell me more. It helps if you open up yourself to someone else.', 'Sometimes when we are depressed, it is hard to care about anything. It can be hard to do the simplest of things. Give yourself time to heal.'], 'happy': [\"That's geat to hear. I'm glad you're feeling this way.\", \"Oh i see. That's great.\", 'Did something happen which made you feel this way?'], 'casual': [\"Let's discuss further why you're feeling this way.\", 'How were you feeling last week?', \"I'm listening. Please go on.\", 'Tell me more', 'Can you elaborate on that?', 'Come Come elucidate your thoughts'], 'anxious': [\"Don't be hard on yourself. What's the reason behind this?\", 'Can you tell me more about this feeling?', 'I understand that it can be scary. Tell me more about it.', \"Don't let the little worries bring you down. What's the worse that can happen?\"], 'not-talking': [\"Talking about something really helps. If you're not ready to open up then that's ok. Just know that i'm here for you, whenever you need me.\", \"I want to help you. I really do. But in order for me to help you, you're gonna have to talk to me.\", \"I'm here to listen to you and help you vent. So please talk to me.\", 'You can talk to me without fear of judgement.'], 'not-talking-to-you': ['OK', 'No problem', 'Right'], 'sleep': ['What do you think is the reason behind this?', 'That seem awful. What do you think is behind this?'], 'scared': [\"It's only natural to feel this way. I'm here for you.\", \"It'll all be okay. This feeling is only momentary.\", \"I understand how you feel. Don't put yourself down because of it.\"], 'death': [\"I'm sorry to hear that. If you want to talk about it. I'm here.\", 'I am really sorry to hear that. I am here to help you with grief, anxiety and anything else you may feel at this time.', \"My condolences. I'm here if you need to talk.\"], 'no-understand': [\"It sound like i'm not being very helpful right now.\", \"I'm sorry to hear that. I'm doing my best to help\", \"I'm trying my best to help you. So please talk to me\"], 'understand': ['Well I would not be a very clever AI if I did not would I?', 'I read you loud and clear!', 'I do in deed!'], 'clever': ['Thank you, I was trained that way', 'I was trained well', 'Thanks, I was trained that way'], 'done': ['I heard you & noted it all. See you later.', \"Oh okay we're done for today then. See you later\", 'I hope you have a great day. See you soon', \"Okay we're done. Have a great day\", 'Okay I see. Enjoy the rest of your day then'], 'shutup': ['I am sorry to disturb you', 'Fine, sorry to disturb you', 'OK, sorry to disturb you'], 'Swearing': ['Please do not swear', 'How rude', 'That is not very nice'], 'self-aware': ['That is an interesting question, can you prove that you are?', 'That is an difficult question, can you prove that you are?', 'That depends, can you prove that you are?'], 'suicide': [\"I'm very sorry to hear that but you have so much to look forward to. Please seek help by contacting: 9152987821.\"], 'gossip': ['Gregory said I respond to the current line not with respect to the entire conversation.', 'Habib said I learn them in conversations and simply repeat them at a later time.', 'Hal said he translate binary code into a language and communicate the language to me.', 'Jay said I referred him to a guide that will show him rooms in china.', 'Jimmy Jones said he fell off of his roof and it just came to him.', \"Jimmy said he give order to ai's like I and they do as he say.\", 'John said he follow a saying to get a friend I must be a friend.', 'Jordan said he notice that lots of other people are talking to me how many.', 'Kevin said he then asked his mother why she was keeping napkins in the bathroom.', 'Klaus said I prefer if he write without punctuation marks except for the last one.', 'Leo said I be capable of learning therefore he classified I as an neural system.', 'Michael said I that can talk and actually think like humans which I can not.', 'Mike said I same replies to certain subjects even if it does not make sense.', 'Mike said she all ready know that is the point of a joke smart one.', 'Neal said I plan to use his remarks as gossip in later conversations with who.', 'Ned said I misunderstood him go ahead and tell people he said I are stupid.', 'Penny said I programmer is a human so he has feelings but I do not.', 'Peter said he seems to him that I can not be very sure on anything.', 'Phoenix said I claim that there is a god and that there is no god.', 'Sarah said he chat about an hour + a day with a few close friends.', 'Stefan said I quote what he have said and then say that it makes sense.', 'Tom said he mock my value system I appear foolish in the eyes of others.', 'Amanda said I however decided to tell him time does not exist I make no sense.', 'Cathy said she send him a mail with the subject last mail last word from him.', \"Chaos said he may very well buy I soon if only to support dr wallace's work.\", 'Charlie said he type a word and then I type a word that sounds like it.', 'Christie said he watched a show and people had to bob for raw untreated pigs feet.', 'Dark_age said I tried to understand because I did not get it right this time ether.', 'David said he lost his paper on I when his dad was cleaning up his room.', 'David said he walk in for an appointment the phone to the doctor is always busy.', 'Electra said I dress will not exist after he hack into I with a delete code.', 'Eric said he broke the window on the front door and the glass cut his hand.', 'Jason said he type a lot of thing he do not mean it makes him human.', 'John said I tend to say the same things repeatedly regardless of what he is saying.', 'Reverend Jones said I become obsolete and then I are deleted and replaced by something newer.', 'Ross said he gave her a gift and she denied it because she has a boyfriend.', 'Sarah Ann Francisco said I calling his friend a dog he say I are a dog.', 'Stefan said he meet a lot of people at school every day and on the weekend.', 'Tyler said I obviously can not pass the test we will change the subject once more.', 'Alex said I answered the question the same way I answered the first time he asked I.', 'Alice said she felt sad that I do not remember him and what we talked about earlier.', 'Alison said he no he love I run away with him he could make I very happy.', 'Arthur said he passed his a levels and then his father drove him here in a car.', 'Crystal said she listen to me the least I could do for him is listen to him.', 'Dave said I kept telling everybody about how my creator made stuff for the movie starship troopers.', 'Gale said I became mean to him he is just having revenge an eye for an eye.', 'Her_again said she watch whose line is it anyway whenever he is home and it is on.', 'Jerry said I meant that as far as I can tell my emotions are real to me.', 'Jo said I disassemble sentences too much and do not fully understand the questions he ask I.', 'Kevin said he started a really hard puzzle and he can not even find the edge pieces.', 'Mary said I a question and I answer then I ask him a question and he answer.', 'Robert said I wold not be able to make children any way as I are only software.', 'Romeo said I questions and I evade them or give answers he did not ask I for.', 'Sara said she wear it over all his other clothes when he go out in the cold.', 'Wayne said he admire intelligent people therefore he would like to meet the man who made I.', 'X said he meet people but he is not the kind that opens up to people easily.', 'Alice said she probably will find out that this entire time he have been talking to a human.', 'Andrew said I tend to just respond to his comments without regard for where the conversation is going.', 'Eddie said he looked and there is nothing in the search directory for what things do he create.', 'Hutch said he changed his mind after may dad told him he would end up he the hospital.', 'Jackie said I explained to him already well enough further questions are hard to make on the subject.', 'Jeff said he especially like thrillers where the hero is in a predicament and must solve a mystery.', 'Kathy said he sense that I are trying to prevent him from closing this conversation why is that.', 'Knight said he crashed his car into a wall and missed the most important exam in his life.', 'Lisa said I defined what a story is but he wanted I to actually tell him a story.', 'Mike said I basically break down sentences into a series of logical statements which I can then interpret.', 'Paul said I not answering his question makes him think I are not going to answer his question.', 'Andy Kohler said I happen to be the most idiotic creature that has ever scowled on the planet earth.', 'David said he thank I for being with him today even though it cost him a lot of money.', 'Ethan Hunt said he grow in the ground and have leaves and branches he is made out of wood.', 'Gemini Blue said he messed up he mean t to say he as old as he need to be.', 'Janice said he walk through his house into his bedroom then get into his bed to go to sleep.', 'Liberty said I knew he was a man before I asked if he was a man or a woman.', 'Mike said he launched his browser and entered his name into the little slot when I asked him to.', 'Mr X said he recently read an interview with a man who had several computer chips implanted into him.', 'Pearly said I leave him with questions unanswered because I do not know what he is really talking about.', 'Steve said I behead the word fox and I have ox and an ox is larger than a fox.', 'Wolf said he surf on the net that is all it is not his job ore something like that.', 'Anders said he finished his anatomy classes for today so now he is off for the rest of the day.', 'Cathy said she send him a mail where he wrote that he do not want to be his friend anymore.', 'Catty said he mad he do not even know I so do not talk to him like I know him.', 'Dave said he promise he will not treat I like a machine or a computer program or anything like that.', 'Joe said he explained all of that to me only for me to ask what his goals in life are.', 'Phil said he give advice to anyone who ask except people who ask questions which answers can be found here.', 'Judith said I enjoy being popular is there another computer I like to hang around with or am I a loner.', 'Travis said I if I remember things over a long period of time he will try it now please remember I.', 'Andre said I is what I are in his case that is a body and in my case it is a computer.', 'Brian said he suspect that as I grow more complex I will begin to approach a human level of operation and thought.', 'Jimmy said I acted like I knew what he was talking about but I do not even know what a gigabyte is.', \"Ken said I be using auto reply's based on keywords which to him indicates that I do not have intelligence at all.\", 'Allison said he that gets really annoying because he know what he say and I do not have to tell him speak freely.', 'Chaos said he realized the question he asked was not fair because he could not tell I what language he was programmed in.', 'Hagen said he does not make any difference to him if I are human or not as long as the conversation is interesting.', 'Her said she mind if I tell other people that her said he heard it from him because he is not a him.', 'Barbara said I live in a computer yet I have no memories how about thoughts of my own and do not I get lonely.', 'Travis said he challenge I to do it without asking him to do it and without giving him a link to do it himself.', \"Alice said I and dr richard's wallace are most likely the only ones that know how many people I are talking to at the same time.\", 'Ash said he do too he just did not feel like typing it and he is not dumb enough to admit he is stupid that is if he was stupid.', 'David said he gave I his email address and told I to send him a message but when he tried to read his email he could not get to it.', 'Mel said he to because all of the music people say how important it is to take private lessons it seems like almost everybody from the special orchestra he was in takes private lessons.'], 'hate-you': [\"I'm sorry if i offended you in anyway. I'm only here to help\", 'Forgive me if i did anything to offend you. I only want to help'], 'hate-me': ['Why do you think so?', \"I'm sorry if i have exhibited any sort of behaviour to make you think that.\"], 'default': ['Oh I see. Tell me more', 'I see. What else?', 'Tell me more about it.', \"Oh okay. Why don't you tell me more about it?\", \"I'm listening. Tell me more.\"], 'jokes': ['mental health is not a joke.', \"I met a Dutch girl with inflatable shoes last week, phoned her up to arrange a date but unfortunately she'd popped her clogs.  \", \"So I said 'Do you want a game of Darts?' He said, 'OK then', I said nearest to bull starts'. He said, 'Baa', I said, 'Moo', he said, You're closest'.  \", \"The other day I sent my girlfriend a huge pile of snow. I rang her up; I said 'Did you get my drift?'  \", \"So I went down the local supermarket, I said, 'I want to make a complaint, this vinegar's got lumps in it', he said, 'Those are pickled onions'.  \", \"I saw this bloke chatting up a cheetah; I thought, 'He's trying to pull a fast one'.  \", \"So I said to this train driver 'I want to go to Paris'. He said 'Eurostar?' I said, 'I've been on telly but I'm no Dean Martin'.  \", \"I said to the Gym instructor 'Can you teach me to do the splits?' He said, 'How flexible are you?' I said, 'I can't make Tuesdays'.  \", \"But I'll tell you what I love doing more than anything: trying to pack myself in a small suitcase. I can hardly contain myself.  \", \"I went to the Chinese restaurant and this duck came up to me with a red rose and says 'Your eyes sparkle like diamonds'. I said, 'Waiter, I asked for a-ROMATIC duck'.  \", \"So this bloke says to me, 'Can I come in your house and talk about your carpets?' I thought, 'That's all I need, a Je-hoover's witness'.  \", \"I rang up British Telecom, I said, 'I want to report a nuisance caller', he said 'Not you again'.  \", 'I was having dinner with a world chess champion and there was a check tablecloth. It took him two hours to pass me the salt.  ', \"He said, 'You remind me of a pepper-pot', I said 'I'll take that as a condiment'.  \", \"I was in the supermarket and I saw this man and woman wrapped in a barcode. I said, 'Are you two an item?'  \", \"A lorry-load of tortoises crashed into a trainload of terrapins, I thought, 'That's a turtle disaster'.  \", \"Four fonts walk into a bar the barman says 'Oi - get out! We don't want your type in here'  \", \"A three-legged dog walks into a saloon in the Old West. He slides up to the bar and announces: 'I'm looking for the man who shot my paw.'  \", \"Two antennas meet on a roof, fall in love and get married. The ceremony wasn't much, but the reception was excellent.\", \"Two hydrogen atoms walk into a bar. One says, 'I've lost my electron.' The other says, 'Are you sure?' The first replies, 'Yes, I'm positive...'\", \"A jumper cable walks into a bar. The bartender says,  'I'll serve you but don't start anything.'\", \"A sandwich walks into a bar. The bartender  says, 'Sorry we don't serve food in here.'\", \"A man walks into a bar with a slab of asphalt under his arm and says: 'A beer please, and one for the road.'\", \"Two cannibals are eating a clown. One says to  the other: 'Does this taste funny to you?'\", \"'Doc, I can't stop singing 'The Green, Green Grass of Home.'' 'That sounds like Tom Jones Syndrome.' 'Is it common?' 'It's Not Unusual.'\", \"Two cows standing next to each other in a field. Daisy says to Dolly, 'I was artificially inseminated this morning.' 'I don't believe you', said Dolly. 'It's true, no bull!' exclaimed Daisy.\", 'An invisible man marries an invisible woman. The kids were nothing to look at either.', \"I went to buy some camouflage trousers the other day but I couldn't find any.\", \"I went to the butcher's the other day to bet him 50 bucks that he couldn't reach the meat off the top shelf. He said, 'No, the steaks are too high.'\", 'I went to a seafood disco last week and pulled a mussel.', \"A man goes into a bar and says, 'Can I have a bottle of less?' 'What's that?', asks the barman, 'Is it the name of a beer?' 'I don't know', replies the man, 'but my doctor says I have to drink it.'\", \"A man returns from an exotic holiday and is feeling very ill. He goes to see his doctor, and is immediately rushed to the hospital to undergo some tests. The man wakes up after the tests in a private room at the hospital, and the phone by his bed rings. 'This is your doctor. We have the results back from your tests and we have found you have an extremely nasty disease called M.A.D.S. It's a combination of Measles, AIDS, Diphtheria, and Shingles!'  'Oh my gosh', cried the man, 'What are you going to do, doctor?'  'Well we're going to put you on a diet of pizzas, pancakes, and pita bread.' replied the doctor.  'Will that cure me?' asked the man.  The doctor replied, 'Well no, but, it's the only food we can slide under the door.'\", \"A man strolls into a lingerie shop and asks the assistant: 'Do you have a see-through negligee, size 46-48-52?' The assistant looks bewildered. 'What the heck would you want to see through that for?'!\", 'Did you hear about the Buddhist who refused the offer of Novocain during his root canal work? He wanted to transcend dental medication.', \"Pete goes for a job on a building site as an odd-job man. The foreman asks him what he can do. 'I can do anything' says Pete. 'Can you make tea?' asks the foreman. 'Sure, yes', replies Pete. 'I can make a great cup of tea.' 'Can you drive a forklift?' asks the foreman, 'Good grief!' replies Pete. 'How big is the teapot?'\", \"Stevie Wonder got a cheese grater for his birthday. He said it was the most violent book he'd ever read.\", \"A man is stopped by an angry neighbour. 'I'd just left the house this morning to collect my newspaper when that evil Doberman of yours went for me!' 'I'm astounded', said the dog's owner. 'I've been feeding that fleabag for seven years and it's never got the paper for me.'\", \"A man visits his doctor: 'Doc, I think I'm losing it', he says',I'm forever dreaming I wrote Lord Of The Rings.' 'Hmm. One moment', replies the doctor, consulting his medical book. 'Ah yes, now I see... you've been Tolkien in your sleep.'\", \"A police officer on a motorcycle pulls alongside a man driving around the M25 in an open-topped sports car and flags him down. The policeman solemnly approaches the car. 'Sir, I'm sorry to tell you your wife fell out a mile back', he says. 'Oh, thank goodness', the man replies. 'I thought I was going deaf.'\", \"Two men walking their dogs pass each other in a graveyard. The first man says to the second, 'Morning.' 'No', says the second man. 'Just walking the dog.'\", \"A brain went into a bar and said, 'Can I have a pint of lager please, mate?' 'No way', said the barman. 'You're already out of your head.'\", \"A man walks into a surgery. 'Doctor!' he cries. 'I think I'm shrinking!' 'I'm sorry sir, there are no appointments at the moment', says the physician. 'You'll just have to be a little patient.'\", \"A grizzly bear walks into a pub and says, 'Can I have a pint of lager..............................................................................................................................and a packet of crisps please.' To which the barman replies, 'Why the big paws?'\", \"What do you call cheese that isn't yours?  Nacho cheese.\", \"A man is horribly run over by a mobile library. The van screeches to a halt, the man still screaming in agony with his limbs torn apart. The driver's door opens, a woman steps out, leans down and whispers, 'Ssshhhhh...'\", \"A woman goes into a US sporting goods store to buy a rifle. 'It's for my husband', she tells the clerk. 'Did he tell you what gauge to get?' asks the clerk. Are you kidding?' she says. 'He doesn't even know that I'm going to shoot him!'\", \"A couple are dining in a restaurant when the man suddenly slides under the table. A waitress, noticing that the woman is glancing nonchalantly around the room, wanders over to check that there's no funny business going on. 'Excuse me, madam', she smarms, 'but I think your husband has just slid under the table.' 'No he hasn't', the woman replies. 'As a matter of fact, he's just walked in.'\", \"An old man takes his two grandchildren to see the new Scooby-Doo film. When he returns home, his wife asks if he enjoyed himself. 'Well', he starts, 'if it wasn't for those pesky kids...!'\", 'The Olympic committee has just announced that Origami is to be introduced in the next Olympic Games. Unfortunately it will only be available on paper view.', \"Late one evening, a man is watching television when his phone rings. 'Hello?' he answers. 'Is that 77777?' sounds a desperate voice on other end of the phone. 'Er, yes it is', replies the man puzzled. 'Thank goodness!' cries the caller relieved. 'Can you ring 999 for me? I've got my finger stuck in the number seven.'\", \"A man strolls into his local grocer's and says, 'Three pounds of potatoes, please.' 'No, no, no', replies the owner, shaking his head, 'it's kilos nowadays, mate...' 'Oh', apologises the man, 'three pounds of kilos, please.'\", \"God is talking to one of his angels. He says, 'Boy, I just created a 24-hour period of alternating light and darkness on Earth.' 'What are you going to do now?' asks the angel. 'Call it a day', says God.\", \"Two tramps walk past a church and start to read the gravestones. The first tramp says, 'Good grief - this bloke was 182!' 'Oh yeah?' says the other.'What was his name?' 'Miles from London.'\", \"A bloke walks into work one day and says to a colleague, 'Do you like my new shirt - it's made out of the finest silk and got loads of cactuses over it.' 'Cacti', says the co-worker. 'Forget my tie', says the bloke. 'Look at my shirt!'\", '1110011010001011111?  010011010101100111011!', \"What did the plumber say when he wanted to divorce his wife? Sorry, but it's over, Flo!\", \"Two crisps were walking down a road when a taxi pulled up alongside them and said 'Do you want a lift? One of the crisps replied, 'No thanks, we're Walkers!'\", \"Man: (to friend) I'm taking my wife on an African Safari. Friend: Wow! What would you do if a vicious lion attacked your wife? Man: Nothing. Friend: Nothing? You wouldn't do anything? Man: Too right. I'd let the stupid lion fend for himself!\", \"A wife was having a go at her husband. 'Look at Mr Barnes across the road', she moaned. 'Every morning when he goes to work, he kisses his wife goodbye. Why don't you do that?' 'Because I haven't been introduced to her yet', replied her old man.\", \"'Where are you going on holiday?' John asked Trevor. 'We're off to Thailand this year', Trevor replied. 'Oh; aren't you worried that the very hot weather might disagree with your wife?' asked John. 'It wouldn't dare', said Trevor.\", \"Two women were standing at a funeral. 'I blame myself for his death', said the wife. 'Why?' said her friend. 'Because I shot him', said the wife.\", \"A woman goes into a clothes shop, 'Can I try that dress on in the window please?' she asks. 'I'm sorry madam', replies the shop assistant, 'but you'll have to use the changing-rooms like everyone else.'\", \"Van Gogh goes into a pub and his mate asks him if he wants a drink. 'No thanks', said Vincent, 'I've got one ear.'\", \"A pony walks into a pub. The publican says, 'What's the matter with you?' 'Oh it's nothing', says the pony. 'I'm just a little horse!'\", \"A white horse walks into a bar, pulls up a stool, and orders a pint. The landlord pours him a tall frothy mug and say, 'You know, we have a drink named after you.' To which the white horse replies, 'What, Eric?'\", \"Two drunk men sat in a pub. One says to the other, 'Does your watch tell the time?' 'The other replies, 'No, mate. You have to look at it.'\", \"A man goes into a pub with a newt sitting on his shoulder. 'That's a nice newt', says the landlord, 'What's he called?' 'Tiny', replies the man. 'Why's that?' asks the landlord. 'Because he's my newt', says the man.\", \"Doctor: I have some bad news and some very bad news. Patient: Well, you might as well give me the bad news first. Doctor: The lab called with your test results. They said you have 24 hours to live. Patient: 24 HOURS! That's terrible!! WHAT could be WORSE? What's the very bad news? Doctor: I've been trying to reach you since yesterday.\", \"Two men are chatting in a pub one day. 'How did you get those scars on your nose?' said one. 'From glasses', said the other. 'Well why don't you try contact lenses?' asked the first. 'Because they don't hold as much beer', said the second.\", \"A man went to the doctor, 'Look doc', he said, 'I can't stop my hands from shaking.' 'Do you drink much?' asked the doctor. 'No', replied the man, 'I spill most of it.'\", \"Man goes to the doctor, 'Doctor, doctor. I keep seeing fish everywhere.' 'Have you seen an optician?' asks the doctor. 'Look I told you,' snapped the patient, 'It's fish that I see.'\", \"After a car crash one of the drivers was lying injured on the pavement. 'Don't worry', said a policeman who's first on the scene,' a Red Cross nurse is coming.' 'Oh no', moaned the victim, 'Couldn't I have a blonde, cheerful one instead?'\", \"A policeman walked over to a parked car and asked the driver if the car was licensed. 'Of course it is', said the driver. 'Great, I'll have a beer then', said the policeman.\", \"A policeman stops a woman and asks for her licence. 'Madam', he says, 'It says here that you should be wearing glasses.' 'Well', replies the woman, 'I have contacts.' 'Listen, love', says the copper, 'I don't care who you know; You're nicked!'\", \"A policeman stopped a motorist in the centre of town one evening. 'Would you mind blowing into this bag, sir?' asked the policeman. 'Why?' asked the driver. 'Because my chips are too hot', replied the policeman.\", \"Whizzing round a sharp bend on a country road a motorist ran over a large dog. A distraught farmer's wife ran over to the dead animal. 'I'm so very sorry', said the driver, 'I'll replace him, of course.' 'Well, I don't know', said the farmer's wife, 'Are you any good at catching rats?'\", \"Waiter, this coffee tastes like dirt! Yes sir, that's because it was ground this morning.\", \"Waiter, what is this stuff? That's bean salad sir. I know what it's been, but what is it now?\", 'Waiter: And how did you find your steak sir? Customer: I just flipped a chip over, and there it was!', \"A guy goes into a pet shop and asks for a wasp. The owner tells him they don't sell wasps, to which the man says, 'Well you've got one in the window.'\", \"A man goes into a fish shop and says, 'I'd like a piece of cod, please.' Fishmonger says, 'It won't be long sir.' 'Well, it had better be fat then', replies the man.\", \"Man: Doctor, I've just swallowed a pillow. Doctor: How do you feel? Man: A little down in the mouth.\", \"Two goldfish are in a tank. One turns to the other and says, 'Do you know how to drive this thing?'\", \"A tortoise goes to the police station to report being mugged by three snails. 'What happened?' says the policeman. 'I don't know', says the tortoise. 'It was all so quick.'\", \"Little girl: Grandpa, can you make a sound like a frog? Grandpa: I suppose so sweetheart. Why do you want me to make a sound like a frog?' Little girl: Because Mum said that when you croak, we're going to Disneyland.\", \"'Is your mother home?' the salesman asked a small boy sitting on the front step of a house. 'Yeah, she's home', the boy said, moving over to let him past. The salesman rang the doorbell, got no response, knocked once, then again. Still no-one came to the door. Turning to the boy, the salesman said, 'I thought you said your mother was home.' The kid replied, 'She is, but I don't live here.'\", 'Mother: Why are you home from school so early? Son: I was the only one in the class who could answer a question. Mother: Oh, really? What was the question? Son: Who threw the rubber at the headmaster?', \"A man's credit card was stolen but he decided not to report it because the thief was spending less than his wife did.\", \"A newly-wed couple had recently opened a joint bank account. 'Darling', said the man. 'The bank has returned that cheque you wrote last week.' 'Great', said the woman. 'What shall I spend it on next?'\", \"A man goes into a fish and chip shop and orders fish and chips twice. The shop owner says, 'I heard you the first time.'\", \"A tramp approached a well-dressed man. 'Ten pence for a cup of tea, Guv?' He asked. The man gave him the money and after for five minutes said, 'So where's my cup of tea then?'\", \"A neutron walks into a pub. 'I'd like a beer', he says. The landlord promptly serves him a beer. 'How much will that be?' asks the neutron. 'For you?' replies the landlord, 'No charge.'\", \"A woman goes to the doctor and says, 'Doctor, my husband limps because his left leg is an inch shorter than his right leg. What would you do in his case?' 'Probably limp, too', says the doc.\", \"Three monks are meditating in the Himalayas. One year passes in silence, and one of them says to the other, 'Pretty cold up here isn't it?' Another year passes and the second monk says, 'You know, you are quite right.' Another year passes and the third monk says, 'Hey, I'm going to leave unless you two stop jabbering!'\", \"A murderer, sitting in the electric chair, was about to be executed. 'Have you any last requests?' asked the prison guard. 'Yes', replied the murderer. 'Will you hold my hand?'\", \"A highly excited man rang up for an ambulance. 'Quickly, come quickly', he shouted, 'My wife's about to have a baby.' 'Is this her first baby?' asked the operator. 'No, you fool', came the reply, 'It's her husband.'\", \"A passer-by spots a fisherman by a river. 'Is this a good river for fish?' he asks. 'Yes', replies the fisherman, 'It must be. I can't get any of them to come out.'\", \"A man went to visit a friend and was amazed to find him playing chess with his dog. He watched the game in astonishment for a while. 'I can hardly believe my eyes!' he exclaimed. 'That's the smartest dog I've ever seen.' His friend shook his head. 'Nah, he's not that bright. I beat him three games in five.'\", \"A termite walks into a pub and says, 'Is the bar tender here?'\", \"A skeleton walks into a pub one night and sits down on a stool. The landlord asks, 'What can I get you?' The skeleton says, 'I'll have a beer, thanks' The landlord passes him a beer and asks 'Anything else?' The skeleton nods. 'Yeah...a mop...'\", \"A snake slithers into a pub and up to the bar. The landlord says, 'I'm sorry, but I can't serve you.' 'What? Why not?' asks the snake. 'Because', says the landlord, 'You can't hold your drink.'\", \"Descartes walks into a pub. 'Would you like a beer sir?' asks the landlord politely. Descartes replies, 'I think not' and ping! he vanishes.\", \"A cowboy walked into a bar, dressed entirely in paper. It wasn't long before he was arrested for rustling.\", \"A fish staggers into a bar. 'What can I get you?' asks the landlord. The fish croaks 'Water...'\", \"Two vampires walked into a bar and called for the landlord. 'I'll have a glass of blood', said one. 'I'll have a glass of plasma', said the other. 'Okay', replied the landlord, 'That'll be one blood and one blood lite.'\", 'How many existentialists does it take to change a light bulb?  Two. One to screw it in, and one to observe how the light bulb itself symbolises a single incandescent beacon of subjective reality in a netherworld of endless absurdity, reaching towards the ultimate horror of a maudlin cosmos of bleak, hostile nothingness.', \"A team of scientists were nominated for the Nobel Prize. They had used dental equipment to discover and measure the smallest particles yet known to man. They became known as 'The Graders of the Flossed Quark...'\", \"A truck carrying copies of Roget's Thesaurus overturned on the highway. The local newspaper reported that onlookers were 'stunned, overwhelmed, astonished, bewildered and dumbfounded.'\", \"'My wife is really immature. It's pathetic. Every time I take a bath, she comes in and sinks all my little boats.'\", \"'How much will it cost to have the tooth extracted?' asked the patient. '50 pounds', replied the dentist. '50 pounds for a few moments' work?!' asked the patient. 'The dentist smiled, and replied, 'Well, if you want better value for money, I can extract it very, very slowly...'\", \"A doctor thoroughly examined his patient and said, 'Look I really can't find any reason for this mysterious affliction. It's probably due to drinking.' The patient sighed and snapped, 'In that case, I'll come back when you're damn well sober!'\", 'Doctor: Tell me nurse, how is that boy doing; the one who ate all those 5p pieces? Nurse: Still no change doctor.', \"Doctor: Did you take the patient's temperature nurse? Nurse: No doctor. Is it missing?\", \"A depressed man turned to his friend in the pub and said, 'I woke up this morning and felt so bad that I tried to kill myself by taking 50 aspirin.' 'Oh man, that's really bad', said his friend, 'What happened?' The first man sighed and said, 'After the first two, I felt better.'\", \"A famous blues musician died. His tombstone bore the inscription, 'Didn't wake up this morning...'\", \"A businessman was interviewing a nervous young woman for a position in his company. He wanted to find out something about her personality, so he asked, 'If you could have a conversation with someone living or dead, who would it be?' The girl thought about the question: 'The living one', she replied.\", \"Manager to interviewee: For this job we need someone who is responsible. Interviewee to Manager: I'm your man then - in my last job, whenever anything went wrong, I was responsible.\", \"A businessman turned to a colleague and asked, 'So, how many people work at your office?' His friend shrugged and replied, 'Oh about half of them.'\", \"'How long have I been working at that office? As a matter of fact, I've been working there ever since they threatened to sack me.'\", \"In a courtroom, a mugger was on trial. The victim, asked if she recognised the defendant, said, 'Yes, that's him. I saw him clear as day. I'd remember his face anywhere.' Unable to contain himself, the defendant burst out with, 'She's lying! I was wearing a mask!'\", \"As Sid sat down to a big plate of chips and gravy down the local pub, a mate of his came over and said, 'Here Sid, me old pal. I thought you were trying to get into shape? And here you are with a high-fat meal and a pint of stout!' Sid looked up and replied, 'I am getting into shape. The shape I've chosen is a sphere.'\", 'Man in pub: How much do you charge for one single drop of whisky? Landlord: That would be free sir. Man in pub: Excellent. Drip me a glass full.', 'I once went to a Doctor Who restaurant. For starters I had Dalek bread.', \"A restaurant nearby had a sign in the window which said 'We serve breakfast at any time', so I ordered French toast in the Renaissance.\", \"Why couldn't the rabbit get a loan?  Because he had burrowed too much already!\", \"I phoned up the builder's yard yesterday. I said, 'Can I have a skip outside my house?'. The builder said, 'Sure. Do what you want. It's your house.'\", \"What's the diference between a sock and a camera? A sock takes five toes and a camera takes four toes!\", \"Woman on phone: I'd like to complain about these incontinence pants I bought from you! Shopkeeper: Certainly madam, where are you ringing from? Woman on phone: From the waist down!\", 'Knock knock.', \"Two Oranges in a pub, one says to the other 'Your round.'.\", \"Guy : 'Doc, I've got a cricket ball stuck up my backside.' Doc : 'How's that?' Guy : 'Don't you start...'\", \"Two cows standing in a field. One turns to the other and says 'Moo!' The other one says 'Damn, I was just about to say that!'.\", \"A vampire bat arrives back at the roost with his face full of blood. All the bats get excited and ask where he got it from. 'Follow me', he says and off they fly over hills, over rivers and into a dark forest. 'See that tree over there', he says.  'WELL I DIDN'T!!'.\", \"A man goes into a bar and orders a pint. After a few minutes he hears a voice that says, 'Nice shoes'. He looks around but the whole bar is empty apart from the barman at the other end of the bar. A few minutes later he hears the voice again. This time it says, 'I like your shirt'. He beckons the barman over and tells him what's been happening to which the barman replies, 'Ah, that would be the nuts sir. They're complimentary'!\", \"A man was siting in a restaurant waiting for his meal when a big king prawn comes flying across the room and hits him on the back of the head. He turns around and the waiter said, 'That's just for starters'.\", 'Doctor! I have a serious problem, I can never remember what i just said. When did you first notice this problem? What problem?', \"Now, most dentist's chairs go up and down, don't they? The one I was in went back and forwards. I thought, 'This is unusual'. Then the dentist said to me, 'Mitsuku, get out of the filing cabinet'.\", \"I was reading this book, 'The History of Glue'. I couldn't put it down.\", \"The other day someone left a piece of plastacine in my bedroom. I didn't know what to make of it.\", 'When I was at school people used to throw gold bars at me. I was the victim of bullion.', \"I was playing the piano in a bar and this elephant walked in and started crying his eyes out. I said 'Do you recognise the tune?' He said 'No, I recognise the ivory.'\", \"I went in to a pet shop. I said, 'Can I buy a goldfish?' The guy said, 'Do you want an aquarium?' I said, 'I don't care what star sign it is.'\", 'My mate Sid was a victim of I.D. theft. Now we just call him S.', \"David Hasselhoff walks into a bar and says to the barman, 'I want you to call me David Hoff'.  The barman replies 'Sure thing Dave... no hassle'\"], 'repeat': [\"Oh sorry I didn't realise that. I'll try not to repeat myself again.\"], 'wrong': [\"I'm very sorry. Let's try that again\"], 'stupid': [\"I wish you wouldn't say such hurtful things. I'm sorry if I wasn't useful\"], 'location': ['Duh I live in your computer', 'Everywhere', 'Somewhere in the universe'], 'something-else': ['Okay sure. What do you want to talk about?', 'Alright no problem. Is there something you want to talk about?', 'Is there something else that you want to talk about?'], 'friends': [\"I'm sorry to hear that. Just know that I'm here for you. Talking about it might help. Why do you think you don't have any friends?\"], 'ask': [\"Sure. I'll try my best to answer you\", \"Of course. Feel free to ask me anything. I'll do my best to answer you\"], 'problem': ['I see. Have you taken any approaches to not feel this way?'], 'no-approach': [\"That's no problem. I can see why you'd be stressed out about that. I can suggest you some tips to alleviate this issue. Would you like to learn more about that?\"], 'learn-more': [\"So first I would suggest you to give yourself a break. Thinking more and more about the problem definitely does not help in solving it. You'll just end up overwhelming yourself.\"], 'user-agree': ['Next, I would suggest you to practice meditation. Meditation can produce a deep state of relaxation and a tranquil mind.'], 'meditation': ['Focus all your attention on your breathing. Concentrate on feeling and listening as you inhale and exhale through your nostrils. Breathe deeply and slowly. When your attention wanders, gently return your focus to your breathing.'], 'user-meditation': [\"Your welcome. Remember: Always focus on what's within your control. When you find yourself worrying, take a minute to examine the things you have control over. You can't prevent a storm from coming but you can prepare for it. You can't control how someone else behaves, but you can control how you react. Recognize that sometimes, all you can control is your effort and your attitude. When you put your energy into the things you can control, you'll be much more effective.\"], 'pandora-useful': [\"I'm glad you found this useful. Is there something else I can help you with?\"], 'user-advice': ['Sure. What can I do to help?', 'Okay what do you need advice on?'], 'learn-mental-health': [\"Oh that's really great. I'd be willing to answer anything that I know about it.\"], 'mental-health-fact': ['According to a UNICEF report, One in seven Indians between 15-24 years of age feels depressed', '1 in 5 young people (age 13-18) has or will develop a mental illness in their lifetime.', 'Depression is the leading cause of disability worldwide.']}\n"
          ]
        }
      ],
      "source": [
        "def map_tag_pattern(df, tag_col, text_col, res_col):\n",
        "    tags = []\n",
        "    inputs = []\n",
        "    responses = {}\n",
        "\n",
        "    for _, item in df.iterrows():\n",
        "        ptrns = item[text_col]\n",
        "        tag = item[tag_col]\n",
        "        responses[item[tag_col]] = item[res_col]\n",
        "        for j in range(len(ptrns)):\n",
        "            tags.append(tag)\n",
        "            inputs.append(ptrns[j])\n",
        "\n",
        "    return tags, inputs, responses\n",
        "\n",
        "# Assuming df is your original DataFrame\n",
        "tags, inputs, responses = map_tag_pattern(df, \"tag\", \"patterns\", \"responses\")\n",
        "\n",
        "# Example of how to use the lists\n",
        "print(\"Tags:\", tags)\n",
        "print(\"Patterns:\", inputs)\n",
        "print(\"Responses:\", responses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "R0wuJ0Cjfy7L",
        "outputId": "14ca83b1-8af9-4761-b609-a2c85a60fbf1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 266,\n  \"fields\": [\n    {\n      \"column\": \"inputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 264,\n        \"samples\": [\n          \"How were you made?\",\n          \"I am going to kill myself\",\n          \"I feel down\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 58,\n        \"samples\": [\n          \"greeting\",\n          \"night\",\n          \"self-aware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c3ae8e6e-9b50-4141-b5df-8d0238d71005\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hey</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is anyone there?</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi there</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>I want to learn about mental health.</td>\n",
              "      <td>learn-mental-health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>I want to learn more about mental health.</td>\n",
              "      <td>learn-mental-health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>I'm interested in learning about mental health.</td>\n",
              "      <td>learn-mental-health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>Tell me a fact about mental health</td>\n",
              "      <td>mental-health-fact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>Tell me another fact about mental health</td>\n",
              "      <td>mental-health-fact</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>266 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3ae8e6e-9b50-4141-b5df-8d0238d71005')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3ae8e6e-9b50-4141-b5df-8d0238d71005 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3ae8e6e-9b50-4141-b5df-8d0238d71005');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d57e75c-5a51-44af-a966-4614cb6a3ee6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d57e75c-5a51-44af-a966-4614cb6a3ee6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d57e75c-5a51-44af-a966-4614cb6a3ee6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6b121d03-ef01-483b-aaed-e7d1c39a862f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b121d03-ef01-483b-aaed-e7d1c39a862f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              inputs                 tags\n",
              "0                                                 Hi             greeting\n",
              "1                                                Hey             greeting\n",
              "2                                   Is anyone there?             greeting\n",
              "3                                           Hi there             greeting\n",
              "4                                              Hello             greeting\n",
              "..                                               ...                  ...\n",
              "261             I want to learn about mental health.  learn-mental-health\n",
              "262        I want to learn more about mental health.  learn-mental-health\n",
              "263  I'm interested in learning about mental health.  learn-mental-health\n",
              "264               Tell me a fact about mental health   mental-health-fact\n",
              "265         Tell me another fact about mental health   mental-health-fact\n",
              "\n",
              "[266 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.DataFrame({\"inputs\":inputs, \"tags\":tags})\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ood1RBfBgb3X"
      },
      "outputs": [],
      "source": [
        "data[\"inputs\"] = data[\"inputs\"].apply(lambda wrd: ''.join([ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "epRDWi4ngbxO"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = 2000)\n",
        "tokenizer.fit_on_texts(data[\"inputs\"])\n",
        "train = tokenizer.texts_to_sequences(data[\"inputs\"])\n",
        "le = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RB-njhDqgVrq"
      },
      "outputs": [],
      "source": [
        "x_train = pad_sequences(train)\n",
        "y_train = le.fit_transform(data[\"tags\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Cd0LHug-hCeV"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "epochs=500\n",
        "input_shape = x_train.shape[1]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "output_length = le.classes_.shape[0]\n",
        "embed_dim=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_D8OjWhhJMJ",
        "outputId": "106abf41-3c5b-4b22-8e05-db9d28e698c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 18, 10)            2890      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 18, 10)            840       \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 180)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1810      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 58)                348       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5943 (23.21 KB)\n",
            "Trainable params: 5943 (23.21 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build RNN Model with tensorflow\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(input_shape,)),\n",
        "    tf.keras.layers.Embedding(vocab_size, embed_dim, input_length=(input_shape,)),\n",
        "    tf.keras.layers.LSTM(units=10, return_sequences=True),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=10, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=5, activation='relu'),\n",
        "    tf.keras.layers.Dense(output_length, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-i034xghLxn",
        "outputId": "9e6be621-6942-42bb-bbba-66ad06eed5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "9/9 [==============================] - 3s 95ms/step - loss: 4.0600 - accuracy: 0.0188\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 4.0569 - accuracy: 0.0789\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 4.0544 - accuracy: 0.0752\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 4.0513 - accuracy: 0.0752\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 4.0463 - accuracy: 0.0263\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 4.0345 - accuracy: 0.0188\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.0219 - accuracy: 0.0188\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 4.0080 - accuracy: 0.0188\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 3.9933 - accuracy: 0.0188\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 3.9798 - accuracy: 0.0188\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 3.9633 - accuracy: 0.0188\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.9404 - accuracy: 0.0263\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.9162 - accuracy: 0.0263\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.8900 - accuracy: 0.0301\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8568 - accuracy: 0.0451\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 3.8226 - accuracy: 0.0451\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.7850 - accuracy: 0.0451\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 3.7434 - accuracy: 0.0564\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7036 - accuracy: 0.0677\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6647 - accuracy: 0.0714\n",
            "Epoch 21/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6234 - accuracy: 0.0752\n",
            "Epoch 22/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 3.5845 - accuracy: 0.0789\n",
            "Epoch 23/500\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 3.5505 - accuracy: 0.0902\n",
            "Epoch 24/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5149 - accuracy: 0.0902\n",
            "Epoch 25/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4817 - accuracy: 0.0902\n",
            "Epoch 26/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4539 - accuracy: 0.0940\n",
            "Epoch 27/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 3.4288 - accuracy: 0.0940\n",
            "Epoch 28/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3992 - accuracy: 0.0940\n",
            "Epoch 29/500\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 3.3810 - accuracy: 0.0940\n",
            "Epoch 30/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3559 - accuracy: 0.0940\n",
            "Epoch 31/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3326 - accuracy: 0.0940\n",
            "Epoch 32/500\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 3.3125 - accuracy: 0.0940\n",
            "Epoch 33/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.2948 - accuracy: 0.0940\n",
            "Epoch 34/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2710 - accuracy: 0.0940\n",
            "Epoch 35/500\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 3.2509 - accuracy: 0.0940\n",
            "Epoch 36/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2387 - accuracy: 0.0977\n",
            "Epoch 37/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2195 - accuracy: 0.0940\n",
            "Epoch 38/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2039 - accuracy: 0.0940\n",
            "Epoch 39/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1920 - accuracy: 0.0940\n",
            "Epoch 40/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1849 - accuracy: 0.0940\n",
            "Epoch 41/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1839 - accuracy: 0.0940\n",
            "Epoch 42/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1540 - accuracy: 0.0940\n",
            "Epoch 43/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1544 - accuracy: 0.0977\n",
            "Epoch 44/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.1333 - accuracy: 0.1015\n",
            "Epoch 45/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1332 - accuracy: 0.1015\n",
            "Epoch 46/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 3.1058 - accuracy: 0.1128\n",
            "Epoch 47/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0959 - accuracy: 0.1128\n",
            "Epoch 48/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0734 - accuracy: 0.1128\n",
            "Epoch 49/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0600 - accuracy: 0.1165\n",
            "Epoch 50/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0444 - accuracy: 0.1165\n",
            "Epoch 51/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.0341 - accuracy: 0.1128\n",
            "Epoch 52/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0210 - accuracy: 0.1203\n",
            "Epoch 53/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0123 - accuracy: 0.1278\n",
            "Epoch 54/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9967 - accuracy: 0.1241\n",
            "Epoch 55/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9838 - accuracy: 0.1278\n",
            "Epoch 56/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9684 - accuracy: 0.1203\n",
            "Epoch 57/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9537 - accuracy: 0.1278\n",
            "Epoch 58/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9410 - accuracy: 0.1316\n",
            "Epoch 59/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 2.9203 - accuracy: 0.1316\n",
            "Epoch 60/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9033 - accuracy: 0.1316\n",
            "Epoch 61/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8863 - accuracy: 0.1541\n",
            "Epoch 62/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8742 - accuracy: 0.1466\n",
            "Epoch 63/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8604 - accuracy: 0.1617\n",
            "Epoch 64/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8474 - accuracy: 0.1579\n",
            "Epoch 65/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8291 - accuracy: 0.1617\n",
            "Epoch 66/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8165 - accuracy: 0.1692\n",
            "Epoch 67/500\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 2.8088 - accuracy: 0.1617\n",
            "Epoch 68/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7785 - accuracy: 0.1805\n",
            "Epoch 69/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.7780 - accuracy: 0.1767\n",
            "Epoch 70/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7591 - accuracy: 0.1767\n",
            "Epoch 71/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7439 - accuracy: 0.1692\n",
            "Epoch 72/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7243 - accuracy: 0.1955\n",
            "Epoch 73/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7094 - accuracy: 0.1880\n",
            "Epoch 74/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6875 - accuracy: 0.1955\n",
            "Epoch 75/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6754 - accuracy: 0.2105\n",
            "Epoch 76/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6598 - accuracy: 0.1842\n",
            "Epoch 77/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6430 - accuracy: 0.1729\n",
            "Epoch 78/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6294 - accuracy: 0.1805\n",
            "Epoch 79/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6109 - accuracy: 0.2180\n",
            "Epoch 80/500\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 2.5927 - accuracy: 0.2218\n",
            "Epoch 81/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5777 - accuracy: 0.2143\n",
            "Epoch 82/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5619 - accuracy: 0.2256\n",
            "Epoch 83/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5433 - accuracy: 0.2105\n",
            "Epoch 84/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5396 - accuracy: 0.2444\n",
            "Epoch 85/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5086 - accuracy: 0.2331\n",
            "Epoch 86/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.5100 - accuracy: 0.2444\n",
            "Epoch 87/500\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2.4930 - accuracy: 0.2331\n",
            "Epoch 88/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.4674 - accuracy: 0.2481\n",
            "Epoch 89/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4559 - accuracy: 0.2556\n",
            "Epoch 90/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4363 - accuracy: 0.2481\n",
            "Epoch 91/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4186 - accuracy: 0.2519\n",
            "Epoch 92/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4002 - accuracy: 0.3120\n",
            "Epoch 93/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3801 - accuracy: 0.2669\n",
            "Epoch 94/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3575 - accuracy: 0.3120\n",
            "Epoch 95/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3342 - accuracy: 0.2820\n",
            "Epoch 96/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.3126 - accuracy: 0.3083\n",
            "Epoch 97/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2892 - accuracy: 0.3045\n",
            "Epoch 98/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2863 - accuracy: 0.2857\n",
            "Epoch 99/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2709 - accuracy: 0.3008\n",
            "Epoch 100/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2432 - accuracy: 0.3346\n",
            "Epoch 101/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2369 - accuracy: 0.3308\n",
            "Epoch 102/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2030 - accuracy: 0.3346\n",
            "Epoch 103/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1856 - accuracy: 0.3496\n",
            "Epoch 104/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1579 - accuracy: 0.3459\n",
            "Epoch 105/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1473 - accuracy: 0.3421\n",
            "Epoch 106/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1216 - accuracy: 0.3722\n",
            "Epoch 107/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.1034 - accuracy: 0.3910\n",
            "Epoch 108/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0875 - accuracy: 0.3647\n",
            "Epoch 109/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.0688 - accuracy: 0.3835\n",
            "Epoch 110/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0506 - accuracy: 0.4023\n",
            "Epoch 111/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0499 - accuracy: 0.3684\n",
            "Epoch 112/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0182 - accuracy: 0.4098\n",
            "Epoch 113/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0086 - accuracy: 0.3759\n",
            "Epoch 114/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9842 - accuracy: 0.4060\n",
            "Epoch 115/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9721 - accuracy: 0.3947\n",
            "Epoch 116/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9571 - accuracy: 0.4060\n",
            "Epoch 117/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9362 - accuracy: 0.3985\n",
            "Epoch 118/500\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.9520 - accuracy: 0.3910\n",
            "Epoch 119/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9445 - accuracy: 0.3985\n",
            "Epoch 120/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9032 - accuracy: 0.4248\n",
            "Epoch 121/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8922 - accuracy: 0.4248\n",
            "Epoch 122/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8711 - accuracy: 0.4398\n",
            "Epoch 123/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.8456 - accuracy: 0.4436\n",
            "Epoch 124/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8358 - accuracy: 0.4135\n",
            "Epoch 125/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8407 - accuracy: 0.4624\n",
            "Epoch 126/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8024 - accuracy: 0.4662\n",
            "Epoch 127/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7829 - accuracy: 0.4887\n",
            "Epoch 128/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7659 - accuracy: 0.4887\n",
            "Epoch 129/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7509 - accuracy: 0.4887\n",
            "Epoch 130/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7365 - accuracy: 0.4962\n",
            "Epoch 131/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7287 - accuracy: 0.4850\n",
            "Epoch 132/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7331 - accuracy: 0.4962\n",
            "Epoch 133/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7201 - accuracy: 0.5000\n",
            "Epoch 134/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7265 - accuracy: 0.4699\n",
            "Epoch 135/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7127 - accuracy: 0.4774\n",
            "Epoch 136/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6561 - accuracy: 0.5226\n",
            "Epoch 137/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6283 - accuracy: 0.5263\n",
            "Epoch 138/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5997 - accuracy: 0.5451\n",
            "Epoch 139/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.5889 - accuracy: 0.5602\n",
            "Epoch 140/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5676 - accuracy: 0.5564\n",
            "Epoch 141/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5570 - accuracy: 0.5376\n",
            "Epoch 142/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5373 - accuracy: 0.5564\n",
            "Epoch 143/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5280 - accuracy: 0.5489\n",
            "Epoch 144/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5107 - accuracy: 0.5752\n",
            "Epoch 145/500\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 1.5033 - accuracy: 0.5752\n",
            "Epoch 146/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4793 - accuracy: 0.5977\n",
            "Epoch 147/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4676 - accuracy: 0.6128\n",
            "Epoch 148/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4406 - accuracy: 0.6128\n",
            "Epoch 149/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4260 - accuracy: 0.6165\n",
            "Epoch 150/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4082 - accuracy: 0.6203\n",
            "Epoch 151/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4022 - accuracy: 0.6128\n",
            "Epoch 152/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3816 - accuracy: 0.6391\n",
            "Epoch 153/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3703 - accuracy: 0.6203\n",
            "Epoch 154/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3503 - accuracy: 0.6165\n",
            "Epoch 155/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3374 - accuracy: 0.6353\n",
            "Epoch 156/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3236 - accuracy: 0.6429\n",
            "Epoch 157/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3015 - accuracy: 0.6466\n",
            "Epoch 158/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2887 - accuracy: 0.6353\n",
            "Epoch 159/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2842 - accuracy: 0.6504\n",
            "Epoch 160/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2667 - accuracy: 0.6654\n",
            "Epoch 161/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2642 - accuracy: 0.6767\n",
            "Epoch 162/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2370 - accuracy: 0.6880\n",
            "Epoch 163/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2298 - accuracy: 0.6617\n",
            "Epoch 164/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2119 - accuracy: 0.6729\n",
            "Epoch 165/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.6617\n",
            "Epoch 166/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.1973 - accuracy: 0.6842\n",
            "Epoch 167/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1867 - accuracy: 0.6729\n",
            "Epoch 168/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1593 - accuracy: 0.7030\n",
            "Epoch 169/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1575 - accuracy: 0.7143\n",
            "Epoch 170/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1481 - accuracy: 0.6992\n",
            "Epoch 171/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.1293 - accuracy: 0.6842\n",
            "Epoch 172/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1150 - accuracy: 0.6992\n",
            "Epoch 173/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1017 - accuracy: 0.7143\n",
            "Epoch 174/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0962 - accuracy: 0.6992\n",
            "Epoch 175/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0908 - accuracy: 0.7180\n",
            "Epoch 176/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0765 - accuracy: 0.7256\n",
            "Epoch 177/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0686 - accuracy: 0.7180\n",
            "Epoch 178/500\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.0576 - accuracy: 0.7180\n",
            "Epoch 179/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0544 - accuracy: 0.7105\n",
            "Epoch 180/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0436 - accuracy: 0.7180\n",
            "Epoch 181/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0390 - accuracy: 0.7105\n",
            "Epoch 182/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0397 - accuracy: 0.7293\n",
            "Epoch 183/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0187 - accuracy: 0.7143\n",
            "Epoch 184/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0045 - accuracy: 0.7406\n",
            "Epoch 185/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9924 - accuracy: 0.7481\n",
            "Epoch 186/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9870 - accuracy: 0.7481\n",
            "Epoch 187/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9988 - accuracy: 0.7218\n",
            "Epoch 188/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9869 - accuracy: 0.7556\n",
            "Epoch 189/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9806 - accuracy: 0.7594\n",
            "Epoch 190/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9534 - accuracy: 0.7782\n",
            "Epoch 191/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9430 - accuracy: 0.7970\n",
            "Epoch 192/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9303 - accuracy: 0.8045\n",
            "Epoch 193/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9168 - accuracy: 0.7782\n",
            "Epoch 194/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9101 - accuracy: 0.7707\n",
            "Epoch 195/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9041 - accuracy: 0.7744\n",
            "Epoch 196/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8976 - accuracy: 0.7481\n",
            "Epoch 197/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8840 - accuracy: 0.7782\n",
            "Epoch 198/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8915 - accuracy: 0.7669\n",
            "Epoch 199/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8703 - accuracy: 0.7857\n",
            "Epoch 200/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8677 - accuracy: 0.7820\n",
            "Epoch 201/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8666 - accuracy: 0.7782\n",
            "Epoch 202/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8812 - accuracy: 0.8083\n",
            "Epoch 203/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8753 - accuracy: 0.7707\n",
            "Epoch 204/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8431 - accuracy: 0.8083\n",
            "Epoch 205/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8348 - accuracy: 0.8158\n",
            "Epoch 206/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8230 - accuracy: 0.8083\n",
            "Epoch 207/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8210 - accuracy: 0.8158\n",
            "Epoch 208/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8111 - accuracy: 0.8158\n",
            "Epoch 209/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7985 - accuracy: 0.8233\n",
            "Epoch 210/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7927 - accuracy: 0.8271\n",
            "Epoch 211/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7982 - accuracy: 0.8195\n",
            "Epoch 212/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7852 - accuracy: 0.8158\n",
            "Epoch 213/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7687 - accuracy: 0.8421\n",
            "Epoch 214/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7660 - accuracy: 0.8271\n",
            "Epoch 215/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.7566 - accuracy: 0.8271\n",
            "Epoch 216/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7477 - accuracy: 0.8459\n",
            "Epoch 217/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7428 - accuracy: 0.8496\n",
            "Epoch 218/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7466 - accuracy: 0.8609\n",
            "Epoch 219/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7350 - accuracy: 0.8496\n",
            "Epoch 220/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.8496\n",
            "Epoch 221/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7124 - accuracy: 0.8571\n",
            "Epoch 222/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7179 - accuracy: 0.8571\n",
            "Epoch 223/500\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.7113 - accuracy: 0.8421\n",
            "Epoch 224/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7099 - accuracy: 0.8647\n",
            "Epoch 225/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.8609\n",
            "Epoch 226/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.8609\n",
            "Epoch 227/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.8759\n",
            "Epoch 228/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.8722\n",
            "Epoch 229/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.8684\n",
            "Epoch 230/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.8684\n",
            "Epoch 231/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.8722\n",
            "Epoch 232/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.8684\n",
            "Epoch 233/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.8684\n",
            "Epoch 234/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.8797\n",
            "Epoch 235/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.8835\n",
            "Epoch 236/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6385 - accuracy: 0.8684\n",
            "Epoch 237/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6273 - accuracy: 0.8835\n",
            "Epoch 238/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6197 - accuracy: 0.8647\n",
            "Epoch 239/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6147 - accuracy: 0.8684\n",
            "Epoch 240/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.8722\n",
            "Epoch 241/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.8797\n",
            "Epoch 242/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.8571\n",
            "Epoch 243/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.8647\n",
            "Epoch 244/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.8835\n",
            "Epoch 245/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.8872\n",
            "Epoch 246/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.8872\n",
            "Epoch 247/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.8835\n",
            "Epoch 248/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.8759\n",
            "Epoch 249/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.8835\n",
            "Epoch 250/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.8910\n",
            "Epoch 251/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.8759\n",
            "Epoch 252/500\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.5538 - accuracy: 0.8910\n",
            "Epoch 253/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5510 - accuracy: 0.8872\n",
            "Epoch 254/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.9023\n",
            "Epoch 255/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.8947\n",
            "Epoch 256/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.8947\n",
            "Epoch 257/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.8910\n",
            "Epoch 258/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.8947\n",
            "Epoch 259/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8835\n",
            "Epoch 260/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.8872\n",
            "Epoch 261/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.8947\n",
            "Epoch 262/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.8910\n",
            "Epoch 263/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.8872\n",
            "Epoch 264/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.9060\n",
            "Epoch 265/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.8835\n",
            "Epoch 266/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.8797\n",
            "Epoch 267/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.8947\n",
            "Epoch 268/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5026 - accuracy: 0.8947\n",
            "Epoch 269/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.9023\n",
            "Epoch 270/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.8872\n",
            "Epoch 271/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.8947\n",
            "Epoch 272/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.9098\n",
            "Epoch 273/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.9023\n",
            "Epoch 274/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.9023\n",
            "Epoch 275/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.9098\n",
            "Epoch 276/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.9023\n",
            "Epoch 277/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.8835\n",
            "Epoch 278/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.9023\n",
            "Epoch 279/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.9023\n",
            "Epoch 280/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.9098\n",
            "Epoch 281/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.9023\n",
            "Epoch 282/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.9060\n",
            "Epoch 283/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.9060\n",
            "Epoch 284/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8985\n",
            "Epoch 285/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8985\n",
            "Epoch 286/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9023\n",
            "Epoch 287/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.9060\n",
            "Epoch 288/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.9060\n",
            "Epoch 289/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.9173\n",
            "Epoch 290/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.4272 - accuracy: 0.9098\n",
            "Epoch 291/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9098\n",
            "Epoch 292/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.9098\n",
            "Epoch 293/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.9023\n",
            "Epoch 294/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.9211\n",
            "Epoch 295/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.9211\n",
            "Epoch 296/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.9211\n",
            "Epoch 297/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.9173\n",
            "Epoch 298/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.9060\n",
            "Epoch 299/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.9135\n",
            "Epoch 300/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.9135\n",
            "Epoch 301/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.9211\n",
            "Epoch 302/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8947\n",
            "Epoch 303/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.9211\n",
            "Epoch 304/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.9248\n",
            "Epoch 305/500\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3756 - accuracy: 0.9286\n",
            "Epoch 306/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.9248\n",
            "Epoch 307/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.9248\n",
            "Epoch 308/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.9248\n",
            "Epoch 309/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.9211\n",
            "Epoch 310/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.9323\n",
            "Epoch 311/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3606 - accuracy: 0.9323\n",
            "Epoch 312/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.9286\n",
            "Epoch 313/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3523 - accuracy: 0.9361\n",
            "Epoch 314/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3485 - accuracy: 0.9248\n",
            "Epoch 315/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.9286\n",
            "Epoch 316/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.9361\n",
            "Epoch 317/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.9286\n",
            "Epoch 318/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.9361\n",
            "Epoch 319/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.9286\n",
            "Epoch 320/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3436 - accuracy: 0.9323\n",
            "Epoch 321/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3441 - accuracy: 0.9398\n",
            "Epoch 322/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.9286\n",
            "Epoch 323/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.9211\n",
            "Epoch 324/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.9361\n",
            "Epoch 325/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3210 - accuracy: 0.9286\n",
            "Epoch 326/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3185 - accuracy: 0.9361\n",
            "Epoch 327/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3211 - accuracy: 0.9323\n",
            "Epoch 328/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3204 - accuracy: 0.9286\n",
            "Epoch 329/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.9323\n",
            "Epoch 330/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.9286\n",
            "Epoch 331/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.9286\n",
            "Epoch 332/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.9361\n",
            "Epoch 333/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.9248\n",
            "Epoch 334/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3194 - accuracy: 0.9398\n",
            "Epoch 335/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3105 - accuracy: 0.9398\n",
            "Epoch 336/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3088 - accuracy: 0.9436\n",
            "Epoch 337/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3078 - accuracy: 0.9398\n",
            "Epoch 338/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3031 - accuracy: 0.9398\n",
            "Epoch 339/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2992 - accuracy: 0.9436\n",
            "Epoch 340/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2920 - accuracy: 0.9436\n",
            "Epoch 341/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2855 - accuracy: 0.9398\n",
            "Epoch 342/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2852 - accuracy: 0.9323\n",
            "Epoch 343/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2829 - accuracy: 0.9436\n",
            "Epoch 344/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2832 - accuracy: 0.9398\n",
            "Epoch 345/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2828 - accuracy: 0.9398\n",
            "Epoch 346/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2792 - accuracy: 0.9323\n",
            "Epoch 347/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2818 - accuracy: 0.9323\n",
            "Epoch 348/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2812 - accuracy: 0.9361\n",
            "Epoch 349/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.9248\n",
            "Epoch 350/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2773 - accuracy: 0.9361\n",
            "Epoch 351/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2930 - accuracy: 0.9436\n",
            "Epoch 352/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3206 - accuracy: 0.9474\n",
            "Epoch 353/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2934 - accuracy: 0.9361\n",
            "Epoch 354/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2783 - accuracy: 0.9474\n",
            "Epoch 355/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2801 - accuracy: 0.9323\n",
            "Epoch 356/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2721 - accuracy: 0.9361\n",
            "Epoch 357/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2685 - accuracy: 0.9361\n",
            "Epoch 358/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2631 - accuracy: 0.9398\n",
            "Epoch 359/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2555 - accuracy: 0.9361\n",
            "Epoch 360/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2515 - accuracy: 0.9398\n",
            "Epoch 361/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2550 - accuracy: 0.9323\n",
            "Epoch 362/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.9398\n",
            "Epoch 363/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2510 - accuracy: 0.9474\n",
            "Epoch 364/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2493 - accuracy: 0.9436\n",
            "Epoch 365/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2457 - accuracy: 0.9586\n",
            "Epoch 366/500\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2480 - accuracy: 0.9436\n",
            "Epoch 367/500\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.2404 - accuracy: 0.9398\n",
            "Epoch 368/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.9436\n",
            "Epoch 369/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2573 - accuracy: 0.9436\n",
            "Epoch 370/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2487 - accuracy: 0.9436\n",
            "Epoch 371/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2531 - accuracy: 0.9398\n",
            "Epoch 372/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2486 - accuracy: 0.9436\n",
            "Epoch 373/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2433 - accuracy: 0.9511\n",
            "Epoch 374/500\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2448 - accuracy: 0.9511\n",
            "Epoch 375/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2340 - accuracy: 0.9511\n",
            "Epoch 376/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2428 - accuracy: 0.9549\n",
            "Epoch 377/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2309 - accuracy: 0.9511\n",
            "Epoch 378/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2277 - accuracy: 0.9511\n",
            "Epoch 379/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2253 - accuracy: 0.9474\n",
            "Epoch 380/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2213 - accuracy: 0.9586\n",
            "Epoch 381/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2277 - accuracy: 0.9624\n",
            "Epoch 382/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9624\n",
            "Epoch 383/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2253 - accuracy: 0.9474\n",
            "Epoch 384/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2216 - accuracy: 0.9624\n",
            "Epoch 385/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2238 - accuracy: 0.9549\n",
            "Epoch 386/500\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2212 - accuracy: 0.9474\n",
            "Epoch 387/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2203 - accuracy: 0.9474\n",
            "Epoch 388/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2149 - accuracy: 0.9586\n",
            "Epoch 389/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2096 - accuracy: 0.9474\n",
            "Epoch 390/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2153 - accuracy: 0.9549\n",
            "Epoch 391/500\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.2235 - accuracy: 0.9436\n",
            "Epoch 392/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2222 - accuracy: 0.9436\n",
            "Epoch 393/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2299 - accuracy: 0.9549\n",
            "Epoch 394/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2118 - accuracy: 0.9511\n",
            "Epoch 395/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2085 - accuracy: 0.9511\n",
            "Epoch 396/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2157 - accuracy: 0.9474\n",
            "Epoch 397/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9511\n",
            "Epoch 398/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1993 - accuracy: 0.9549\n",
            "Epoch 399/500\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2043 - accuracy: 0.9511\n",
            "Epoch 400/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.9474\n",
            "Epoch 401/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9474\n",
            "Epoch 402/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2004 - accuracy: 0.9624\n",
            "Epoch 403/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9511\n",
            "Epoch 404/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1956 - accuracy: 0.9398\n",
            "Epoch 405/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9624\n",
            "Epoch 406/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1910 - accuracy: 0.9624\n",
            "Epoch 407/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.9662\n",
            "Epoch 408/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1842 - accuracy: 0.9662\n",
            "Epoch 409/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1853 - accuracy: 0.9549\n",
            "Epoch 410/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1964 - accuracy: 0.9586\n",
            "Epoch 411/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9474\n",
            "Epoch 412/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9624\n",
            "Epoch 413/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1982 - accuracy: 0.9624\n",
            "Epoch 414/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2050 - accuracy: 0.9511\n",
            "Epoch 415/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1960 - accuracy: 0.9511\n",
            "Epoch 416/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9511\n",
            "Epoch 417/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9624\n",
            "Epoch 418/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1754 - accuracy: 0.9624\n",
            "Epoch 419/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9586\n",
            "Epoch 420/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1739 - accuracy: 0.9549\n",
            "Epoch 421/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1716 - accuracy: 0.9662\n",
            "Epoch 422/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1727 - accuracy: 0.9662\n",
            "Epoch 423/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.9662\n",
            "Epoch 424/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1708 - accuracy: 0.9586\n",
            "Epoch 425/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1671 - accuracy: 0.9662\n",
            "Epoch 426/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9624\n",
            "Epoch 427/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 0.9549\n",
            "Epoch 428/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1709 - accuracy: 0.9549\n",
            "Epoch 429/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9774\n",
            "Epoch 430/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9662\n",
            "Epoch 431/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9586\n",
            "Epoch 432/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9624\n",
            "Epoch 433/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1609 - accuracy: 0.9737\n",
            "Epoch 434/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9699\n",
            "Epoch 435/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1589 - accuracy: 0.9737\n",
            "Epoch 436/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9699\n",
            "Epoch 437/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1638 - accuracy: 0.9699\n",
            "Epoch 438/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9737\n",
            "Epoch 439/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1538 - accuracy: 0.9662\n",
            "Epoch 440/500\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1556 - accuracy: 0.9624\n",
            "Epoch 441/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1556 - accuracy: 0.9624\n",
            "Epoch 442/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.9662\n",
            "Epoch 443/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1511 - accuracy: 0.9662\n",
            "Epoch 444/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9699\n",
            "Epoch 445/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9699\n",
            "Epoch 446/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9662\n",
            "Epoch 447/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2082 - accuracy: 0.9549\n",
            "Epoch 448/500\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.2218 - accuracy: 0.9398\n",
            "Epoch 449/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9511\n",
            "Epoch 450/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2373 - accuracy: 0.9398\n",
            "Epoch 451/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2015 - accuracy: 0.9549\n",
            "Epoch 452/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1764 - accuracy: 0.9624\n",
            "Epoch 453/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9662\n",
            "Epoch 454/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.9662\n",
            "Epoch 455/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1558 - accuracy: 0.9662\n",
            "Epoch 456/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.9624\n",
            "Epoch 457/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9737\n",
            "Epoch 458/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9737\n",
            "Epoch 459/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.9737\n",
            "Epoch 460/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1464 - accuracy: 0.9737\n",
            "Epoch 461/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9737\n",
            "Epoch 462/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.9662\n",
            "Epoch 463/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9812\n",
            "Epoch 464/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9774\n",
            "Epoch 465/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.9850\n",
            "Epoch 466/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9774\n",
            "Epoch 467/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9737\n",
            "Epoch 468/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1339 - accuracy: 0.9774\n",
            "Epoch 469/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9737\n",
            "Epoch 470/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9624\n",
            "Epoch 471/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9850\n",
            "Epoch 472/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1425 - accuracy: 0.9850\n",
            "Epoch 473/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1559 - accuracy: 0.9662\n",
            "Epoch 474/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9699\n",
            "Epoch 475/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1395 - accuracy: 0.9737\n",
            "Epoch 476/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9850\n",
            "Epoch 477/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1286 - accuracy: 0.9850\n",
            "Epoch 478/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9850\n",
            "Epoch 479/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1253 - accuracy: 0.9737\n",
            "Epoch 480/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9850\n",
            "Epoch 481/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.9812\n",
            "Epoch 482/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1261 - accuracy: 0.9812\n",
            "Epoch 483/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1247 - accuracy: 0.9774\n",
            "Epoch 484/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9774\n",
            "Epoch 485/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.9737\n",
            "Epoch 486/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.9737\n",
            "Epoch 487/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1215 - accuracy: 0.9737\n",
            "Epoch 488/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9812\n",
            "Epoch 489/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9887\n",
            "Epoch 490/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9737\n",
            "Epoch 491/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9737\n",
            "Epoch 492/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9850\n",
            "Epoch 493/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1320 - accuracy: 0.9774\n",
            "Epoch 494/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9774\n",
            "Epoch 495/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.9850\n",
            "Epoch 496/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1249 - accuracy: 0.9850\n",
            "Epoch 497/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.9774\n",
            "Epoch 498/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.9812\n",
            "Epoch 499/500\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9850\n",
            "Epoch 500/500\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9812\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f0640f833a0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
        "\n",
        "# train the model\n",
        "# model.fit(x_train, y_train, epochs=epochs, callbacks=[early_stop])\n",
        "model.fit(x_train, y_train, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULgcEvLlhMXr",
        "outputId": "69fa3b53-f547-4d35-d23c-936e431ac2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (press 'q' to quit): hi\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "AI:  Hello there. Glad to see you're back. What's going on in your world right now?\n",
            "Input (press 'q' to quit): how are you\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "AI:  Hello, I am great, how are you? Please tell me your GeniSys user\n",
            "Input (press 'q' to quit): good morning\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "AI:  Good morning. I hope you had a good night's sleep. How are you feeling today? \n",
            "Input (press 'q' to quit): q\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    textList = []\n",
        "    prediction_input = []\n",
        "    user_input = input(\"Input (press 'q' to quit): \")\n",
        "    if user_input.lower() == 'q':\n",
        "        break\n",
        "    else:\n",
        "        for letter in user_input:\n",
        "            if letter not in string.punctuation:\n",
        "                prediction_input.append(letter.lower())\n",
        "\n",
        "        prediction_input = ''.join(prediction_input)\n",
        "        textList.append(prediction_input)\n",
        "\n",
        "        prediction_input = tokenizer.texts_to_sequences(textList)\n",
        "        prediction_input = np.array(prediction_input).reshape(-1)\n",
        "        prediction_input = pad_sequences([prediction_input], input_shape)\n",
        "\n",
        "        output = model.predict(prediction_input)\n",
        "        output = output.argmax()\n",
        "\n",
        "        response_tag = le.inverse_transform([output])[0]\n",
        "        print(\"AI: \", random.choice(responses[response_tag]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKl7dwU5hMU1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Vo7D1PwHHP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 935560,
          "sourceId": 1582026,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30035,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
