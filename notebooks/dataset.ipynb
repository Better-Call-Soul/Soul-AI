{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(path):\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= readFile('../data/raw/summarization/samsum/samsum-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n"
     ]
    }
   ],
   "source": [
    "print(data[\"dialogue\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                           dialogue  \\\n",
      "0  13862856  Hannah: Hey, do you have Betty's number?\\nAman...   \n",
      "1  13729565  Eric: MACHINE!\\nRob: That's so gr8!\\nEric: I k...   \n",
      "2  13680171  Lenny: Babe, can you help me with something?\\n...   \n",
      "3  13729438  Will: hey babe, what do you want for dinner to...   \n",
      "4  13828600  Ollie: Hi , are you in Warsaw\\nJane: yes, just...   \n",
      "\n",
      "                                             summary  \n",
      "0  Hannah needs Betty's number but Amanda doesn't...  \n",
      "1  Eric and Rob are going to watch a stand-up on ...  \n",
      "2  Lenny can't decide which trousers to buy. Bob ...  \n",
      "3  Emma will be home soon and she will let Will k...  \n",
      "4  Jane is in Warsaw. Ollie and Jane has a party....  \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "summaries = []\n",
    "labels = [1]\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    if len(data['dialogue'][i].split('\\r\\n')) > 1:\n",
    "        sentences =data['dialogue'][i].replace(\" |\", \" \").split('\\r\\n')\n",
    "        \n",
    "    else:\n",
    "        sentences =data['dialogue'][i].replace(\" |\", \" \").split('\\n')\n",
    "        \n",
    "    if len(sentences) == 1:\n",
    "        continue\n",
    "    summaries.append(data['summary'][i].strip('\\n').replace('\\r\\nt', ' '))\n",
    "    if len(labels) > 1:\n",
    "        \n",
    "        temp = ''\n",
    "        temp += sentences[0]\n",
    "        for j in range(1, len(sentences)):\n",
    "            if labels[i][j] != labels[i][j-1]:\n",
    "                \n",
    "                temp = temp + sep + sentences[j]\n",
    "            else:\n",
    "                temp = temp + ' ' + sentences[j]\n",
    "        temp += ' | '\n",
    "        conversations.append(temp)\n",
    "    elif labels[0] == 1:\n",
    "        conversations.append('' + ' </s><s> '.join(sentences))\n",
    "    elif labels[0] == 0:\n",
    "        conversations.append(' | ' + ' '.join(sentences))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah: Hey, do you have Betty's number? </s><s> Amanda: Lemme check </s><s> Hannah: <file_gif> </s><s> Amanda: Sorry, can't find it. </s><s> Amanda: Ask Larry </s><s> Amanda: He called her last time we were at the park together </s><s> Hannah: I don't know him well </s><s> Hannah: <file_gif> </s><s> Amanda: Don't be shy, he's very nice </s><s> Hannah: If you say so.. </s><s> Hannah: I'd rather you texted him </s><s> Amanda: Just text him ðŸ™‚ </s><s> Hannah: Urgh.. Alright </s><s> Hannah: Bye </s><s> Amanda: Bye bye\n"
     ]
    }
   ],
   "source": [
    "print(conversations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "print(summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the samsum dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the samsum dataset\n",
    "dataset = load_dataset(\"samsum\")\n",
    "\n",
    "# Convert dataset to pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv('samsum_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\python312\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eslam ashraf\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/536.6 kB 960.0 kB/s eta 0:00:01\n",
      "   ------ --------------------------------- 81.9/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 143.4/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 194.6/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 245.8/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 276.5/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 327.7/536.6 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------- ----------- 368.6/536.6 kB 995.6 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 419.8/536.6 kB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 471.0/536.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  532.5/536.6 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 536.6/536.6 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ------------- ------------------------- 41.0/116.3 kB 991.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 112.6/116.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 116.3/116.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/166.4 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 92.2/166.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  163.8/166.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 166.4/166.4 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)\n",
      "   ---------------------------------------- 0.0/363.4 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/363.4 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 112.6/363.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 163.8/363.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 225.3/363.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 276.5/363.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 337.9/363.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 363.4/363.4 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.7 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 41.0/146.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 112.6/146.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 146.7/146.7 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp312-cp312-win_amd64.whl (29 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 41.0/60.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 41.0/50.5 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/76.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.4/76.4 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, attrs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'c:\\\\Python312\\\\Scripts\\\\get_gprof'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
