{"cells":[{"cell_type":"code","execution_count":49,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-15T17:02:48.091201Z","iopub.status.busy":"2024-07-15T17:02:48.090780Z","iopub.status.idle":"2024-07-15T17:02:48.114807Z","shell.execute_reply":"2024-07-15T17:02:48.113957Z","shell.execute_reply.started":"2024-07-15T17:02:48.091138Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/news-summary/news_summary_more.csv\n","/kaggle/input/news-summary/news_summary.csv\n","/kaggle/input/wikihow-summarization/wikihowAll.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:02:48.142369Z","iopub.status.busy":"2024-07-15T17:02:48.142084Z","iopub.status.idle":"2024-07-15T17:02:54.608873Z","shell.execute_reply":"2024-07-15T17:02:54.607847Z","shell.execute_reply.started":"2024-07-15T17:02:48.142329Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: contractions in /opt/conda/lib/python3.7/site-packages (0.1.73)\n","Requirement already satisfied: textsearch>=0.0.21 in /opt/conda/lib/python3.7/site-packages (from contractions) (0.0.24)\n","Requirement already satisfied: anyascii in /opt/conda/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (1.4.0)\n"]}],"source":["!pip install contractions"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:02:54.612288Z","iopub.status.busy":"2024-07-15T17:02:54.611876Z","iopub.status.idle":"2024-07-15T17:03:00.640741Z","shell.execute_reply":"2024-07-15T17:03:00.639951Z","shell.execute_reply.started":"2024-07-15T17:02:54.612223Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('../input/wikihow-summarization/wikihowAll.csv', delimiter=',')\n"]},{"cell_type":"code","execution_count":52,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2024-07-15T17:03:00.642598Z","iopub.status.busy":"2024-07-15T17:03:00.642262Z","iopub.status.idle":"2024-07-15T17:03:00.653413Z","shell.execute_reply":"2024-07-15T17:03:00.652449Z","shell.execute_reply.started":"2024-07-15T17:03:00.642551Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n","  from pandas import Panel\n"]}],"source":["import numpy as np  \n","import pandas as pd \n","\n","import re\n","import nltk\n","\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords   \n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint,Callback\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm, tqdm_notebook\n","from tqdm._tqdm_notebook import tqdm_notebook\n","tqdm_notebook.pandas()\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:03:00.655386Z","iopub.status.busy":"2024-07-15T17:03:00.654982Z","iopub.status.idle":"2024-07-15T17:03:00.777990Z","shell.execute_reply":"2024-07-15T17:03:00.777243Z","shell.execute_reply.started":"2024-07-15T17:03:00.655327Z"},"trusted":true},"outputs":[],"source":["data = data.dropna()"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:03:00.781277Z","iopub.status.busy":"2024-07-15T17:03:00.780986Z","iopub.status.idle":"2024-07-15T17:03:07.284825Z","shell.execute_reply":"2024-07-15T17:03:07.283677Z","shell.execute_reply.started":"2024-07-15T17:03:00.781236Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspellchecker in /opt/conda/lib/python3.7/site-packages (0.8.1)\n"]}],"source":["!pip install pyspellchecker"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:03:07.289680Z","iopub.status.busy":"2024-07-15T17:03:07.289360Z","iopub.status.idle":"2024-07-15T17:03:07.344402Z","shell.execute_reply":"2024-07-15T17:03:07.343540Z","shell.execute_reply.started":"2024-07-15T17:03:07.289634Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.data import find\n","from nltk import download\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk import pos_tag\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","import contractions\n","import unicodedata\n","from bs4 import BeautifulSoup\n","import emoji\n","import re\n","from spellchecker import SpellChecker\n","from typing import List\n","\n","class Preprocessor:\n","\n","    resources = [\n","        'tokenizers/punkt',\n","        'corpora/stopwords',\n","        'corpora/wordnet',\n","        'taggers/averaged_perceptron_tagger'\n","    ]\n","\n","    def __init__(self) -> None:\n","        for resource in self.resources:\n","            try:\n","                find(resource)\n","                print(f\"{resource} is already downloaded.\")\n","            except LookupError:\n","                print(f\"{resource} not found. Downloading...\")\n","                download(resource.split('/')[1])\n","\n","        # Stopword removal\n","        self.stop_words = set(stopwords.words('english'))\n","        # Initialize the WordNet lemmatizer\n","        self.lemmatizer = WordNetLemmatizer()\n","\n","    def lower_sentence(self, sentence: str) -> str:\n","        '''\n","        Lowercase the sentence.\n","        :param data: The sentence to lowercase.\n","        :return: The lowercased sentence\n","        :rtype: str\n","        '''\n","        return sentence.lower()\n","\n","    def remove_emails(self, sentence: str) -> str:\n","        '''\n","        Remove emails from the sentence.\n","        :param sentence: The sentence to remove emails from.\n","        :type sentence: str\n","        :return: The sentence without emails.\n","        :rtype: str\n","        '''\n","        return re.sub(r\"\\S*@\\S*\\s?\", \"\", sentence)\n","\n","    def remove_nonascii_diacritic(self, sentence: str) -> str:\n","        '''\n","\n","        Remove diacritics from the sentence.\n","\n","        :param sentence: The sentence to remove diacritics from.\n","\n","        :type sentence: str\n","\n","        :return: The sentence without diacritics.\n","\n","        :rtype: str\n","        '''\n","\n","        return unicodedata.normalize(\"NFKD\", sentence).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n","\n","    def clean_html(self, sentence: str) -> str:\n","        '''\n","        Remove HTML tags from the sentence.\n","        :param sentence: The sentence to remove HTML tags from.\n","        :type sentence: str\n","        :return: The sentence without HTML tags.\n","        :rtype: str\n","        '''\n","        return BeautifulSoup(sentence, \"html.parser\").get_text()\n","\n","    def replace_repeated_chars(self, sentence: str) -> str:\n","        '''\n","        Replace repeated characters in the sentence.\n","        :param sentence: The sentence to replace repeated characters in.\n","        :type sentence: str\n","        :return: The sentence with replaced repeated characters.\n","        :rtype: str\n","        '''\n","        # Replace consecutive occurrences of ',', '!', '.', and '?' with a single occurrence\n","        return re.sub(r'([,!?.])\\1+', r'\\1', sentence)\n","\n","    def translate_emojis_to_text(self, sentence: str) -> str:\n","        '''\n","        Translate emojis in the sentence to text.\n","        :param sentence: The sentence to translate emojis to text.\n","        :type sentence: str\n","        :return: The sentence with translated emojis to text.\n","        :rtype: str\n","        '''\n","        line = ''\n","        for char in sentence:\n","            if emoji.is_emoji(char):\n","                emoji_text = emoji.demojize(char)[1:-1].replace('_', ' ')\n","                line += emoji_text\n","            else:\n","                line += char\n","\n","        return line\n","\n","    def expand_sentence(self, sentence: str) -> str:\n","        '''\n","        Expand the contractions in the sentence.\n","        :param sentence: The sentence to expand contractions in.\n","        :type sentence: str\n","        :return: The sentence with expanded contractions.\n","        :rtype: str\n","        '''\n","        return contractions.fix(sentence)\n","\n","    def remove_url(self, sentence: str) -> str:\n","        '''\n","        Remove URLs from the sentence.\n","        :param sentence: The sentence to remove URLs from.\n","        :type sentence: str\n","        :return: The sentence without URLs.\n","        :rtype: str\n","        '''\n","        return re.sub(\"((http\\://|https\\://|ftp\\://)|(www.))+(([a-zA-Z0-9\\.-]+\\.[a-zA-Z]{2,4})|([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(/[a-zA-Z0-9%:/-_\\?\\.'~]*)?\", '', sentence)\n","\n","    def remove_possessives(self, sentence: str) -> str:\n","        '''\n","        Strip possessives from the sentence.\n","        :param sentence: The sentence to strip possessives from.\n","        :type sentence: str\n","        :return: The sentence without possessives.\n","        :rtype: str\n","        '''\n","        # Stripping the possessives\n","        sentence = sentence.replace(\"'s\", '')\n","        sentence = sentence.replace('’s', '')\n","        sentence = sentence.replace('s’', 's')\n","        sentence = sentence.replace(\"s'\", 's')\n","        return sentence\n","\n","    def remove_extra_space(self, sentence: str) -> str:\n","        '''\n","        Remove extra spaces from the sentence.\n","        :param sentence: The sentence to remove extra spaces from.\n","        :type sentence: str\n","        :return: The sentence without extra spaces.\n","        :rtype: str\n","        '''\n","        return re.sub(r'\\s+', ' ', sentence).strip()\n","\n","\n","    def check_sentence_spelling(self, sentence: List[str]) -> List[str]:\n","        '''\n","        Check the spelling of the words in the sentence.\n","        :param sentence: The sentence to check the spelling of.\n","        :type sentence: list\n","        :return: The sentence with corrected spelling.\n","        :rtype: list\n","        '''\n","        spell = SpellChecker()\n","        corrected_sentence = []\n","        for word in sentence:\n","            if word != '':\n","                correction = spell.correction(word)\n","                if correction is not None:\n","                    corrected_sentence.append(correction)\n","                else:\n","                    corrected_sentence.append(word)\n","            else:\n","                corrected_sentence.append('')\n","        return corrected_sentence\n","\n","    def tokenize_sentence(self, sentence: str) -> List[str]:\n","        '''\n","        Tokenize the sentence.\n","        :param sentence: The sentence to tokenize.\n","        :type sentence: str\n","        :return: The tokenized sentence.\n","        :rtype: str\n","        '''\n","        return nltk.word_tokenize(sentence)\n","\n","\n","    def remove_stop_words(self, sentence: List[str]) -> List[str]:\n","        '''\n","        Remove stop words from the sentence.\n","        :param sentence: The sentence to remove stop words from.\n","        :type sentence: list[str]\n","        :return: The sentence without stop words.\n","        :rtype: list[str]\n","        '''\n","        return [word for word in sentence if word not in self.stop_words]\n","\n","    def lemm_sentence(self, sentence: List[str]) -> List[str]:\n","        '''\n","        Lemmatize the sentence.\n","        :param sentence: The sentence to lemmatize.\n","        :type sentence: list[str]\n","        :return: The lemmatized sentence.\n","        :rtype: list[str]\n","        '''\n","        # Perform POS tagging\n","        pos_tags = pos_tag(sentence)\n","        # Lemmatize each word based on its POS tag\n","        lemmatized_words = []\n","        for word, pos in pos_tags:\n","            # Map Penn Treebank POS tags to WordNet POS tags\n","            if pos.startswith('N'):  # Nouns\n","                pos = 'n'\n","            elif pos.startswith('V'):  # Verbs\n","                pos = 'v'\n","            elif pos.startswith('J'):  # Adjectives\n","                pos = 'a'\n","            elif pos.startswith('R'):  # Adverbs\n","                pos = 'r'\n","            else:\n","                pos = 'n'  # Default to noun if POS tag not found\n","\n","            # Lemmatize the word using the appropriate POS tag\n","            lemma = self.lemmatizer.lemmatize(word, pos=pos)\n","            lemmatized_words.append(lemma)\n","        return lemmatized_words\n","\n","    def detokenize_sentence(self, sentence: List[str]) -> str:\n","        '''\n","        Detokenize the sentence.\n","        :param sentence: The sentence to detokenize.\n","        :type sentence: list[str]\n","        :return: The detokenized sentence.\n","        :rtype: str\n","        '''\n","        return TreebankWordDetokenizer().detokenize(sentence)\n","\n","    def remove_emojis(self,text:str) -> str:\n","        '''\n","        Removes specific patterns like (😃,🚀) and emojis from the given text.\n","        :type text: list[str]\n","        :return: Text without emojis.\n","        :rtype: str\n","        '''\n","        emoji_pattern = re.compile(\"[\"\n","                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                u\"\\U00002500-\\U00002BEF\"  # chinese char\n","                u\"\\U00002700-\\U000027BF\"  # Dingbats\n","                u\"\\U00002702-\\U000027B0\"\n","                u\"\\U000024C2-\\U0001F251\"\n","                u\"\\U0001f926-\\U0001f937\"\n","                u\"\\U00010000-\\U0010ffff\"\n","                u\"\\u2640-\\u2642\"\n","                u\"\\u2600-\\u2B55\"\n","                u\"\\u200d\"\n","                u\"\\u23cf\"\n","                u\"\\u23e9\"\n","                u\"\\u231a\"\n","                u\"\\u3030\"\n","                \"]+\", flags=re.UNICODE)\n","        text = emoji_pattern.sub(r'', text)\n","\n","        return text\n","\n","    def remove_emoticons(self,text:str) -> str:\n","        '''\n","        Removes specific patterns like[:) | :(] and emoticons from the given text.\n","        :type text: list[str]\n","        :return: Text without emoticons.\n","        :rtype: str\n","        '''\n","        # Define a regular expression pattern to match emoticons\n","        emoticon_pattern = re.compile(r':(\\)+)|:-(\\))+|;(\\))+|:-(D)+|:(D)+|;-(D)+|x(D)+|X(D)+|:-(\\()+|:(\\()+|:-(/)+|:(/)+|:-(\\))+||:(\\))+||:-(O)+|:(O)+|:-(\\*)+|:(\\*)+|<(3)+|:(P)+|:-(P)+|;(P)+|;-(P)+|:(S)+|>:(O)+|8(\\))+|B-(\\))+|O:(\\))+', flags=re.IGNORECASE)\n","        # Remove emoticons using the pattern\n","        return emoticon_pattern.sub('', text)\n","\n","    def remove_non_alphabetic(self,text:str) -> str:\n","        '''\n","        Removes non-alphabetic characters from the given text.\n","        :type text: str\n","        :return: Text without non-alphabetic characters.\n","        :rtype: str\n","        '''\n","        cleaned_text = re.sub(r'\\W+', ' ', text)\n","        return cleaned_text\n","\n","    def clean(self, line: str, steps: List[str] = None, empty: str ='Normal') -> List[str]:\n","        '''\n","        Clean the line and return it as a list of tokens\n","        :param line: the line to clean\n","        :type line: str\n","        :param steps: list of steps to apply\n","        :type steps: list[str]\n","        :return: the cleaned line as a list of tokens\n","        :rtype: list\n","        '''\n","        # Default steps to apply if none are specified\n","        default_steps = [\n","            'translate_emojis_to_text',\n","            'lower_sentence',\n","            'remove_nonascii_diacritic',\n","            'remove_emails',\n","            'clean_html',\n","            'remove_url',\n","            'replace_repeated_chars',\n","            'expand_sentence',\n","            'remove_possessives',\n","            'remove_extra_space',\n","            'tokenize_sentence',\n","            'check_sentence_spelling',\n","            'remove_stop_words',\n","            'lemm_sentence'\n","        ]\n","\n","        # Use specified steps if provided, otherwise use default steps\n","        if steps is None:\n","            steps = default_steps\n","\n","        # Define the processing functions\n","        processing_functions = {\n","            'translate_emojis_to_text': self.translate_emojis_to_text,\n","            'lower_sentence': self.lower_sentence,\n","            'remove_nonascii_diacritic': self.remove_nonascii_diacritic,\n","            'remove_emails': self.remove_emails,\n","            'clean_html': self.clean_html,\n","            'remove_url': self.remove_url,\n","            'replace_repeated_chars': self.replace_repeated_chars,\n","            'expand_sentence': self.expand_sentence,\n","            'remove_possessives': self.remove_possessives,\n","            'remove_extra_space': self.remove_extra_space,\n","            'tokenize_sentence': self.tokenize_sentence,\n","            'check_sentence_spelling': self.check_sentence_spelling,\n","            'remove_stop_words': self.remove_stop_words,\n","            'lemm_sentence': self.lemm_sentence,\n","            'detokenize_sentence': self.detokenize_sentence,\n","            'remove_emojis': self.remove_emojis,\n","            'remove_emoticons': self.remove_emoticons,\n","            'remove_non_alphabetic': self.remove_non_alphabetic\n","        }\n","\n","        # Apply the specified steps\n","        for step in steps:\n","            if step in processing_functions:\n","                line = processing_functions[step](line)\n","\n","        # Ensure tokenize_sentence was applied\n","        if isinstance(line, str):\n","            line = [line]\n","\n","        if len(line) == 0:\n","            return [empty]\n","\n","        return line\n","     \n","\n"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:03:07.346253Z","iopub.status.busy":"2024-07-15T17:03:07.345930Z","iopub.status.idle":"2024-07-15T17:03:07.361354Z","shell.execute_reply":"2024-07-15T17:03:07.360546Z","shell.execute_reply.started":"2024-07-15T17:03:07.346195Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers/punkt is already downloaded.\n","corpora/stopwords is already downloaded.\n","corpora/wordnet is already downloaded.\n","taggers/averaged_perceptron_tagger is already downloaded.\n"]}],"source":["preprocess=Preprocessor()"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:03:07.363374Z","iopub.status.busy":"2024-07-15T17:03:07.362887Z","iopub.status.idle":"2024-07-15T17:41:39.936841Z","shell.execute_reply":"2024-07-15T17:41:39.936062Z","shell.execute_reply.started":"2024-07-15T17:03:07.363156Z"},"trusted":true},"outputs":[],"source":["\n","def clean_text_wiki(text):\n","\n","    clean_text=preprocess.clean(text,\n","            [\"lower_sentence\",\"remove_emojis\",\"remove_emoticons\",\"remove_nonascii_diacritic\",\n","            \"remove_emails\",\"clean_html\",\n","            \"remove_url\",\"replace_repeated_chars\",\"expand_sentence\",\n","            \"remove_extra_space\",\"tokenize_sentence\",\"remove_stop_words\",\"detokenize_sentence\"]\n","            ,\"\")[0]\n","    return clean_text\n","\n","cleaning_text = []\n","\n","for t in data['text']:\n","    cleaning_text.append(clean_text_wiki(t))"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:41:39.939035Z","iopub.status.busy":"2024-07-15T17:41:39.938618Z","iopub.status.idle":"2024-07-15T17:43:24.080184Z","shell.execute_reply":"2024-07-15T17:43:24.079290Z","shell.execute_reply.started":"2024-07-15T17:41:39.938964Z"},"trusted":true},"outputs":[],"source":["def clean_summary_wiki(text):\n","\n","    clean_text=preprocess.clean(text,\n","            [\"lower_sentence\",\"remove_emojis\",\"remove_emoticons\",\"remove_nonascii_diacritic\",\n","            \"remove_emails\",\"clean_html\",\n","            \"remove_url\",\"replace_repeated_chars\",\"expand_sentence\",\n","            \"remove_extra_space\"]\n","            ,\"\")[0]\n","    return clean_text\n","\n","\n","cleaning_summary = []\n","for t in data['headline']:\n","    cleaning_summary.append(clean_summary_wiki(t))\n","\n"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-15T12:48:25.943058Z","iopub.status.busy":"2024-07-15T12:48:25.942578Z","iopub.status.idle":"2024-07-15T12:48:25.953155Z","shell.execute_reply":"2024-07-15T12:48:25.952269Z","shell.execute_reply.started":"2024-07-15T12:48:25.942953Z"}},"source":["#### save cleaning text"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:24.081909Z","iopub.status.busy":"2024-07-15T17:43:24.081584Z","iopub.status.idle":"2024-07-15T17:43:24.474185Z","shell.execute_reply":"2024-07-15T17:43:24.473433Z","shell.execute_reply.started":"2024-07-15T17:43:24.081859Z"},"trusted":true},"outputs":[],"source":["data['cleaning_text'] = cleaning_text\n","data['cleaning_summary'] = cleaning_summary\n","data['cleaning_summary']=data['cleaning_summary'].replace('', np.nan)\n","data['cleaning_text']=data['cleaning_text'].replace('', np.nan)\n","\n","data=data.dropna(axis = 0)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:24.475893Z","iopub.status.busy":"2024-07-15T17:43:24.475493Z","iopub.status.idle":"2024-07-15T17:43:24.481459Z","shell.execute_reply":"2024-07-15T17:43:24.480586Z","shell.execute_reply.started":"2024-07-15T17:43:24.475831Z"},"trusted":true},"outputs":[{"data":{"text/plain":["214293"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["len(data)"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:24.483254Z","iopub.status.busy":"2024-07-15T17:43:24.482918Z","iopub.status.idle":"2024-07-15T17:43:24.509488Z","shell.execute_reply":"2024-07-15T17:43:24.508763Z","shell.execute_reply.started":"2024-07-15T17:43:24.483203Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["text:  photographer,keep necessary lens,cords,batteries quadrant home studio . paints kept brushes,cleaner,canvas,print supplies ink,etc . make broader groups areas supplies make finding easier,limiting search much smaller area . ideas include:essential supplies area--things use every day . inspiration reference area . dedicated work area . infrequent secondary supplies area,tucked way .;,mean cleaning entire studio,means keeping area immediately around desk,easel,pottery wheel,etc . clean night . discard trash unnecessary materials wipe dirty surfaces . endeavor leave workspace way sit next day start working immediately,without work tidying . even rest studio bit disorganized,organized workspace help get business every time want make art .,visual people,lot artist clutter comes desire keep track supplies visually instead tucked sight . using jars,old glasses,vases,cheap,clear plastic drawers,keep things sight without leaving strewn haphazardly . ideas,beyond mentioned,include:canvas shoe racks back door wine racks cups slot hold pens/pencils . plastic restaurant squirt bottles paint,pigment,etc.,simply string wires across wall along ceiling use hold essential papers want cut ruin tacks tape . cheap easy,also good way handle papers ideas touch regularly need pin inspiration.,shelving artist's best friend cheap easy way get room studio art space . afraid get high either,especially infrequently used supplies . upper reaches room often under-utilized,provide vital space tools materials.,turning one wall chalkboard gives perfect space ideas,sketches,planning without requiring extra equipment space . even use smaller areas . paint jars storage equipment,allowing relabel chalk needs change .,lot disorganization comes keep moving location things,trying optimize space reorganizing frequently . usually opposite effect,leading lost items uncertainty cleaning,afternoon label maker solve everything . instead spending mental energy looking storing things,follow labels,freeing mind think art.,month,purge studio . essential part project,either throw file away later . artists constantly making new things,experimenting,making mess . good thing,set aside time declutter . may fun moment,lot fun spending 30 minutes digging junk find right paint old sketch . sentimental . used last six months little chance use next six months . toss.\n","summary:  keep related supplies in the same area., make an effort to clean a dedicated workspace after every session., place loose supplies in large, clearly visible containers., use clotheslines and clips to hang sketches, photos, and reference material., use every inch of the room for storage, especially vertical space., use chalkboard paint to make space for drafting ideas right on the walls., purchase a label maker to make your organization strategy semi-permanent., make a habit of throwing out old, excess, or useless stuff each month.\n","\n","\n","text:  see image drawing develops step-by-step . however,important detail:following drawings examine,, create something unique . use lines create image shape sections . fill appeared sections different patterns/ ornaments . add text needed,example``neopoprealism 25 !\"add colored strip top,color wish .;,painting mural always requires preparation . need equipment effort,planning attention detail help succeed . painting mural requires suitable location,right surface painted . surface smooth flat . however,even rough-textured surfaces used neopoprealist mural project .,exterior projects last years,using newer 100% acrylic exterior paint would best choice . interior walls,use latex paints . latex offer easier cleanup lower costs . measuring total wall area covered,total amount paint calculated,since mural painting requires two colors - white black - figuring actual area painted color necessary allow purchasing right amount one . large walls backgrounds may rolled sprayed white paint sprayer,details may added brushes . paints sensitive high temperatures,humidity,direct sunlight,however,interior projects many complications . public places,keeping mural protected may require attention . reason,make neopoprealist mural dedicated 25-year anniversary school office,consider using varnish mural .,see sample . design give sense proportion . unique requirements elements.,use sketch measure scale distances locations various points subject . measuring key features help calculate amount paint feature identified color.,surface low,whole mural painted standing ground stepladder . higher work,may rent scaffold.,mark horizontal vertical lines.,use white paint background.,begin marking,using scaled sketch,location key elements objects,located foreground . everything depends complexity mural . confident artistic results,may choose draw details freehand.,careful,keep clean transition edges one color (black) another (white). however,mistakes touched later . always allow fresh color dry proceeding drawing.,example would painting large patterns use big brushes,limbs,use small brushes tiny detailed patterns.,drip run,paint color paint appropriate location . sharpen lines patterns blurred.,intended last long time surface require cleaning,overcoat mural project clear sealer.,however,able involve 16 percent brain's grays matter,end primitive crafting patterns even worse,doodling so-called zen-doodling . create neopoprealist art one needs abilities,developed talented people studying using nadia russ' neopoprealist instructional books .,copycats' self-promotional superficial books teach doodle nothing common visual arts mission.\n","summary:  create a sketch in the neopoprealist manner of the future mural on a small piece of paper 8\"x10\" using the black ink pen., prepare to create your neopoprealist mural., prepare your paint., begin your project with a design., produce a scaled down version of your finished mural., prepare the wall to be painted., after you have primed the surface, measure the wall., paint in the base coat of the background., allow the background and base coats to dry., draw the lines, then fill the appeared section with different repetitive patterns (examine the images above)., paint patterns with brushes of suitable size for the particular portion of work you are painting., clean up the lines and shapes as needed., seal the mural if needed., be inspired and it will help you succeed!\n","\n","\n","text:  possible become vfx artist without college degree,path often easier one . vfx artists usually major fine arts,computer graphics,animation . choose college reputation strength areas reputation good job placement graduates . availability internships another factor consider.out jobs advertised vfx artists,majority given time specify bachelors degree minimum requirement applicants .;,studios offer short-term programs people want learn vfx artistry without pursuing college degree . enrolling programs expensive financial aid always offered,usually cutting edge technology learn from.,although may create hand sketches,majority work completed computer using up-to-date programs . stay informed newest software advances following vfx blogs taking online computer tutorials.for example,vfx artists expected well-versed graphics animation programs,adobe creative suite javascript.clearly list every program work resume .,hop onto youtube another video service search vfx clip reels demonstrations . videos focus particular skill set,shading,practice . challenge mimic difficult tasks,even try improve upon models used.,take many art design classes .,simply carry sketch pad around work basic animation skills . draw,consider factors lighting framing . even geometry skills come handy creating particular type background even persons face.make choice become observer world around . ask:could capture movement leaves?, situations shadows appear?, watch creations eye detail . look techniques used original approaches see . try recreate scenes find particularly interesting . research artists see backgrounds contact like.,gain experience,likely find gravitating toward certain aspect design . become calling card directors professionals seek type work . build specialization,start choosing jobs emphasis attend additional training seminars.for example,vfx specialists focus human characters faces,animal figures,city backgrounds.\n","summary:  get a bachelors degree., enroll in a studio-based program., train on a number of vfx computer programs., watch online tutorials., nurture your artistic side., pay close attention to movies, television shows, and video games., develop a specialization.\n","\n","\n","text:  best art investors research pieces art buy,someone education interest art world likely understand niche market . well personal research,need contacts people art world,auctioneers,gallery directors dealers,give good investment advice .;,may confuse three terms,careful . slightly different goal mind looking buy art . art collectors buy art investment purposes . buy decorate display home . consider important part home life,art collectors hard time parting pieces collection . many collectors end selling pieces art,may done necessity . collectors often loan works museums occasionally donate museums upon death . art investors seek diversify portfolio art investment . investment firms put two half three percent investment money art . seek good advice often buy paintings older popular historically,paintings old masters . investments kept decades,sold market right,investor seeking get six ten percent profit rise per year . investments also often made given inheritance future generations family . art investment often undertaken wealthy . art speculators try invest art believe appreciate value . aim buy art low price budding artists beginning careers . hope sell work 10 15 years artists peak careers people collectors willing pay much pieces . type investment takes intimate involvement art world liquidity order buy art .,art investments small part investment portfolio,along stocks,bonds,new businesses . figure range begin pick potential pieces,get advice investors art dealers .,study mei moses fine art index get firm grasp art market today . although predict popular future,tell art tends keep value low-risk art volatile market value .,absolute rule follow,paintings successful artists tend get better returns sculpture installation art .,get information making purchase . going buy auction,prepared walk away price goes higher investment range . beware art auctioneers dealers promise high return paintings . many ways,like stock brokers financial investment firms,may promise anything get sale . found trustworthy buy anything,ponzi schemes art market bubbles part investment landscape well . never bought art auction environment,may want seek advice done properly . study auction booklet hand,learn secret buyers prices quickly inflate . fine auction houses would willing teach basics see serious investor .,arrange payment,shipping insurance . piece art insured catalogued part estate .,order art investment retain value,kept low-humidity avoid marred . may choose hang home,may want get art collector's advice hang care . share information children,intended inheritance investment . need well aware take care art,may lose money ruin painting entirely .,well keeping tabs art world understand rise falls certain schools art,appraiser tell investment maturing . may clue reached desired profit .,art buy fit home,storing,research banks,hotels institutions rent fine art rotating basis . may able demand thousands dollars per year art hang another building . keep mind need make sure art covered insurance policy loss damage . make sure renter provides insurance art . prepare contract stipulates time allotted,fee,insurance shipment art .,unless employ art dealer auction house exact moment art high value,take years thousands dollars fees find right buyer.\n","summary:  start with some experience or interest in art., understand the difference between art collectors, art investors and art speculators., figure out what you are willing to pay for art, before going to an auction house., pay attention to what schools of art are selling well, and which are down., focus art investments on fine art paintings, rather than decorative art., reach out to trusted auction houses and dealers when you are looking to buy art., buy your investment art when you feel confident of its worth, its price and its ability to grow in value., study how art is properly stored., have your art investments appraised occasionally., consider renting out your art investments., understand that selling an art investment can take time.\n","\n","\n","text:  start planning project work,likely gathering scraps inspiration test sketches . everyone strategy,nothing maddening digging book internet re-find cool idea saw three months ago . try:dedicating 1 notebook,preferably insert folders,project . making bookmark folder project internet browser easily compile online inspiration . tacking physical inspiration wall cork board near workspace.,artists simply dive right large projects . almost 100% time instead work related,smaller projects called``studies\"prepare larger work . might practice face portrait making,sketch different composition ideas,practice vulnerable difficult part sculpture . keep organized way prepare skills,ideas,supplies needed final project .,end day,artists visual people,tucking everything away neatly cleanly may conducive artistic process . course,neither losing misplacing essential supplies . find compromise packing away supplies currently use,leaving little bit``essential\"clutter . okay inspiration scattered around studio--make sure inspiration need current project .``organized\"excuse make attempt . feel like options perfect cleanliness utter mess--middle ground .,nothing worse spending long night painting realize run white paint halfway section . week,frequently possible,check quantities supplies refill becomes problem . simple spreadsheet notebook,marked end artistic session,quick easy way keep tabs stuff .,deciding paint mural huge undertaking . sketching idea,transposing image onto wall,painting basic colors,adding shading/detail four separate manageable projects . organization key big projects,even feels``constraining\"creativity . reality,organizing work progress frees mind actually creative,instead worrying logistics . figure building blocks part project,tackling . jump around across parts project haphazardly.\n","summary:  keep your reference materials, sketches, articles, photos, etc, in one easy to find place., make \"studies,\" or practice sketches, to organize effectively for larger projects., limit the supplies you leave out to the project at hand., keep an updated list of all of the necessary supplies, and the quantities of each., break down bigger works into more easily completed parts.\n","\n","\n"]}],"source":["for i in range(5):\n","    print(\"text: \",data['cleaning_text'][i])\n","    print(\"summary: \",data['cleaning_summary'][i])\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-15T12:48:26.134810Z","iopub.status.busy":"2024-07-15T12:48:26.134412Z","iopub.status.idle":"2024-07-15T12:48:26.150813Z","shell.execute_reply":"2024-07-15T12:48:26.149772Z","shell.execute_reply.started":"2024-07-15T12:48:26.134751Z"}},"source":["## Graph for show len of text and summary"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:24.511061Z","iopub.status.busy":"2024-07-15T17:43:24.510789Z","iopub.status.idle":"2024-07-15T17:43:24.514682Z","shell.execute_reply":"2024-07-15T17:43:24.513636Z","shell.execute_reply.started":"2024-07-15T17:43:24.511022Z"},"trusted":true},"outputs":[],"source":["text_counter = []\n","summary_counter = []"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:24.516110Z","iopub.status.busy":"2024-07-15T17:43:24.515805Z","iopub.status.idle":"2024-07-15T17:43:28.546455Z","shell.execute_reply":"2024-07-15T17:43:28.545751Z","shell.execute_reply.started":"2024-07-15T17:43:24.516051Z"},"trusted":true},"outputs":[],"source":["for sentance in data['cleaning_text']:\n","    text_counter.append(len(sentance.split()))\n","for sentance in data['cleaning_summary']:\n","    summary_counter.append(len(sentance.split()))"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:28.548081Z","iopub.status.busy":"2024-07-15T17:43:28.547799Z","iopub.status.idle":"2024-07-15T17:43:28.558608Z","shell.execute_reply":"2024-07-15T17:43:28.557763Z","shell.execute_reply.started":"2024-07-15T17:43:28.548042Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6759\n","84\n"]}],"source":["print(max(text_counter))\n","print((summary_counter[0]))"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:28.560271Z","iopub.status.busy":"2024-07-15T17:43:28.559980Z","iopub.status.idle":"2024-07-15T17:43:28.569740Z","shell.execute_reply":"2024-07-15T17:43:28.568969Z","shell.execute_reply.started":"2024-07-15T17:43:28.560229Z"},"trusted":true},"outputs":[],"source":["# # plotting the data\n","# plt.figure(figsize=(14, 7))\n","\n","# # plotting the distribution of text lengths\n","# plt.subplot(1, 2, 1)\n","# sns.histplot(text_counter, kde=True, color='blue', bins=150)\n","# plt.title('Distribution of Text Sentence Lengths')\n","# plt.xlabel('Number of Words')\n","# plt.ylabel('Frequency')\n","\n","# # plotting the distribution of summary lengths\n","# plt.subplot(1, 2, 2)\n","# sns.histplot(summary_counter, kde=True, color='green', bins=150)\n","# plt.title('Distribution of Summary Sentence Lengths')\n","# plt.xlabel('Number of Words')\n","# plt.ylabel('Frequency')\n","\n","# plt.tight_layout()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:28.571264Z","iopub.status.busy":"2024-07-15T17:43:28.570886Z","iopub.status.idle":"2024-07-15T17:43:29.552034Z","shell.execute_reply":"2024-07-15T17:43:29.550887Z","shell.execute_reply.started":"2024-07-15T17:43:28.571212Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.34163038456692474\n"]}],"source":["count=0\n","for row in data['cleaning_summary']:\n","    if(len(row.split())<=30):\n","        count=count+1\n","print(count/len(data['cleaning_summary']))"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:29.554003Z","iopub.status.busy":"2024-07-15T17:43:29.553595Z","iopub.status.idle":"2024-07-15T17:43:32.802340Z","shell.execute_reply":"2024-07-15T17:43:32.801414Z","shell.execute_reply.started":"2024-07-15T17:43:29.553942Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.4959331382732987\n"]}],"source":["count=0\n","for row in data['cleaning_text']:\n","    if(len(row.split())<=150):\n","        count=count+1\n","print(count/len(data['cleaning_text']))"]},{"cell_type":"markdown","metadata":{},"source":["# Select the Summaries and Text between max len defined above"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:32.804261Z","iopub.status.busy":"2024-07-15T17:43:32.803943Z","iopub.status.idle":"2024-07-15T17:43:32.808193Z","shell.execute_reply":"2024-07-15T17:43:32.807372Z","shell.execute_reply.started":"2024-07-15T17:43:32.804204Z"},"trusted":true},"outputs":[],"source":["limit_text_len = 70\n","limit_summary_len = 20"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:32.809878Z","iopub.status.busy":"2024-07-15T17:43:32.809564Z","iopub.status.idle":"2024-07-15T17:43:34.219760Z","shell.execute_reply":"2024-07-15T17:43:34.218927Z","shell.execute_reply.started":"2024-07-15T17:43:32.809828Z"},"trusted":true},"outputs":[],"source":["## delete all lenght larger than limitations\n","\n","cleaned_text =np.array(data['cleaning_text'])\n","cleaned_summary=np.array(data['cleaning_summary'])\n","\n","short_text=[]\n","short_summary=[]\n","\n","for i in range(len(cleaned_text)):\n","    if(len(cleaned_summary[i].split())<=limit_summary_len and len(cleaned_text[i].split())<=limit_text_len):\n","        short_text.append(cleaned_text[i])\n","        short_summary.append(cleaned_summary[i])\n","        \n","data=pd.DataFrame({'cleaning_text':short_text,'cleaning_summary':short_summary})"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.223467Z","iopub.status.busy":"2024-07-15T17:43:34.223135Z","iopub.status.idle":"2024-07-15T17:43:34.234868Z","shell.execute_reply":"2024-07-15T17:43:34.233811Z","shell.execute_reply.started":"2024-07-15T17:43:34.223420Z"},"trusted":true},"outputs":[],"source":["data['cleaning_summary'] = data['cleaning_summary'].apply(lambda x : 'sostok '+ x + ' eostok')"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.236640Z","iopub.status.busy":"2024-07-15T17:43:34.236266Z","iopub.status.idle":"2024-07-15T17:43:34.249847Z","shell.execute_reply":"2024-07-15T17:43:34.248466Z","shell.execute_reply.started":"2024-07-15T17:43:34.236592Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0       sostok tie up your horse., groom your horse. e...\n","1       sostok introduce yourself to his friends., tal...\n","2       sostok learn what he likes., ask him what he t...\n","3       sostok once again, if he says no, just shake i...\n","4       sostok eye contact., physical contact., jealou...\n","                              ...                        \n","8243      sostok determine how you think of books. eostok\n","8244    sostok shelve all of your books alphabetically...\n","8245    sostok place the books on the shelf according ...\n","8246    sostok this technique can also be a sub-techni...\n","8247    sostok use chrome to plate metals subject to c...\n","Name: cleaning_summary, Length: 8248, dtype: object"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["data['cleaning_summary']"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-15T12:49:23.221214Z","iopub.status.busy":"2024-07-15T12:49:23.220851Z","iopub.status.idle":"2024-07-15T12:49:23.225379Z","shell.execute_reply":"2024-07-15T12:49:23.224378Z","shell.execute_reply.started":"2024-07-15T12:49:23.221165Z"}},"source":["## split data "]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.251758Z","iopub.status.busy":"2024-07-15T17:43:34.251361Z","iopub.status.idle":"2024-07-15T17:43:34.263729Z","shell.execute_reply":"2024-07-15T17:43:34.262763Z","shell.execute_reply.started":"2024-07-15T17:43:34.251710Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","## split train , test and val \n","x_tr, x_temp, y_tr, y_temp = train_test_split(np.array(data['cleaning_text']), np.array(data['cleaning_summary']),\n","                                              test_size=0.2, random_state=0, shuffle=True)\n","\n","x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=0, shuffle=True)\n"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.265593Z","iopub.status.busy":"2024-07-15T17:43:34.265251Z","iopub.status.idle":"2024-07-15T17:43:34.620305Z","shell.execute_reply":"2024-07-15T17:43:34.619581Z","shell.execute_reply.started":"2024-07-15T17:43:34.265545Z"},"trusted":true},"outputs":[],"source":["x_tokenizer = Tokenizer() \n","x_tokenizer.fit_on_texts(list(x_tr))"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.622135Z","iopub.status.busy":"2024-07-15T17:43:34.621811Z","iopub.status.idle":"2024-07-15T17:43:34.640999Z","shell.execute_reply":"2024-07-15T17:43:34.640098Z","shell.execute_reply.started":"2024-07-15T17:43:34.622082Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["percentage of rare words in vocabulary: 40.04414163707897\n","total coverage of rare words in data: 3.22236893923599\n"]}],"source":["therold_count = 2\n","\n","count = 0\n","total_count = 0\n","frequnecy = 0\n","total_freq = 0\n","\n","for key,counter in x_tokenizer.word_counts.items():\n","    total_count = total_count + 1\n","    total_freq = total_freq + counter\n","    if(counter < therold_count):\n","        count = count + 1\n","        frequnecy = frequnecy + counter\n","    \n","print(\"percentage of rare words in vocabulary:\", (count/total_count) * 100)\n","print(\"total coverage of rare words in data:\", (frequnecy/total_freq) * 100)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:34.643128Z","iopub.status.busy":"2024-07-15T17:43:34.642741Z","iopub.status.idle":"2024-07-15T17:43:35.355059Z","shell.execute_reply":"2024-07-15T17:43:35.354074Z","shell.execute_reply.started":"2024-07-15T17:43:34.643071Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["size of vocabulary in X = 12497\n"]}],"source":["x_tokenizer = Tokenizer(num_words = total_count-count) \n","x_tokenizer.fit_on_texts(list(x_tr))\n","\n","#convert text sequences into integer sequences \n","x_train_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n","x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n","\n","# padding zero upto maximum length\n","x_train_pad  =  pad_sequences(x_train_seq,  maxlen = limit_text_len, padding = 'post')\n","x_val_pad   =  pad_sequences(x_val_seq, maxlen = limit_text_len, padding = 'post')\n","\n","# size of vocabulary ( +1 for padding token)\n","x_vocabulary   =  x_tokenizer.num_words + 1\n","\n","print(\"size of vocabulary in X = {}\".format(x_vocabulary))"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:35.358416Z","iopub.status.busy":"2024-07-15T17:43:35.357954Z","iopub.status.idle":"2024-07-15T17:43:35.545738Z","shell.execute_reply":"2024-07-15T17:43:35.544598Z","shell.execute_reply.started":"2024-07-15T17:43:35.358244Z"},"trusted":true},"outputs":[],"source":["y_tokenizer = Tokenizer()   \n","y_tokenizer.fit_on_texts(list(y_tr))"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:35.547667Z","iopub.status.busy":"2024-07-15T17:43:35.547268Z","iopub.status.idle":"2024-07-15T17:43:35.562989Z","shell.execute_reply":"2024-07-15T17:43:35.561797Z","shell.execute_reply.started":"2024-07-15T17:43:35.547606Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["percentage of rare words in vocabulary: 47.7267943590823\n","total coverage of rare words in data: 4.451140512739979\n"]}],"source":["therold_count = 2\n","\n","count = 0\n","total_count = 0\n","frequnecy = 0\n","total_freq = 0\n","\n","for key,counter in y_tokenizer.word_counts.items():\n","    total_count = total_count + 1\n","    total_freq = total_freq + counter\n","    if(counter < therold_count):\n","        count = count + 1\n","        frequnecy = frequnecy + counter\n","    \n","print(\"percentage of rare words in vocabulary:\", (count/total_count) * 100)\n","print(\"total coverage of rare words in data:\", (frequnecy/total_freq) * 100)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:35.565199Z","iopub.status.busy":"2024-07-15T17:43:35.564727Z","iopub.status.idle":"2024-07-15T17:43:36.013257Z","shell.execute_reply":"2024-07-15T17:43:36.012395Z","shell.execute_reply.started":"2024-07-15T17:43:35.565133Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of vocabulary in Y = 4968\n"]}],"source":["y_tokenizer = Tokenizer(num_words = total_count - count) \n","y_tokenizer.fit_on_texts(list(y_tr))\n","\n","# convert text sequences into integer sequences \n","y_train_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n","y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n","\n","# padding zero upto maximum length\n","y_train_pad    =   pad_sequences(y_train_seq, maxlen = limit_summary_len, padding = 'post')\n","y_val_pad   =   pad_sequences(y_val_seq, maxlen = limit_summary_len, padding = 'post')\n","\n","# size of vocabulary ( +1 for padding token)\n","y_vocabulary  =   y_tokenizer.num_words + 1\n","print(\"Size of vocabulary in Y = {}\".format(y_vocabulary))"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:43:36.014710Z","iopub.status.busy":"2024-07-15T17:43:36.014425Z","iopub.status.idle":"2024-07-15T17:43:37.070405Z","shell.execute_reply":"2024-07-15T17:43:37.069413Z","shell.execute_reply.started":"2024-07-15T17:43:36.014671Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'attention_keras' already exists and is not an empty directory.\n"]}],"source":["!git clone \"https://github.com/thushv89/attention_keras\""]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:57:14.602899Z","iopub.status.busy":"2024-07-15T17:57:14.602553Z","iopub.status.idle":"2024-07-15T17:57:16.474612Z","shell.execute_reply":"2024-07-15T17:57:16.473772Z","shell.execute_reply.started":"2024-07-15T17:57:14.602857Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Seq2Seq_Attention_Model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Encoder_Input (InputLayer)      [(None, 70)]         0                                            \n","__________________________________________________________________________________________________\n","masking_4 (Masking)             (None, 70)           0           Encoder_Input[0][0]              \n","__________________________________________________________________________________________________\n","Encoder_Embedding (Embedding)   (None, 70, 150)      1874550     masking_4[0][0]                  \n","__________________________________________________________________________________________________\n","Bidirectional_Encoder_LSTM1 (Bi [(None, 70, 600), (N 1082400     Encoder_Embedding[0][0]          \n","__________________________________________________________________________________________________\n","Decoder_Input (InputLayer)      [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","Bidirectional_Encoder_LSTM2 (Bi [(None, 70, 600), (N 2162400     Bidirectional_Encoder_LSTM1[0][0]\n","__________________________________________________________________________________________________\n","masking_5 (Masking)             (None, None)         0           Decoder_Input[0][0]              \n","__________________________________________________________________________________________________\n","Bidirectional_Encoder_LSTM3 (Bi [(None, 70, 600), (N 2162400     Bidirectional_Encoder_LSTM2[0][0]\n","__________________________________________________________________________________________________\n","Decoder_Embedding (Embedding)   (None, None, 150)    745200      masking_5[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 600)          0           Bidirectional_Encoder_LSTM3[0][1]\n","                                                                 Bidirectional_Encoder_LSTM3[0][3]\n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 600)          0           Bidirectional_Encoder_LSTM3[0][2]\n","                                                                 Bidirectional_Encoder_LSTM3[0][4]\n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 600),  1802400     Decoder_Embedding[0][0]          \n","                                                                 concatenate_16[0][0]             \n","                                                                 concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","attention_layer (AttentionLayer ((None, None, 600),  720600      Bidirectional_Encoder_LSTM3[0][0]\n","                                                                 Decoder_LSTM[0][0]               \n","__________________________________________________________________________________________________\n","concat_layer (Concatenate)      (None, None, 1200)   0           Decoder_LSTM[0][0]               \n","                                                                 attention_layer[0][0]            \n","__________________________________________________________________________________________________\n","Final_Output_Layer (TimeDistrib (None, None, 4968)   5966568     concat_layer[0][0]               \n","==================================================================================================\n","Total params: 16,516,518\n","Trainable params: 16,516,518\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Model\n","from attention_keras.src.layers.attention import AttentionLayer\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, TimeDistributed, Bidirectional, Masking\n","\n","hidden_dim = 300\n","embedding_dim = 150\n","#### encoder\n","\n","# Encoder input shape\n","Encoder_Input = Input(shape=(limit_text_len, ), name='Encoder_Input')\n","masked_input = Masking(mask_value=0)(Encoder_Input)\n","\n","# Embedding layer\n","Encoder_Embedding =  Embedding(x_vocabulary, embedding_dim, trainable=True, name='Encoder_Embedding')(masked_input)\n","# Bidirectional Encoder LSTM 1\n","encoder_lstm1 = Bidirectional(LSTM(hidden_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.5), name='Bidirectional_Encoder_LSTM1')\n","enc_output_1, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_lstm1(Encoder_Embedding)\n","\n","# Concatenate forward and backward states\n","state_h1 = Concatenate()([forward_h1, backward_h1])\n","state_c1 = Concatenate()([forward_c1, backward_c1])\n","\n","# Bidirectional Encoder LSTM 2\n","encoder_lstm2 = Bidirectional(LSTM(hidden_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.5), name='Bidirectional_Encoder_LSTM2')\n","enc_output_2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(enc_output_1)\n","\n","# Concatenate forward and backward states\n","state_h2 = Concatenate()([forward_h2, backward_h2])\n","state_c2 = Concatenate()([forward_c2, backward_c2])\n","\n","# Bidirectional Encoder LSTM 3\n","encoder_lstm3 = Bidirectional(LSTM(hidden_dim, return_state=True, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), name='Bidirectional_Encoder_LSTM3')\n","enc_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm3(enc_output_2)\n","\n","# Concatenate forward and backward states\n","state_h = Concatenate()([forward_h, backward_h])\n","state_c = Concatenate()([forward_c, backward_c])\n","\n","############## decoder\n","# decoder input\n","dec_inputs = Input(shape=(None,), name='Decoder_Input')\n","masked_dec_inputs = Masking(mask_value=0)(dec_inputs)\n","\n","# Embedding layer\n","dec_emb_layer = Embedding(y_vocabulary, embedding_dim, trainable=True, name='Decoder_Embedding')\n","dec_emb = dec_emb_layer(masked_dec_inputs)\n","\n","decoder_lstm = LSTM(2*hidden_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2, name='Decoder_LSTM')\n","dec_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n","\n","# Attention layer\n","attn_layer = AttentionLayer(name='attention_layer')\n","attn_out, attn_states = attn_layer([enc_outputs, dec_outputs])\n","\n","# Concat attention input and decoder LSTM output\n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([dec_outputs, attn_out])\n","\n","# Dense layer\n","decoder_dense = TimeDistributed(Dense(y_vocabulary, activation='softmax'), name='Final_Output_Layer')\n","decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","# Define the model \n","model = Model([Encoder_Input, dec_inputs], decoder_outputs, name='Seq2Seq_Attention_Model')\n","\n","# Print model summary\n","model.summary()"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:57:16.476895Z","iopub.status.busy":"2024-07-15T17:57:16.476581Z","iopub.status.idle":"2024-07-15T17:57:16.535997Z","shell.execute_reply":"2024-07-15T17:57:16.535253Z","shell.execute_reply.started":"2024-07-15T17:57:16.476846Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer = 'rmsprop',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   mode = 'min',\n","                   verbose = 1,\n","                   patience = 1)\n","\n","mc = ModelCheckpoint('ALL_best_model.h5',\n","                    monitor = 'val_loss',\n","                    mode = 'min',\n","                    verbose = 1,\n","                    save_best_only = True)"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:57:16.537763Z","iopub.status.busy":"2024-07-15T17:57:16.537370Z","iopub.status.idle":"2024-07-15T18:03:32.657899Z","shell.execute_reply":"2024-07-15T18:03:32.657074Z","shell.execute_reply.started":"2024-07-15T17:57:16.537714Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 6598 samples, validate on 825 samples\n","Epoch 1/50\n","6336/6598 [===========================>..] - ETA: 1s - loss: 5.4683\n","Epoch 00001: val_loss improved from inf to 4.45451, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 41s 6ms/sample - loss: 5.4391 - val_loss: 4.4545\n","Epoch 2/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 4.5983\n","Epoch 00002: val_loss improved from 4.45451 to 4.28541, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 4.6003 - val_loss: 4.2854\n","Epoch 3/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 4.4524\n","Epoch 00003: val_loss improved from 4.28541 to 4.13040, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 4.4552 - val_loss: 4.1304\n","Epoch 4/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 4.3016\n","Epoch 00004: val_loss improved from 4.13040 to 4.04114, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 4.3033 - val_loss: 4.0411\n","Epoch 5/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 4.1847\n","Epoch 00005: val_loss improved from 4.04114 to 3.96114, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 4.1813 - val_loss: 3.9611\n","Epoch 6/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 4.0879\n","Epoch 00006: val_loss improved from 3.96114 to 3.86251, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 4.0832 - val_loss: 3.8625\n","Epoch 7/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.9540\n","Epoch 00007: val_loss improved from 3.86251 to 3.81719, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.9602 - val_loss: 3.8172\n","Epoch 8/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.8498\n","Epoch 00008: val_loss improved from 3.81719 to 3.78560, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.8501 - val_loss: 3.7856\n","Epoch 9/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.7545\n","Epoch 00009: val_loss improved from 3.78560 to 3.74713, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.7571 - val_loss: 3.7471\n","Epoch 10/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.6667\n","Epoch 00010: val_loss improved from 3.74713 to 3.73390, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.6694 - val_loss: 3.7339\n","Epoch 11/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.5849\n","Epoch 00011: val_loss improved from 3.73390 to 3.70045, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.5863 - val_loss: 3.7005\n","Epoch 12/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.5079\n","Epoch 00012: val_loss improved from 3.70045 to 3.68732, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.5078 - val_loss: 3.6873\n","Epoch 13/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.4370\n","Epoch 00013: val_loss improved from 3.68732 to 3.67138, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.4317 - val_loss: 3.6714\n","Epoch 14/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.3535\n","Epoch 00014: val_loss improved from 3.67138 to 3.67027, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.3509 - val_loss: 3.6703\n","Epoch 15/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.2775\n","Epoch 00015: val_loss improved from 3.67027 to 3.66562, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.2770 - val_loss: 3.6656\n","Epoch 16/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.2000\n","Epoch 00016: val_loss improved from 3.66562 to 3.66478, saving model to ALL_best_model.h5\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.2019 - val_loss: 3.6648\n","Epoch 17/50\n","6336/6598 [===========================>..] - ETA: 0s - loss: 3.1283\n","Epoch 00017: val_loss did not improve from 3.66478\n","6598/6598 [==============================] - 21s 3ms/sample - loss: 3.1288 - val_loss: 3.6665\n","Epoch 00017: early stopping\n"]}],"source":["history = model.fit([x_train_pad, y_train_pad[:,:-1]], y_train_pad.reshape(y_train_pad.shape[0], y_train_pad.shape[1], 1)[:,1:],\n","                    epochs = 50,\n","                    callbacks = [es, mc],\n","                    batch_size = 264,\n","                    validation_data = ([x_val_pad,y_val_pad[:,:-1]], y_val_pad.reshape(y_val_pad.shape[0], y_val_pad.shape[1], 1)[:,1:]))"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:03:32.660581Z","iopub.status.busy":"2024-07-15T18:03:32.660239Z","iopub.status.idle":"2024-07-15T18:03:32.989067Z","shell.execute_reply":"2024-07-15T18:03:32.988220Z","shell.execute_reply.started":"2024-07-15T18:03:32.660526Z"},"trusted":true},"outputs":[],"source":["reverse_target_word_index = y_tokenizer.index_word\n","reverse_source_word_index = x_tokenizer.index_word\n","target_word_index = y_tokenizer.word_index\n","\n","# encode the input sequence to get the feature vector\n","encoder_model = Model(inputs=Encoder_Input, outputs=[enc_outputs, state_h, state_c])\n","\n","# decoder setup\n","# below tensors will hold the states of the previous time step\n","decoder_state_input_h = Input(shape=(2*hidden_dim,))\n","decoder_state_input_c = Input(shape=(2*hidden_dim,))\n","decoder_hid_s_input = Input(shape=(limit_text_len, 2*hidden_dim))\n","\n","# get the embeddings of the decoder sequence\n","decoder_emb2 = dec_emb_layer(dec_inputs) \n","# to predict the next word in the sequence, set the initial states to the states from the previous time step\n","dec_outputs, state_h2, state_c2 = decoder_lstm(decoder_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","attn_layer = AttentionLayer(name='attention_layer')\n","#attention inference\n","attn_out, attn_states_inf = attn_layer([decoder_hid_s_input, dec_outputs])\n","decoder_inf_concat = Concatenate(axis=-1, name='concat')([dec_outputs, attn_out])\n","\n","# a dense softmax layer to generate prob dist. over the target vocabulary\n","dec_outputs = decoder_dense(decoder_inf_concat) \n","\n","# final decoder model\n","decoder_model = Model(\n","    [dec_inputs] + [decoder_hid_s_input,decoder_state_input_h, decoder_state_input_c],\n","    [dec_outputs] + [state_h2, state_c2])\n"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:03:32.991042Z","iopub.status.busy":"2024-07-15T18:03:32.990725Z","iopub.status.idle":"2024-07-15T18:03:33.206869Z","shell.execute_reply":"2024-07-15T18:03:33.205605Z","shell.execute_reply.started":"2024-07-15T18:03:32.990986Z"},"trusted":true},"outputs":[],"source":["encoder_model.save('encoder_model.h5')\n","decoder_model.save('decoder_model.h5')\n","\n","# Save tokenizers\n","import pickle\n","\n","with open('x_tokenizer.pkl', 'wb') as f:\n","    pickle.dump(x_tokenizer, f)\n","\n","with open('y_tokenizer.pkl', 'wb') as f:\n","    pickle.dump(y_tokenizer, f)"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:03:33.208601Z","iopub.status.busy":"2024-07-15T18:03:33.208249Z","iopub.status.idle":"2024-07-15T18:03:33.218722Z","shell.execute_reply":"2024-07-15T18:03:33.217681Z","shell.execute_reply.started":"2024-07-15T18:03:33.208549Z"},"trusted":true},"outputs":[],"source":["def out_sequence(input_by_seq):\n","    # encode the input as state vectors.\n","    encoder_out, encoder_h, encoder_c = encoder_model.predict(input_by_seq)\n","    \n","    # generate empty target sequence of length 1.\n","    target_seq = np.zeros((1,1))\n","    \n","    # ppulate the first word of target sequence with the start word.\n","    target_seq[0, 0] = target_word_index['sostok']\n","\n","    stop = False\n","    out_sentence = ''\n","    while not stop:\n","      \n","        output_tokens, Enc_h, Enc_c = decoder_model.predict([target_seq] + [encoder_out, encoder_h, encoder_c])\n","\n","\n","        # get token\n","        token_index = np.argmax(output_tokens[0, -1, :])\n","        token = reverse_target_word_index[token_index]\n","        \n","        if(token!='eostok'):\n","            out_sentence += ' '+token\n","\n","        # exit condition: either hit max length or find stop word.\n","        if (token == 'eostok'  or len(out_sentence.split()) >= (limit_summary_len-1)):\n","            stop = True\n","\n","        # update the target sequence (of length 1).\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = token_index\n","\n","        # Update internal states\n","        encoder_h, encoder_c= Enc_h,Enc_c\n","\n","    return out_sentence"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:03:33.220503Z","iopub.status.busy":"2024-07-15T18:03:33.220031Z","iopub.status.idle":"2024-07-15T18:03:33.234292Z","shell.execute_reply":"2024-07-15T18:03:33.233422Z","shell.execute_reply.started":"2024-07-15T18:03:33.220435Z"},"trusted":true},"outputs":[],"source":["def seq2summary(input_seq):\n","    out = ''\n","    for i in input_seq:\n","        if((i != 0 and i != target_word_index['sostok']) and i != target_word_index['eostok']):\n","            out = out + reverse_target_word_index[i] + ' '\n","    return out\n","\n","def seq2text(input_seq):\n","    out = ''\n","    for i in input_seq:\n","        if(i != 0):\n","            out = out + reverse_source_word_index[i]+' '\n","    return out"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:03:33.235994Z","iopub.status.busy":"2024-07-15T18:03:33.235694Z","iopub.status.idle":"2024-07-15T18:03:39.526416Z","shell.execute_reply":"2024-07-15T18:03:39.525592Z","shell.execute_reply.started":"2024-07-15T18:03:33.235945Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: use conditioner like long scent mixes well honey stir conditioner honey bowl thoroughly combined store extra conditioner old conditioner bottle later use use ratio honey conditioner make larger batch shampoo hair use honey conditioner would normal conditioner distribute small amount hair rinse finished leave conditioner hair 5 10 minutes finish shower greater lightening effect hair feels sticky rinsing decrease amount honey use increase amount conditioner \n","Original summary: mix 1 4 cup honey and 1 2 cup conditioner use the conditioner after every shampoo \n","Predicted summary:  make the spice and solution make the water add the water\n","\n","\n","Review: things improved greatly decorating still unusual fashion prepared carry \n","Original summary: attach earring findings to each stopper through the stopper hole wear with \n","Predicted summary:  use the ingredients of the ingredients\n","\n","\n","Review: rice ball purchased supermarket 100 g mushroom found forged throughout autumn select specific ingredients wish use rucksack press start button satisfied chosen start cooking \n","Original summary: ingredients needed to make the rice dish have the ingredients in your rucksack choose your ingredients confirm your decision \n","Predicted summary:  make the ears make the face make the top\n","\n","\n","Review: loan instead 30 year loan way pay extra hundred dollars per month save much total interest example 200 000 mortgage 30 year loan cost another 500 interest payments actually paying total 500 course 30 years hand willing pay extra hundred dollars month example 350 refinancing 15 year loan usually lower interest rate could pay mortgage 15 years best part would save 123 700 interest money pocket talk loan officer options \n","Original summary: your home mortgage \n","Predicted summary:  make a start to the game of the final of the\n","\n","\n","Review: toggle turn grey green able access siri \n","Original summary: turn siri on through settings select general choose siri slide the toggle next siri to the right \n","Predicted summary:  open the settings app tap general tap the settings tap the\n","\n","\n","Review: pick charity feel strongly reputable think fun creative idea fashion show charity shop clothes competition summer garden play etc planning event give something focus even plan holding yet \n","Original summary: organize a fundraiser \n","Predicted summary:  make a first stroke make the stroke make the stroke finished practice writing it\n","\n","\n","Review: easiest use big wide shallow pan job use two forks shred pork meat bite sized pieces continue pork entire pork shoulder reduced pile shredded pork mix crust inside roast together go pulled pork served barbecue sauce either main dish sandwich bun serve side coleslaw baked beans \n","Original summary: place the roast in a large pan the pork serve the pork \n","Predicted summary:  use the ingredients in the top blend the ingredients\n","\n","\n","Review: button used play pause function make sure ipod charged plugged power device turn off ensure ipod stay turned \n","Original summary: press and hold the sleep wake button move the hold button to the right \n","Predicted summary:  open the settings app tap general tap the settings tap the\n","\n","\n","Review: may canon good enough rock n roll great photography begins pressing shutter add photo attachment said send letter '' \n","Original summary: take your pictures with your smart phone's camera snap a picture create a new email document \n","Predicted summary:  make the first stroke make the second stroke make the final stroke finished practice writing it\n","\n","\n","Review: chop broccoli bite size bits dice onion cucumber cut grapes half done prepping ingredients transfer medium size mixing bowl add sunflower seeds stir combine second mixing bowl stir together mayo lemon juice salt pepper pour salad stir combine serve dig \n","Original summary: prep your fruit and veggies mix with your seeds make your dressing mix and serve \n","Predicted summary:  make the dressing and make the top make the top\n","\n","\n"]}],"source":["for i in range(0, 10):\n","    print(\"Review:\", seq2text(x_train_pad[i]))\n","    print(\"Original summary:\", seq2summary(y_train_pad[i]))\n","    print(\"Predicted summary:\", out_sequence(x_train_pad[i].reshape(1, limit_text_len)))\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:46:15.873349Z","iopub.status.busy":"2024-07-15T17:46:15.873080Z","iopub.status.idle":"2024-07-15T17:46:15.877195Z","shell.execute_reply":"2024-07-15T17:46:15.876420Z","shell.execute_reply.started":"2024-07-15T17:46:15.873313Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:09:01.260509Z","iopub.status.busy":"2024-07-15T18:09:01.260098Z","iopub.status.idle":"2024-07-15T18:09:06.878841Z","shell.execute_reply":"2024-07-15T18:09:06.877812Z","shell.execute_reply.started":"2024-07-15T18:09:01.260435Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: probably going hurt,try hard put balls feet toward ground stay flexible .,know land feet,slightly bend knees .,tuck ball first contact ground . land,land balls feet roll . lessen impact great deal.\n","Original summary: sostok prepare to feel some pain., bend your knees., use your knees and hips as shock absorbers. eostok\n","Predicted summary:  make a suitable of the top of the top\n","\n","\n","Review: someone clothes fire,wrap fire blanket .,use edges blanket protect hands prevent getting burned . roll blanket securely place.,instruct person danger stop,drop,roll . classic safety technique used diminish fire . person stop moving,drops ground,rolls fire suffocates.,burns caused fire evaluated medical professional soon possible . even think burns look minor,injury caused fire evaluated medical professional . take person whose clothes fire er immediately.\n","Original summary: sostok wrap someone whose clothes are burning in the fire blanket., have the person stop, drop, and roll., seek medical assistance. eostok\n","Predicted summary:  choose a suitable of the top of the top of the top\n","\n","\n","Review: link network panel located right side taskbar . either 'monitor cable' 'wifi logo' icon .;,find rectangular tab airplane icon . click tab implement mode .,press tab,wait seconds wireless connections disappear network panel.\n","Original summary: sostok open the network panel., search for the airplane mode icon., wait until all the wireless networks stop. eostok\n","Predicted summary:  open the settings app tap the settings tap the history tab tap the\n","\n","\n","Review: allow open/transfer xbox files internet .;,may help future wish program . ,\n","Original summary: sostok download the horizon xbox modding tool., browse the software for curiosity., go to your xbox. eostok\n","Predicted summary:  go to the settings settings the on the button button\n","\n","\n","Review: grey icon gears located home screen .;,fifth set options .,section titled distances . maps use metric system display distances directions.\n","Original summary: sostok open your iphones settings., scroll down and tap maps., scroll down and tap in kilometers. eostok\n","Predicted summary:  open your settings tap tap general tap about tap the next\n","\n","\n","Review: already,get app store play store .,tap log,enter username password,tap log .,tap 3 dots lower right corner open stories select one list . tap chat icon lower left swipe right friend view snaps sent directly .,story series snaps,skip directly next snap . single video skip end.,exit whatever snap story viewing.\n","Original summary: sostok open snapchat., sign in to your account., view a snap/story., tap to skip the snap., swipe down on the snap. eostok\n","Predicted summary:  open the settings app tap the scroll down and tap the next\n","\n","\n","Review: event decided forego eyeliner,eyeshadow great option!try stick neutral colors,want contrast make look edgy . lightest shade matches skin tone choice consider .,need applicator task,large eyeshadow brush best option available . using eyeshadow tool,cover lid evenly best tone skin .,time want choose shade barely lighter skin color . using fresh applicator,blend across lid direction color create natural gradient possible .,check see whether eyeliner thickness way along mirror.\n","Original summary: sostok select eyeshadow., add your eyeshadow., apply eyeshadow in the corner of your eye., wipe off any stray mascara/eyeliner/eyeshadow. eostok\n","Predicted summary:  choose a suitable or on the top of the top\n","\n","\n","Review: , search rainbow.\n","Original summary: sostok go to google.com. , search \"google rainbow\". , click \"i am feeling lucky\". , google rainbow! eostok\n","Predicted summary:  go to the settings settings the on the button button\n","\n","\n","Review: place purpose flour,baking powder,salt sifter . sift bowl,eliminating clumps .,stir sugar little bit time . pour little bowl,mix together,pour more.you adjust amount sugar based preference . people prefer less sugar spice cake .,mixing together dry ingredients,mix cinnamon,clove,spice . make sure combine ingredients well spices evenly distributed throughout mixture.you adjust amount spices based taste .,place mix airtight container . jar works really well . cake mix last least 6 months way.\n","Original summary: sostok sift dry ingredients., mix in sugar., mix in the spices., store in an airtight container. eostok\n","Predicted summary:  make the dressing solution make the juice make the solution\n","\n","\n","Review: hamsters last days,make happy possible . put soft material cage . let sleep much wants . put favorite toys cage .,hamster may lose energy may participate usual exercise . want make excessively tired holding .,talk vet parents diet would best . hamster suffering heart damage,example,may want avoid fatty foods like sunflowers . teeth issues also plague older hamsters . try feeding soft foods like rice cereal.\n","Original summary: sostok make your hamster comfortable., avoid excessive holding., feed and water appropriately. eostok\n","Predicted summary:  choose a suitable on the top of the top of the top\n","\n","\n"]}],"source":["for i in range(0, 10):\n","    print(\"Review:\", x_test[i])\n","    print(\"Original summary:\", y_test[i])\n","    x_tr_seq2    =   x_tokenizer.texts_to_sequences(np.array([x_test[i]])) \n","    x_tr2    =   pad_sequences(x_tr_seq2,  maxlen=limit_text_len, padding='post')\n","    print(\"Predicted summary:\", out_sequence(x_tr2[0].reshape(1,limit_text_len)))\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T17:46:15.890899Z","iopub.status.busy":"2024-07-15T17:46:15.890638Z","iopub.status.idle":"2024-07-15T17:46:15.899837Z","shell.execute_reply":"2024-07-15T17:46:15.899078Z","shell.execute_reply.started":"2024-07-15T17:46:15.890863Z"},"trusted":true},"outputs":[],"source":["# print(\"Review:\",seq2text(x_tr2[0]))\n","# # print(\"Original summary:\",seq2summary(y_tr[i]))\n","# print(\"Predicted summary:\",decode_sequence(x_tr2[0].reshape(1,max_text_len)))\n","# print(\"\\n\")"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T18:15:08.968009Z","iopub.status.busy":"2024-07-15T18:15:08.967657Z","iopub.status.idle":"2024-07-15T18:15:10.892419Z","shell.execute_reply":"2024-07-15T18:15:10.891571Z","shell.execute_reply.started":"2024-07-15T18:15:08.967966Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","import pickle\n","from attention_keras.src.layers.attention import AttentionLayer\n","custom_objects = {'AttentionLayer': AttentionLayer}\n","# Load models\n","encoder_model = load_model('encoder_model.h5')\n","decoder_model = load_model('decoder_model.h5',custom_objects=custom_objects)\n","\n","# Load tokenizers\n","with open('x_tokenizer.pkl', 'rb') as f:\n","    x_tokenizer = pickle.load(f)\n","\n","with open('y_tokenizer.pkl', 'rb') as f:\n","    y_tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":122583,"sourceId":295628,"sourceType":"datasetVersion"},{"datasetId":1895,"sourceId":791838,"sourceType":"datasetVersion"}],"dockerImageVersionId":29908,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
